{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# import resources\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "\r\n",
        "# random seed (for reproducibility)\r\n",
        "seed = 1\r\n",
        "# set random seed for numpy\r\n",
        "np.random.seed(seed)\r\n",
        "# set random seed for pytorch\r\n",
        "torch.manual_seed(seed)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x2172e45a490>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nExVIhReu3IX",
        "outputId": "c077ab39-5192-4b0c-983d-795cbe3c31b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from torchvision import datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "# number of subprocesses to use for data loading\r\n",
        "num_workers = 0\r\n",
        "# how many samples per batch to load\r\n",
        "batch_size = 20\r\n",
        "\r\n",
        "# convert data to Tensors\r\n",
        "transform = transforms.ToTensor()\r\n",
        "\r\n",
        "# choose the training and test datasets\r\n",
        "train_data = datasets.FashionMNIST(root='fmnist', train=True,\r\n",
        "                            download=True, transform=transform)\r\n",
        "\r\n",
        "test_data = datasets.FashionMNIST(root='fmnist', train=False, \r\n",
        "                           download=True, transform=transform)\r\n",
        "\r\n",
        "# prepare data loaders\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           num_workers=num_workers)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          num_workers=num_workers)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\9931168\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "metadata": {
        "id": "zAY9BoidvAc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "    \r\n",
        "# obtain one batch of training images\r\n",
        "dataiter = iter(train_loader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "images = images.numpy()\r\n",
        "\r\n",
        "# plot the images in the batch, along with the corresponding labels\r\n",
        "fig = plt.figure(figsize=(25, 4))\r\n",
        "for idx in np.arange(batch_size):\r\n",
        "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\r\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\r\n",
        "    # print out the correct label for each image\r\n",
        "    # .item() gets the value contained in a Tensor\r\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\9931168\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "P3XDuBTOwZA3",
        "outputId": "af9ff40a-5951-4965-ee91-665806e1eee5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "metadata": {
        "id": "BXtqPAnVwc8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class ConvLayer(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, in_channels=1, out_channels=256):\r\n",
        "        '''Constructs the ConvLayer with a specified input and output size.\r\n",
        "           param in_channels: input depth of an image, default value = 1\r\n",
        "           param out_channels: output depth of the convolutional layer, default value = 256\r\n",
        "           '''\r\n",
        "        super(ConvLayer, self).__init__()\r\n",
        "\r\n",
        "        # defining a convolutional layer of the specified size\r\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, \r\n",
        "                              kernel_size=9, stride=1, padding=0)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input to the layer; an input image\r\n",
        "           return: a relu-activated, convolutional layer\r\n",
        "           '''\r\n",
        "        # applying a ReLu activation to the outputs of the conv layer\r\n",
        "        features = F.relu(self.conv(x)) # will have dimensions (batch_size, 20, 20, 256)\r\n",
        "        return features"
      ],
      "outputs": [],
      "metadata": {
        "id": "f7y0uI3ywf5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class PrimaryCaps(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32):\r\n",
        "        '''Constructs a list of convolutional layers to be used in \r\n",
        "           creating capsule output vectors.\r\n",
        "           param num_capsules: number of capsules to create\r\n",
        "           param in_channels: input depth of features, default value = 256\r\n",
        "           param out_channels: output depth of the convolutional layers, default value = 32\r\n",
        "           '''\r\n",
        "        super(PrimaryCaps, self).__init__()\r\n",
        "\r\n",
        "        # creating a list of convolutional layers for each capsule I want to create\r\n",
        "        # all capsules have a conv layer with the same parameters\r\n",
        "        self.capsules = nn.ModuleList([\r\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \r\n",
        "                      kernel_size=9, stride=2, padding=0)\r\n",
        "            for _ in range(num_capsules)])\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input; features from a convolutional layer\r\n",
        "           return: a set of normalized, capsule output vectors\r\n",
        "           '''\r\n",
        "        # get batch size of inputs\r\n",
        "        batch_size = x.size(0)\r\n",
        "        # reshape convolutional layer outputs to be (batch_size, vector_dim=1152, 1)\r\n",
        "        u = [capsule(x).view(batch_size, 32 * 6 * 6, 1) for capsule in self.capsules]\r\n",
        "        # stack up output vectors, u, one for each capsule\r\n",
        "        u = torch.cat(u, dim=-1)\r\n",
        "        # squashing the stack of vectors\r\n",
        "        u_squash = self.squash(u)\r\n",
        "        return u_squash\r\n",
        "    \r\n",
        "    def squash(self, input_tensor):\r\n",
        "        '''Squashes an input Tensor so it has a magnitude between 0-1.\r\n",
        "           param input_tensor: a stack of capsule inputs, s_j\r\n",
        "           return: a stack of normalized, capsule output vectors, v_j\r\n",
        "           '''\r\n",
        "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\r\n",
        "        scale = squared_norm / (1 + squared_norm) # normalization coeff\r\n",
        "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \r\n",
        "        return output_tensor"
      ],
      "outputs": [],
      "metadata": {
        "id": "FsvxVCgDwjat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "def softmax(input_tensor, dim=1):\r\n",
        "    # transpose input\r\n",
        "    transposed_input = input_tensor.transpose(dim, len(input_tensor.size()) - 1)\r\n",
        "    # calculate softmax\r\n",
        "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\r\n",
        "    # un-transpose result\r\n",
        "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input_tensor.size()) - 1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vYhvYM6szTHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "#import helpers # to get transpose softmax function\r\n",
        "\r\n",
        "# dynamic routing\r\n",
        "def dynamic_routing(b_ij, u_hat, squash, routing_iterations=3):\r\n",
        "    '''Performs dynamic routing between two capsule layers.\r\n",
        "       param b_ij: initial log probabilities that capsule i should be coupled to capsule j\r\n",
        "       param u_hat: input, weighted capsule vectors, W u\r\n",
        "       param squash: given, normalizing squash function\r\n",
        "       param routing_iterations: number of times to update coupling coefficients\r\n",
        "       return: v_j, output capsule vectors\r\n",
        "       '''    \r\n",
        "    # update b_ij, c_ij for number of routing iterations\r\n",
        "    for iteration in range(routing_iterations):\r\n",
        "        # softmax calculation of coupling coefficients, c_ij\r\n",
        "        c_ij = softmax(b_ij, dim=2)\r\n",
        "         #helpers.\r\n",
        "        \r\n",
        "\r\n",
        "        # calculating total capsule inputs, s_j = sum(c_ij*u_hat)\r\n",
        "        s_j = (c_ij * u_hat).sum(dim=2, keepdim=True)\r\n",
        "\r\n",
        "        # squashing to get a normalized vector output, v_j\r\n",
        "        v_j = squash(s_j)\r\n",
        "\r\n",
        "        # if not on the last iteration, calculate agreement and new b_ij\r\n",
        "        if iteration < routing_iterations - 1:\r\n",
        "            # agreement\r\n",
        "            a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\r\n",
        "            \r\n",
        "            # new b_ij\r\n",
        "            b_ij = b_ij + a_ij\r\n",
        "    \r\n",
        "    return v_j # return latest v_j"
      ],
      "outputs": [],
      "metadata": {
        "id": "skUSggXGwm0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# it will also be relevant, in this model, to see if I can train on gpu\r\n",
        "TRAIN_ON_GPU = torch.cuda.is_available()\r\n",
        "\r\n",
        "if(TRAIN_ON_GPU):\r\n",
        "    print('Training on GPU!')\r\n",
        "else:\r\n",
        "    print('Only CPU available')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU!\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaDbIgfCxER-",
        "outputId": "c421a444-2aa3-4c5a-84f8-a993a958dca9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "class DigitCaps(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, num_capsules=10, previous_layer_nodes=32*6*6, \r\n",
        "                 in_channels=8, out_channels=16):\r\n",
        "        '''Constructs an initial weight matrix, W, and sets class variables.\r\n",
        "           param num_capsules: number of capsules to create\r\n",
        "           param previous_layer_nodes: dimension of input capsule vector, default value = 1152\r\n",
        "           param in_channels: number of capsules in previous layer, default value = 8\r\n",
        "           param out_channels: dimensions of output capsule vector, default value = 16\r\n",
        "           '''\r\n",
        "        super(DigitCaps, self).__init__()\r\n",
        "\r\n",
        "        # setting class variables\r\n",
        "        self.num_capsules = num_capsules\r\n",
        "        self.previous_layer_nodes = previous_layer_nodes # vector input (dim=1152)\r\n",
        "        self.in_channels = in_channels # previous layer's number of capsules\r\n",
        "\r\n",
        "        # starting out with a randomly initialized weight matrix, W\r\n",
        "        # these will be the weights connecting the PrimaryCaps and DigitCaps layers\r\n",
        "        self.W = nn.Parameter(torch.randn(num_capsules, previous_layer_nodes, \r\n",
        "                                          in_channels, out_channels))\r\n",
        "\r\n",
        "    def forward(self, u):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param u: the input; vectors from the previous PrimaryCaps layer\r\n",
        "           return: a set of normalized, capsule output vectors\r\n",
        "           '''\r\n",
        "        \r\n",
        "        # adding batch_size dims and stacking all u vectors\r\n",
        "        u = u[None, :, :, None, :]\r\n",
        "        # 4D weight matrix\r\n",
        "        W = self.W[:, None, :, :, :]\r\n",
        "        \r\n",
        "        # calculating u_hat = W*u\r\n",
        "        u_hat = torch.matmul(u, W)\r\n",
        "\r\n",
        "        # getting the correct size of b_ij\r\n",
        "        # setting them all to 0, initially\r\n",
        "        b_ij = torch.zeros(*u_hat.size())\r\n",
        "        \r\n",
        "        # moving b_ij to GPU, if available\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            b_ij = b_ij.cuda()\r\n",
        "\r\n",
        "        # update coupling coefficients and calculate v_j\r\n",
        "        v_j = dynamic_routing(b_ij, u_hat, self.squash, routing_iterations=3)\r\n",
        "\r\n",
        "        return v_j # return final vector outputs\r\n",
        "    \r\n",
        "    \r\n",
        "    def squash(self, input_tensor):\r\n",
        "        '''Squashes an input Tensor so it has a magnitude between 0-1.\r\n",
        "           param input_tensor: a stack of capsule inputs, s_j\r\n",
        "           return: a stack of normalized, capsule output vectors, v_j\r\n",
        "           '''\r\n",
        "        # same squash function as before\r\n",
        "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\r\n",
        "        scale = squared_norm / (1 + squared_norm) # normalization coeff\r\n",
        "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \r\n",
        "        return output_tensor"
      ],
      "outputs": [],
      "metadata": {
        "id": "xGZfUiimxIgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, input_vector_length=16, input_capsules=10, hidden_dim=512):\r\n",
        "        '''Constructs an series of linear layers + activations.\r\n",
        "           param input_vector_length: dimension of input capsule vector, default value = 16\r\n",
        "           param input_capsules: number of capsules in previous layer, default value = 10\r\n",
        "           param hidden_dim: dimensions of hidden layers, default value = 512\r\n",
        "           '''\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        \r\n",
        "        # calculate input_dim\r\n",
        "        input_dim = input_vector_length * input_capsules\r\n",
        "        \r\n",
        "        # define linear layers + activations\r\n",
        "        self.linear_layers = nn.Sequential(\r\n",
        "            nn.Linear(input_dim, hidden_dim), # first hidden layer\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(hidden_dim, hidden_dim*2), # second, twice as deep\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(hidden_dim*2, 28*28), # can be reshaped into 28*28 image\r\n",
        "            nn.Sigmoid() # sigmoid activation to get output pixel values in a range from 0-1\r\n",
        "            )\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input; vectors from the previous DigitCaps layer\r\n",
        "           return: two things, reconstructed images and the class scores, y\r\n",
        "           '''\r\n",
        "        classes = (x ** 2).sum(dim=-1) ** 0.5\r\n",
        "        classes = F.softmax(classes, dim=-1)\r\n",
        "        \r\n",
        "        # find the capsule with the maximum vector length\r\n",
        "        # here, vector length indicates the probability of a class' existence\r\n",
        "        _, max_length_indices = classes.max(dim=1)\r\n",
        "        \r\n",
        "        # create a sparse class matrix\r\n",
        "        sparse_matrix = torch.eye(10) # 10 is the number of classes\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            sparse_matrix = sparse_matrix.cuda()\r\n",
        "        # get the class scores from the \"correct\" capsule\r\n",
        "        y = sparse_matrix.index_select(dim=0, index=max_length_indices.data)\r\n",
        "        \r\n",
        "        # create reconstructed pixels\r\n",
        "        x = x * y[:, :, None]\r\n",
        "        # flatten image into a vector shape (batch_size, vector_dim)\r\n",
        "        flattened_x = x.contiguous().view(x.size(0), -1)\r\n",
        "        # create reconstructed image vectors\r\n",
        "        reconstructions = self.linear_layers(flattened_x)\r\n",
        "        \r\n",
        "        # return reconstructions and the class scores, y\r\n",
        "        return reconstructions, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gu8R_RG0xN3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "class CapsuleNetwork(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self):\r\n",
        "        '''Constructs a complete Capsule Network.'''\r\n",
        "        super(CapsuleNetwork, self).__init__()\r\n",
        "        self.conv_layer = ConvLayer()\r\n",
        "        self.primary_capsules = PrimaryCaps()\r\n",
        "        self.digit_capsules = DigitCaps()\r\n",
        "        self.decoder = Decoder()\r\n",
        "                \r\n",
        "    def forward(self, images):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param images: the original MNIST image input data\r\n",
        "           return: output of DigitCaps layer, reconstructed images, class scores\r\n",
        "           '''\r\n",
        "        primary_caps_output = self.primary_capsules(self.conv_layer(images))\r\n",
        "        caps_output = self.digit_capsules(primary_caps_output).squeeze().transpose(0,1)\r\n",
        "        #print(caps_output.type(), caps_output.size())\r\n",
        "        reconstructions, y = self.decoder(caps_output)\r\n",
        "        return caps_output, reconstructions, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "LKr1_RcwxRuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# instantiate and print net\r\n",
        "#import torch, gc\r\n",
        "#gc.collect()\r\n",
        "#torch.cuda.empty_cache()\r\n",
        "\r\n",
        "capsule_net = CapsuleNetwork()\r\n",
        "\r\n",
        "print(capsule_net)\r\n",
        "\r\n",
        "\r\n",
        "# move model to GPU, if available \r\n",
        "if TRAIN_ON_GPU:\r\n",
        "    capsule_net = capsule_net.cuda()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CapsuleNetwork(\n",
            "  (conv_layer): ConvLayer(\n",
            "    (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
            "  )\n",
            "  (primary_capsules): PrimaryCaps(\n",
            "    (capsules): ModuleList(\n",
            "      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (digit_capsules): DigitCaps()\n",
            "  (decoder): Decoder(\n",
            "    (linear_layers): Sequential(\n",
            "      (0): Linear(in_features=160, out_features=512, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=1024, out_features=784, bias=True)\n",
            "      (5): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHzjE51KxWe3",
        "outputId": "de39ddb8-e603-434a-ce0b-f20854be0d4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "class CapsuleLoss(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self):\r\n",
        "        '''Constructs a CapsuleLoss module.'''\r\n",
        "        super(CapsuleLoss, self).__init__()\r\n",
        "        self.reconstruction_loss = nn.MSELoss(reduction='sum') # cumulative loss, equiv to size_average=False\r\n",
        "\r\n",
        "    def forward(self, x, labels, images, reconstructions):\r\n",
        "        '''Defines how the loss compares inputs.\r\n",
        "           param x: digit capsule outputs\r\n",
        "           param labels: \r\n",
        "           param images: the original MNIST image input data\r\n",
        "           param reconstructions: reconstructed MNIST image data\r\n",
        "           return: weighted margin and reconstruction loss, averaged over a batch\r\n",
        "           '''\r\n",
        "        batch_size = x.size(0)\r\n",
        "\r\n",
        "        ##  calculate the margin loss   ##\r\n",
        "        \r\n",
        "        # get magnitude of digit capsule vectors, v_c\r\n",
        "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\r\n",
        "\r\n",
        "        # calculate \"correct\" and incorrect loss\r\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\r\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\r\n",
        "        \r\n",
        "        # sum the losses, with a lambda = 0.5\r\n",
        "        margin_loss = labels * left + 0.5 * (1. - labels) * right\r\n",
        "        margin_loss = margin_loss.sum()\r\n",
        "\r\n",
        "        ##  calculate the reconstruction loss   ##\r\n",
        "        images = images.view(reconstructions.size()[0], -1)\r\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\r\n",
        "\r\n",
        "        # return a weighted, summed loss, averaged over a batch size\r\n",
        "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lf7jUp2exZQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "# custom loss\r\n",
        "criterion = CapsuleLoss()\r\n",
        "\r\n",
        "# Adam optimizer with default params\r\n",
        "optimizer = optim.Adam(capsule_net.parameters())"
      ],
      "outputs": [],
      "metadata": {
        "id": "GYecVY8Jxdtt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "def train(capsule_net, criterion, optimizer, \r\n",
        "          n_epochs, print_every=300):\r\n",
        "    '''Trains a capsule network and prints out training batch loss statistics.\r\n",
        "       Saves model parameters if *validation* loss has decreased.\r\n",
        "       param capsule_net: trained capsule network\r\n",
        "       param criterion: capsule loss function\r\n",
        "       param optimizer: optimizer for updating network weights\r\n",
        "       param n_epochs: number of epochs to train for\r\n",
        "       param print_every: batches to print and save training loss, default = 100\r\n",
        "       return: list of recorded training losses\r\n",
        "       '''\r\n",
        "\r\n",
        "    # track training loss over time\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    # one epoch = one pass over all training data \r\n",
        "    for epoch in range(1, n_epochs+1):\r\n",
        "\r\n",
        "        # initialize training loss\r\n",
        "        train_loss = 0.0\r\n",
        "        \r\n",
        "        capsule_net.train() # set to train mode\r\n",
        "    \r\n",
        "        # get batches of training image data and targets\r\n",
        "        for batch_i, (images, target) in enumerate(train_loader):\r\n",
        "\r\n",
        "            # reshape and get target class\r\n",
        "            target = torch.eye(10).index_select(dim=0, index=target)\r\n",
        "\r\n",
        "            if TRAIN_ON_GPU:\r\n",
        "                images, target = images.cuda(), target.cuda()\r\n",
        "                #images = images.to('cuda', non_blocking=True)\r\n",
        "                #target = target.to('cuda', non_blocking=True)\r\n",
        "            # zero out gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "            # get model outputs\r\n",
        "            caps_output, reconstructions, y = capsule_net(images)\r\n",
        "            # calculate loss\r\n",
        "            loss = criterion(caps_output, target, images, reconstructions)\r\n",
        "            # perform backpropagation and optimization\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            train_loss += loss.item() # accumulated training loss\r\n",
        "            \r\n",
        "            # print and record training stats\r\n",
        "            if batch_i != 0 and batch_i % print_every == 0:\r\n",
        "                avg_train_loss = train_loss/print_every\r\n",
        "                losses.append(avg_train_loss)\r\n",
        "                print('Epoch: {} \\tTraining Loss: {:.8f}'.format(epoch, avg_train_loss))\r\n",
        "                train_loss = 0 # reset accumulated training loss\r\n",
        "        \r\n",
        "    return losses"
      ],
      "outputs": [],
      "metadata": {
        "id": "V0rVHcOnxjE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "%%time\r\n",
        "# training for 3 epochs\r\n",
        "n_epochs = 500\r\n",
        "losses = train(capsule_net, criterion, optimizer, n_epochs=n_epochs)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16544/3325699662.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(capsule_net, criterion, optimizer, n_epochs, print_every)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# get model outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mcaps_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapsule_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;31m# calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaps_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16544/2990430258.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     15\u001b[0m            '''\n\u001b[0;32m     16\u001b[0m         \u001b[0mprimary_caps_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary_capsules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcaps_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigit_capsules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprimary_caps_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#print(caps_output.type(), caps_output.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mreconstructions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaps_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16544/3288317737.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, u)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# moving b_ij to GPU, if available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mTRAIN_ON_GPU\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mb_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_ij\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# update coupling coefficients and calculate v_j\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQs6bM2gxoCT",
        "outputId": "5b77a345-825f-4929-afac-2807074b2e59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "source": [
        "torch.save(capsule_net.state_dict(), './fmnist-params-500.pt')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def test(capsule_net, test_loader):\r\n",
        "    '''Prints out test statistics for a given capsule net.\r\n",
        "       param capsule_net: trained capsule network\r\n",
        "       param test_loader: test dataloader\r\n",
        "       return: returns last batch of test image data and corresponding reconstructions\r\n",
        "       '''\r\n",
        "    class_correct = list(0. for i in range(10))\r\n",
        "    class_total = list(0. for i in range(10))\r\n",
        "    \r\n",
        "    test_loss = 0 # loss tracking\r\n",
        "\r\n",
        "    capsule_net.eval() # eval mode\r\n",
        "\r\n",
        "    for batch_i, (images, target) in enumerate(test_loader):\r\n",
        "        target = torch.eye(10).index_select(dim=0, index=target)\r\n",
        "\r\n",
        "        batch_size = images.size(0)\r\n",
        "\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            images, target = images.cuda(), target.cuda()\r\n",
        "\r\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\r\n",
        "        caps_output, reconstructions, y = capsule_net(images)\r\n",
        "        # calculate the loss\r\n",
        "        loss = criterion(caps_output, target, images, reconstructions)\r\n",
        "        # update average test loss \r\n",
        "        test_loss += loss.item()\r\n",
        "        # convert output probabilities to predicted class\r\n",
        "        _, pred = torch.max(y.data.cpu(), 1)\r\n",
        "        _, target_shape = torch.max(target.data.cpu(), 1)\r\n",
        "\r\n",
        "        # compare predictions to true label\r\n",
        "        correct = np.squeeze(pred.eq(target_shape.data.view_as(pred)))\r\n",
        "        # calculate test accuracy for each object class\r\n",
        "        for i in range(batch_size):\r\n",
        "            label = target_shape.data[i]\r\n",
        "            class_correct[label] += correct[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "\r\n",
        "    # avg test loss\r\n",
        "    avg_test_loss = test_loss/len(test_loader)\r\n",
        "    print('Test Loss: {:.8f}\\n'.format(avg_test_loss))\r\n",
        "\r\n",
        "    for i in range(10):\r\n",
        "        if class_total[i] > 0:\r\n",
        "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\r\n",
        "                str(i), 100 * class_correct[i] / class_total[i],\r\n",
        "                np.sum(class_correct[i]), np.sum(class_total[i])))\r\n",
        "        else:\r\n",
        "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\r\n",
        "\r\n",
        "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\r\n",
        "        100. * np.sum(class_correct) / np.sum(class_total),\r\n",
        "        np.sum(class_correct), np.sum(class_total)))\r\n",
        "    \r\n",
        "    # return last batch of capsule vectors, images, reconstructions\r\n",
        "    return caps_output, images, reconstructions"
      ],
      "outputs": [],
      "metadata": {
        "id": "oR6Gu9yQyE_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "source": [
        "#load the model\r\n",
        "\r\n",
        "\r\n",
        "from torchsummary import summary\r\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device = torch.device('cpu')\r\n",
        "\r\n",
        "capsule_net = CapsuleNetwork().to(device)\r\n",
        "capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "\r\n",
        "\r\n",
        "pre_trained_dict = capsule_net.state_dict()\r\n",
        "weight_tensor = pre_trained_dict['digit_capsules.W']\r\n",
        "print(weight_tensor.size())\r\n",
        "#print(weight_tensor)\r\n",
        "\r\n",
        "print('none zero weights count: ', torch.count_nonzero(weight_tensor))\r\n",
        "print('number of all tensor cells: ', torch.numel(weight_tensor))\r\n",
        "\r\n",
        "#pre_trained_dict['primary_capsules.capsules.1.weight'] = torch.zeros(32, 256, 9, 9, dtype=torch.float)\r\n",
        "\r\n",
        "#conv_weights = a\r\n",
        "#print(a.size())\r\n",
        "#print(a)\r\n",
        "#print(pre_trained_dict['digit_capsules.W'])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#PRINTING NETWORK PARAMETERS\r\n",
        "#for name, param in capsule_net.named_parameters():\r\n",
        "#    if param.requires_grad:\r\n",
        "#        print(name, param.type())\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "capsule_net.eval()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1152, 8, 16])\n",
            "none zero weights count:  tensor(1474560)\n",
            "number of all tensor cells:  1474560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsuleNetwork(\n",
              "  (conv_layer): ConvLayer(\n",
              "    (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "  )\n",
              "  (primary_capsules): PrimaryCaps(\n",
              "    (capsules): ModuleList(\n",
              "      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "    )\n",
              "  )\n",
              "  (digit_capsules): DigitCaps()\n",
              "  (decoder): Decoder(\n",
              "    (linear_layers): Sequential(\n",
              "      (0): Linear(in_features=160, out_features=512, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Linear(in_features=1024, out_features=784, bias=True)\n",
              "      (5): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# call test function and get reconstructed images\r\n",
        "capsule_net.load_state_dict(torch.load('./fmnist-params-500.pt'))\r\n",
        "capsule_net.eval()\r\n",
        "caps_output, images, reconstructions = test(capsule_net, test_loader)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.13204497\n",
            "\n",
            "Test Accuracy of     0: 85% (856/1000)\n",
            "Test Accuracy of     1: 98% (980/1000)\n",
            "Test Accuracy of     2: 89% (890/1000)\n",
            "Test Accuracy of     3: 90% (909/1000)\n",
            "Test Accuracy of     4: 86% (864/1000)\n",
            "Test Accuracy of     5: 97% (978/1000)\n",
            "Test Accuracy of     6: 70% (704/1000)\n",
            "Test Accuracy of     7: 97% (975/1000)\n",
            "Test Accuracy of     8: 97% (977/1000)\n",
            "Test Accuracy of     9: 97% (973/1000)\n",
            "\n",
            "Test Accuracy (Overall): 91% (9106/10000)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clQUkYe81d3Q",
        "outputId": "2c167fd7-1ca2-4096-9349-ae86ff972989"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "torch.cuda.clear_memory_allocated()  # entirely clear all allocated memory\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch.cuda' has no attribute 'clear_memory_allocated'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-25-05a9f0efd1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_memory_allocated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# entirely clear all allocated memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'clear_memory_allocated'"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "from utils import float2bit\r\n",
        "from utils import bit2float\r\n",
        "import math\r\n",
        "\r\n",
        "#capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "\r\n",
        "#capsule_net.eval()\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "#state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "\r\n",
        "#print(state_dict['digit_capsules.W'][0, 0, 0, 0], '\\n')\r\n",
        "\r\n",
        "\r\n",
        "#binary_tensor = float2bit(state_dict['digit_capsules.W'], num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,)).size(), '\\n')\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,))[0].item(), '\\n')\r\n",
        "\r\n",
        "#torch.reshape(binary_tensor, (-1,))[0] = float(0)\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,))[0].item(), '\\n')\r\n",
        "\r\n",
        "#print(type(torch.reshape(binary_tensor, (-1,))[47185919].item()), '\\n')\r\n",
        "\r\n",
        "\r\n",
        "# validity test  ###############################################\r\n",
        "\r\n",
        "#for i in range (1, 9):\r\n",
        "    #torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index].item()\r\n",
        " #   binary_tensor[0, 0, 0, 0][i] = float(1)\r\n",
        "\r\n",
        "#for i in range (9, 32):\r\n",
        "#    binary_tensor[0, 0, 0, 0][i] = float(0)\r\n",
        "\r\n",
        "\r\n",
        "#print((binary_tensor[0, 0, 0, 0]), '\\n')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#float_tensor = bit2float(binary_tensor, num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "#print(math.isfinite(float_tensor[0, 0, 0, 0]))\r\n",
        "\r\n",
        "\r\n",
        "#print(float_tensor[0, 0, 0, 0])\r\n",
        "\r\n",
        "##################################################################\r\n",
        "\r\n",
        "\r\n",
        "## Fault injection ###############################################\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "number_of_bit_flips = 1000000\r\n",
        "\r\n",
        "exponential_fault_growth = 1\r\n",
        "\r\n",
        "while exponential_fault_growth < 47185919:\r\n",
        "\r\n",
        "    capsule_net.load_state_dict(torch.load('./f-mnist.pt'))\r\n",
        "\r\n",
        "    capsule_net.eval()\r\n",
        "\r\n",
        "    state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "    binary_tensor = float2bit(state_dict['digit_capsules.W'], num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "\r\n",
        "    for i in range (exponential_fault_growth):\r\n",
        "\r\n",
        "        random_bit_number = random.randint(0, 47185919)  \r\n",
        "\r\n",
        "        if( torch.reshape(binary_tensor, (-1,))[random_bit_number] == float(0) ):\r\n",
        "\r\n",
        "            torch.reshape(binary_tensor, (-1,))[random_bit_number] = float(1)\r\n",
        "\r\n",
        "        if( torch.reshape(binary_tensor, (-1,))[random_bit_number] == float(1) ):\r\n",
        "\r\n",
        "         torch.reshape(binary_tensor, (-1,))[random_bit_number] = float(0)\r\n",
        "\r\n",
        "    print(\"Number of Faults Injected: \", exponential_fault_growth, '\\n')\r\n",
        "\r\n",
        "    exponential_fault_growth = exponential_fault_growth*2 \r\n",
        "\r\n",
        "    float_tensor = bit2float(binary_tensor, num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "    for i in range (1474560):\r\n",
        "        if (math.isfinite(torch.reshape(float_tensor, (-1,))[i]) == False):\r\n",
        "         print(\"EROOOOOOOOOOOOOOOOOR\")\r\n",
        "\r\n",
        "    state_dict['digit_capsules.W'] = float_tensor\r\n",
        "    capsule_net.load_state_dict(state_dict)\r\n",
        "    capsule_net.eval()\r\n",
        "    caps_output, images, reconstructions = test(capsule_net, test_loader)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    print(\"*************************************************************************\", '\\n')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Faults Injected:  1 \n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "a = np.zeros((3, 3))\r\n",
        "print (a)\r\n",
        "\r\n",
        "iterator = 47185919\r\n",
        "i = 1\r\n",
        "while i < iterator:\r\n",
        "    print(i)\r\n",
        "    i *= 2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "1\n",
            "2\n",
            "4\n",
            "8\n",
            "16\n",
            "32\n",
            "64\n",
            "128\n",
            "256\n",
            "512\n",
            "1024\n",
            "2048\n",
            "4096\n",
            "8192\n",
            "16384\n",
            "32768\n",
            "65536\n",
            "131072\n",
            "262144\n",
            "524288\n",
            "1048576\n",
            "2097152\n",
            "4194304\n",
            "8388608\n",
            "16777216\n",
            "33554432\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "# Firstly, we get the model stats and parameters: \r\n",
        "\r\n",
        "#from torchsummary import summary\r\n",
        "#from time import sleep\r\n",
        "\r\n",
        "capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "capsule_net.eval()\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "original_parameters = capsule_net.state_dict()\r\n",
        "\r\n",
        "#print('The weight tensor size is:', state_dict['digit_capsules.W'].size(), state_dict['digit_capsules.W'].dtype, '\\n')\r\n",
        "\r\n",
        "#print('Number zero weights count: ', torch.count_nonzero(weight_tensor), '\\n')\r\n",
        "\r\n",
        "#print('Number of all tensor cells: ', torch.numel(weight_tensor), '\\n')\r\n",
        "\r\n",
        "#print('Number of total bits in the weight tensor: ', f\"{torch.numel(weight_tensor)*32:,}\", 'bits', '\\n' )\r\n",
        "\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "\r\n",
        "count = 0\r\n",
        "for i in range (1000):\r\n",
        "    #w_index = random.randint(0,9)\r\n",
        "    #x_index = random.randint(0,1151)\r\n",
        "    #y_index = random.randint(0,7)\r\n",
        "    #z_index = random.randint(0,15)\r\n",
        "    random_tensor_index = random.randint(0,1474559)\r\n",
        "    \r\n",
        "    tensor_cell = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index].item()\r\n",
        "\r\n",
        "    #tensor_cell = state_dict['digit_capsules.W'][w_index, x_index, y_index, z_index].item()\r\n",
        "\r\n",
        "    #print('The random selected weight at:', random_tensor_index, ' value:', type(tensor_cell), tensor_cell, '\\n')\r\n",
        "\r\n",
        "    temp = float_to_bin(tensor_cell)\r\n",
        "\r\n",
        "    #print('The random selected weight value in bits:', temp, type(temp), '\\n')\r\n",
        "\r\n",
        "    #print('Reversion check: ', bin_to_float(temp), type(bin_to_float(temp)), '\\n')\r\n",
        "\r\n",
        "    #for j in range (32):\r\n",
        "    random_bit_location = random.randint(0, 31)\r\n",
        "\r\n",
        "    #print('The selected bit is located at bit:', random_bit_location, '-  Value is:', temp[random_bit_location], '\\n')\r\n",
        "\r\n",
        "    editable_string = list(temp)\r\n",
        "        \r\n",
        "    if ( temp[random_bit_location] == '0' ):\r\n",
        "        editable_string[random_bit_location] = '1'\r\n",
        "    if ( temp[random_bit_location] == '1' ):\r\n",
        "        editable_string[random_bit_location] = '0'\r\n",
        "\r\n",
        "    final_bit_string = ''.join(editable_string)\r\n",
        "    \r\n",
        "    #print('The random selected weight value after bit flip: ', final_bit_string, '\\n')\r\n",
        "\r\n",
        "    final_tensor_value = float(bin_to_float(final_bit_string))\r\n",
        "    if (math.isfinite(final_tensor_value) == True):\r\n",
        "        print(final_tensor_value)\r\n",
        "        torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index] = final_tensor_value\r\n",
        "    #print('The random selected weight value after bit flip in float format', final_tensor_value, '\\n')\r\n",
        "    #print(final_tensor_value)\r\n",
        "    #torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index] = tensor_cell\r\n",
        "\r\n",
        "    #state_dict['digit_capsules.W'][w_index, x_index, y_index, z_index] = final_tensor_value\r\n",
        "    #sleep(0.5) # Time in seconds\r\n",
        "    #Loading updated faulty cell back into the model's tensor\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "capsule_net.load_state_dict(state_dict)\r\n",
        "\r\n",
        "capsule_net.eval()\r\n",
        "caps_output, images, reconstructions = test(capsule_net, test_loader)\r\n",
        "\r\n",
        "  #capsule_net.load_state_dict(original_parameters)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4686159233168183e-10\n",
            "0.834665060043335\n",
            "0.5738019347190857\n",
            "-1.693809151649475\n",
            "-0.41687431931495667\n",
            "0.2846231460571289\n",
            "2.9128847122192383\n",
            "-1.701809287071228\n",
            "-1.883732795715332\n",
            "-1.882802963256836\n",
            "-1.242649793624878\n",
            "0.4774663746356964\n",
            "-2.2517949673783733e-06\n",
            "-0.6633909940719604\n",
            "-2.206758213663118e-11\n",
            "0.8108271360397339\n",
            "-1.0668209791183472\n",
            "1.2507662773132324\n",
            "1.216475248336792\n",
            "-1.3265883922576904\n",
            "0.6387655138969421\n",
            "-0.5887660980224609\n",
            "-1.749934434890747\n",
            "-0.9858512878417969\n",
            "2.1767120361328125\n",
            "0.15294647216796875\n",
            "0.917176365852356\n",
            "-0.02032366581261158\n",
            "-2.719259023666382\n",
            "1.879441499710083\n",
            "-0.4128277003765106\n",
            "-0.005330312997102737\n",
            "-1.2635740041732788\n",
            "0.5676394104957581\n",
            "0.507246732711792\n",
            "-1.6011048555374146\n",
            "-0.6115731000900269\n",
            "2.5539393424987793\n",
            "-2.1078776977811712e-20\n",
            "-0.253911554813385\n",
            "-1.4313610792160034\n",
            "1.2210946083068848\n",
            "0.017640158534049988\n",
            "0.4377450942993164\n",
            "-133244.515625\n",
            "-1.9117329120635986\n",
            "0.9317785501480103\n",
            "-0.9319571852684021\n",
            "1.1800907850265503\n",
            "0.8817236423492432\n",
            "-0.7435846328735352\n",
            "1.5438811779022217\n",
            "2.6254636395606212e-05\n",
            "3.484430105560321e-11\n",
            "0.9726134538650513\n",
            "1.3914414644241333\n",
            "1.3324943780899048\n",
            "0.5213566422462463\n",
            "0.719071090221405\n",
            "1.0101265907287598\n",
            "-1.0810775756835938\n",
            "-1.4372932011230688e-10\n",
            "-0.26918286085128784\n",
            "0.7731052041053772\n",
            "-1.9157376289367676\n",
            "-0.9160729050636292\n",
            "0.010866982862353325\n",
            "0.2903173565864563\n",
            "0.6743772625923157\n",
            "-1.7510709688110774e-39\n",
            "0.042918626219034195\n",
            "-1.7962607145309448\n",
            "0.0848298966884613\n",
            "-0.19825361669063568\n",
            "0.468648225069046\n",
            "0.16354069113731384\n",
            "1.2804242032871116e-05\n",
            "-0.9761194586753845\n",
            "1.0701396465301514\n",
            "0.8084775805473328\n",
            "0.8811667561531067\n",
            "-0.45346084237098694\n",
            "-1.683354377746582\n",
            "-0.3289971947669983\n",
            "-0.9947959184646606\n",
            "-1.6774089336395264\n",
            "-0.954123318195343\n",
            "0.14042404294013977\n",
            "-1.030930519104004\n",
            "0.22646357119083405\n",
            "1.7541496753692627\n",
            "1.2858377695083618\n",
            "-0.49207374453544617\n",
            "0.31067970395088196\n",
            "-0.03361629322171211\n",
            "6.105540251155617e-06\n",
            "-1.8566800874530998e-10\n",
            "0.25930678844451904\n",
            "-1.0197993516921997\n",
            "1.0448977947235107\n",
            "0.4139902889728546\n",
            "-0.6922740936279297\n",
            "0.4368283748626709\n",
            "3.750113364731078e-06\n",
            "0.02513423189520836\n",
            "2.4119374752044678\n",
            "-1.0643584728240967\n",
            "1.584800362586975\n",
            "2.144094228744507\n",
            "1.9139890670776367\n",
            "0.5221424102783203\n",
            "0.30638715624809265\n",
            "-2.589099168777466\n",
            "-1.2892496585845947\n",
            "-0.5917124152183533\n",
            "-0.5547288656234741\n",
            "3.8909684210396513e-20\n",
            "2.1184511184692383\n",
            "-5.94352536545896e+37\n",
            "-1.2110670804977417\n",
            "0.9669520258903503\n",
            "-0.36522147059440613\n",
            "0.12066303193569183\n",
            "0.3031651973724365\n",
            "0.8337497115135193\n",
            "-0.41293731331825256\n",
            "0.4754016697406769\n",
            "-1.0155391693115234\n",
            "0.14479902386665344\n",
            "-0.35455045104026794\n",
            "2.0424253940582275\n",
            "0.3577902913093567\n",
            "4.645964923567783e-21\n",
            "1.3377056121826172\n",
            "-0.5917028188705444\n",
            "1.6250352452562566e-10\n",
            "-35.354061126708984\n",
            "-2.2217113971710205\n",
            "0.6193358898162842\n",
            "0.38018760085105896\n",
            "1.0587612390518188\n",
            "0.002884871792048216\n",
            "-0.9264162182807922\n",
            "0.8693826198577881\n",
            "-0.8401562571525574\n",
            "0.974292516708374\n",
            "1.9042168855667114\n",
            "-0.18528519570827484\n",
            "-1.6972236633300781\n",
            "-0.8633507490158081\n",
            "0.5551627278327942\n",
            "-0.28858089447021484\n",
            "-0.8277394771575928\n",
            "-0.10224851965904236\n",
            "1.3878391981124878\n",
            "0.5821751356124878\n",
            "-1.8155256509780884\n",
            "-1.323249340057373\n",
            "0.04172810539603233\n",
            "-0.8932791948318481\n",
            "0.004499554634094238\n",
            "-0.6000108122825623\n",
            "-1.7044416666030884\n",
            "-0.807467520236969\n",
            "-1.703308214473509e-07\n",
            "-0.3322228491306305\n",
            "-1.6511976718902588\n",
            "-0.390096515417099\n",
            "2.7056651106249774e-06\n",
            "-0.6989789605140686\n",
            "-0.43739205598831177\n",
            "-1.015499234199524\n",
            "1.3189797401428223\n",
            "-0.6223021745681763\n",
            "-8.131742652039975e-05\n",
            "-2.346341371536255\n",
            "0.24938789010047913\n",
            "-0.08127807825803757\n",
            "-0.23928411304950714\n",
            "-0.7919719815254211\n",
            "-1.70927095413208\n",
            "0.2541791796684265\n",
            "0.003381691174581647\n",
            "-0.1702393889427185\n",
            "-0.6089335680007935\n",
            "0.017799226567149162\n",
            "1.4989367374235773e-39\n",
            "0.3643868565559387\n",
            "-0.9066692590713501\n",
            "-0.11716707050800323\n",
            "-0.8353261351585388\n",
            "1.3855124711990356\n",
            "-1.0747963190078735\n",
            "1.1854987144470215\n",
            "-1.117087960243225\n",
            "0.4451195001602173\n",
            "-2.245396137237549\n",
            "1.1885100603103638\n",
            "-6.868445748720049e-20\n",
            "-0.9508264064788818\n",
            "0.20551452040672302\n",
            "-0.5114886164665222\n",
            "-0.9773648977279663\n",
            "-0.7437756657600403\n",
            "-0.4415357708930969\n",
            "2.6816757148218073e-10\n",
            "1.2035717964172363\n",
            "0.34657609462738037\n",
            "-3.086637889726518e-10\n",
            "-1.037224776041028e-19\n",
            "-0.29698389768600464\n",
            "4.9541003646188695e-20\n",
            "-3.2060634702624213e-10\n",
            "0.6154928207397461\n",
            "1.5642354488372803\n",
            "2.5235355774694765e+38\n",
            "-0.019330495968461037\n",
            "-0.43982136249542236\n",
            "-0.9775928854942322\n",
            "0.005636771209537983\n",
            "1.3564692380896304e-05\n",
            "1.0744022130966187\n",
            "-0.001954694977030158\n",
            "-1.4317342042922974\n",
            "0.7443146705627441\n",
            "-0.17749656736850739\n",
            "1.4200375080108643\n",
            "1.006862759590149\n",
            "-0.7138078808784485\n",
            "9.73116343983265e+37\n",
            "0.21308274567127228\n",
            "-0.513723611831665\n",
            "0.6493567228317261\n",
            "2.833781838113158e-20\n",
            "-0.3460668921470642\n",
            "-0.043447233736515045\n",
            "-0.009000963531434536\n",
            "-1.0063111782073975\n",
            "0.8107517957687378\n",
            "-592.738525390625\n",
            "-0.006930537987500429\n",
            "-0.1471812129020691\n",
            "-0.8619325757026672\n",
            "-3.902050139004132e-06\n",
            "8.167274245352019e-06\n",
            "-0.39815548062324524\n",
            "0.5186880826950073\n",
            "-1.0326660871505737\n",
            "1.1221884489059448\n",
            "-4.07658576965332\n",
            "-0.4092337489128113\n",
            "-0.3957515060901642\n",
            "-1.0969721415676759e-06\n",
            "0.7875362038612366\n",
            "0.03198273479938507\n",
            "0.0027293344028294086\n",
            "7.943792661942489e-21\n",
            "0.48204657435417175\n",
            "-1.9688763618469238\n",
            "0.497273325920105\n",
            "-0.0005487538292072713\n",
            "0.10751055926084518\n",
            "0.10715384781360626\n",
            "-0.9353960156440735\n",
            "1.0466349124908447\n",
            "0.4314919114112854\n",
            "-1.0884590148925781\n",
            "-0.47465312480926514\n",
            "-0.8180596232414246\n",
            "-0.0006938294973224401\n",
            "-0.4980018734931946\n",
            "-4.102548597072748e+37\n",
            "-0.750801146030426\n",
            "-0.887513279914856\n",
            "-1.806392788887024\n",
            "1.7067537307739258\n",
            "0.7952156066894531\n",
            "0.5720251798629761\n",
            "523.5570678710938\n",
            "1.0899735689163208\n",
            "1.2187950611114502\n",
            "0.5194019675254822\n",
            "0.6346311569213867\n",
            "2.269906520843506\n",
            "-0.1865512728691101\n",
            "0.5720552206039429\n",
            "0.03758171200752258\n",
            "-0.7427316904067993\n",
            "0.182453915476799\n",
            "-0.6905132532119751\n",
            "-1.0971142053604126\n",
            "1.8531630039215088\n",
            "1.047745943069458\n",
            "-0.3470299541950226\n",
            "0.4806642234325409\n",
            "-1.0420526266098022\n",
            "-1.0086259841918945\n",
            "-1.1107890605926514\n",
            "0.06474687904119492\n",
            "-1.3264482021331787\n",
            "-0.006133189424872398\n",
            "-0.5502089858055115\n",
            "0.888293445110321\n",
            "0.0808291882276535\n",
            "0.7305206656455994\n",
            "-1.65194571018219\n",
            "0.7792297005653381\n",
            "1.0637773275375366\n",
            "-0.0018108469666913152\n",
            "-1.1227507591247559\n",
            "0.7242144346237183\n",
            "-0.6674734354019165\n",
            "-0.6106880307197571\n",
            "0.18990759551525116\n",
            "-2.499363493946305e-10\n",
            "-0.28255632519721985\n",
            "0.6111130714416504\n",
            "-0.48703500628471375\n",
            "-0.4023268520832062\n",
            "0.879883885383606\n",
            "0.5233659744262695\n",
            "-0.3123834431171417\n",
            "-0.15791383385658264\n",
            "-0.007590364199131727\n",
            "-0.03641992062330246\n",
            "-1.2340123653411865\n",
            "0.9836534261703491\n",
            "0.5093742609024048\n",
            "-0.32582521438598633\n",
            "0.2640095353126526\n",
            "2.384028434753418\n",
            "0.3597756028175354\n",
            "1.3102110624313354\n",
            "0.8300571441650391\n",
            "-0.5111739635467529\n",
            "0.09892674535512924\n",
            "0.2511114180088043\n",
            "0.0035737226717174053\n",
            "0.09933114051818848\n",
            "1.4217075109481812\n",
            "32.45317459106445\n",
            "0.07750067859888077\n",
            "0.45106980204582214\n",
            "-0.673812210559845\n",
            "0.3424679934978485\n",
            "1.3140971660614014\n",
            "-0.17615137994289398\n",
            "0.3571084141731262\n",
            "-0.8477128148078918\n",
            "-2.0890533924102783\n",
            "-0.3236824572086334\n",
            "1.073792815208435\n",
            "0.6458468437194824\n",
            "-0.32888278365135193\n",
            "0.551957905292511\n",
            "7.717693733866327e-06\n",
            "-0.18730714917182922\n",
            "-1.1357406377792358\n",
            "0.23045960068702698\n",
            "0.05761972814798355\n",
            "-0.2589874863624573\n",
            "0.3227309286594391\n",
            "1.846287869459e+38\n",
            "-0.2557549476623535\n",
            "0.8896061182022095\n",
            "0.0015280661173164845\n",
            "0.6238054633140564\n",
            "0.7120837569236755\n",
            "1.1949108738917857e-05\n",
            "0.3589235842227936\n",
            "-0.5516353249549866\n",
            "-0.3487367331981659\n",
            "-0.467319518327713\n",
            "0.2789309322834015\n",
            "4.186532978601919e-20\n",
            "2.977892210456381e-20\n",
            "1.3103525638580322\n",
            "0.4055556058883667\n",
            "-0.06377390027046204\n",
            "-2.3072397708892822\n",
            "0.7534986734390259\n",
            "1.4566410779953003\n",
            "-1.2018382549285889\n",
            "1.2813533544540405\n",
            "-0.22969911992549896\n",
            "-2.5340094137888022e+38\n",
            "0.3291414678096771\n",
            "1.4347666501998901\n",
            "-1.2394353689160198e-05\n",
            "-1.4316707849502563\n",
            "-0.34850791096687317\n",
            "1.4631770849227905\n",
            "1.1299564838409424\n",
            "-0.9751867651939392\n",
            "0.15634489059448242\n",
            "1.705539584159851\n",
            "1.5543040037155151\n",
            "1.6595269441604614\n",
            "-1.420946478843689\n",
            "-0.00278459582477808\n",
            "-0.7337605953216553\n",
            "0.14911463856697083\n",
            "0.16162453591823578\n",
            "0.1351391226053238\n",
            "1.4047417640686035\n",
            "0.823900043964386\n",
            "-0.6420522928237915\n",
            "0.0014377619372680783\n",
            "0.5357489585876465\n",
            "-0.9343762397766113\n",
            "-0.6101953983306885\n",
            "-1.8552977975121701e+37\n",
            "-0.5794407725334167\n",
            "0.45263782143592834\n",
            "-0.9088109731674194\n",
            "0.18357881903648376\n",
            "2.1656248569488525\n",
            "-0.35395532846450806\n",
            "-3.1066055283801575e-10\n",
            "0.6366688013076782\n",
            "0.00032535468926653266\n",
            "-0.23251159489154816\n",
            "-0.170311838388443\n",
            "-2.398122787475586\n",
            "1.2521320581436157\n",
            "-0.9433920383453369\n",
            "-7.80575465375577e-11\n",
            "0.6343982219696045\n",
            "-0.03749839961528778\n",
            "0.5665416121482849\n",
            "1.7668406569210162e+38\n",
            "-3.600482623191488e-20\n",
            "-1.0296374559402466\n",
            "-0.1282142996788025\n",
            "-0.3514537811279297\n",
            "-1.0839943885803223\n",
            "0.6714889407157898\n",
            "1.4619544744491577\n",
            "0.9856173396110535\n",
            "-0.0020594955421984196\n",
            "-0.6993867754936218\n",
            "0.49895989894866943\n",
            "-2.945445294102906e-39\n",
            "0.12068038433790207\n",
            "-3.971023510022159e-21\n",
            "1.0535287857055664\n",
            "-2.3106384861026896e-10\n",
            "-0.8497896194458008\n",
            "3.627569557078332e-20\n",
            "-0.5639558434486389\n",
            "1.2601047274074517e-05\n",
            "0.6274288296699524\n",
            "0.05515814200043678\n",
            "1.1060129404067993\n",
            "1.930490493774414\n",
            "-0.08636806905269623\n",
            "-0.6281771659851074\n",
            "-0.15138721466064453\n",
            "-0.039213698357343674\n",
            "0.12484728544950485\n",
            "-0.6797389388084412\n",
            "1.0556626319885254\n",
            "-1.8623811548505163e-20\n",
            "0.5564934015274048\n",
            "1.07753586769104\n",
            "0.7976519465446472\n",
            "-1.8585687939776108e-05\n",
            "-2.269204742333386e-06\n",
            "0.2711344063282013\n",
            "1.1560770273208618\n",
            "1.238933801651001\n",
            "-0.29206615686416626\n",
            "0.9431819319725037\n",
            "0.2252240628004074\n",
            "0.25060850381851196\n",
            "-0.33885738253593445\n",
            "-0.019633175805211067\n",
            "-1.3946985006332397\n",
            "1.3989288806915283\n",
            "-6.691893038508497e+37\n",
            "-0.44161105155944824\n",
            "-0.32244688272476196\n",
            "-0.9377541542053223\n",
            "-0.2565048933029175\n",
            "-0.33461764454841614\n",
            "0.0034492090344429016\n",
            "-0.16779348254203796\n",
            "-0.049682844430208206\n",
            "0.329950749874115\n",
            "-0.08140018582344055\n",
            "1.8334239682005204e-10\n",
            "0.6568456292152405\n",
            "0.990310549736023\n",
            "0.14270880818367004\n",
            "-5.7576830840844195e-06\n",
            "1.3865727186203003\n",
            "-0.2856159508228302\n",
            "-7.963981200326324e-20\n",
            "0.6528197526931763\n",
            "-1.4221971035003662\n",
            "-0.3249015510082245\n",
            "-1.5716572999954224\n",
            "-0.012014125473797321\n",
            "0.5979969501495361\n",
            "-0.31162670254707336\n",
            "-1.0083268880844116\n",
            "-1.6128671169281006\n",
            "-1.6972471475601196\n",
            "0.22317686676979065\n",
            "0.5088365077972412\n",
            "-6.234598571070831e-20\n",
            "0.5108502507209778\n",
            "1.014656901359558\n",
            "1.0329625606536865\n",
            "-1.5109323263168335\n",
            "-0.2116556316614151\n",
            "-0.34061938524246216\n",
            "0.19499894976615906\n",
            "-0.10180419683456421\n",
            "-0.0049613844603300095\n",
            "-0.7475864887237549\n",
            "2.3208162784576416\n",
            "-0.10954815149307251\n",
            "2.734876871109009\n",
            "-3.3220516903015785e-20\n",
            "0.17798109352588654\n",
            "0.7156996130943298\n",
            "1.5942625999450684\n",
            "0.49280980229377747\n",
            "0.4551524221897125\n",
            "0.1241781935095787\n",
            "0.8736764192581177\n",
            "-0.5282785892486572\n",
            "-0.8075979948043823\n",
            "-2.026723363312763e-20\n",
            "0.1809314638376236\n",
            "-1.8700782220548717e-06\n",
            "-1.351939082145691\n",
            "-1.180260005639866e-05\n",
            "0.013191615231335163\n",
            "-0.19408418238162994\n",
            "-0.9651568531990051\n",
            "0.0033272849395871162\n",
            "0.8010114431381226\n",
            "0.6042752861976624\n",
            "0.2801760137081146\n",
            "0.37987619638442993\n",
            "-0.8532294034957886\n",
            "0.3067111670970917\n",
            "0.42748403549194336\n",
            "0.860537052154541\n",
            "-1.3080674592574741e+38\n",
            "0.3862946331501007\n",
            "0.10668989270925522\n",
            "0.4866192638874054\n",
            "144484.5\n",
            "-0.0011386588448658586\n",
            "0.4921724200248718\n",
            "-0.5549749135971069\n",
            "0.09223780035972595\n",
            "6.693629529763712e-06\n",
            "-0.6446689367294312\n",
            "1.4593141078948975\n",
            "-0.002095063216984272\n",
            "-1.2410534620285034\n",
            "0.6367480754852295\n",
            "0.055417392402887344\n",
            "-1.1198161840438843\n",
            "0.00018453208031132817\n",
            "-1.1885204315185547\n",
            "-0.47937145829200745\n",
            "0.05586840584874153\n",
            "0.3535597324371338\n",
            "0.009097538888454437\n",
            "1.8032618761062622\n",
            "0.03188895061612129\n",
            "0.6719167232513428\n",
            "0.9146711230278015\n",
            "-1.3555139303207397\n",
            "1.7558001279830933\n",
            "2.1822545022587292e-05\n",
            "-0.9426141381263733\n",
            "0.15998093783855438\n",
            "1.6841042041778564\n",
            "-3.809186107852299e-21\n",
            "-2.5386719341084897e+38\n",
            "0.5577998161315918\n",
            "-0.8475815057754517\n",
            "0.12098240107297897\n",
            "1.1281707286834717\n",
            "1.8919851779937744\n",
            "0.34900760650634766\n",
            "1.8560596704483032\n",
            "0.3549371659755707\n",
            "1.1208232641220093\n",
            "-0.5830531716346741\n",
            "-6.040238430543432e-21\n",
            "-9.065136835628707e-11\n",
            "-1.213671088218689\n",
            "0.4044022262096405\n",
            "0.5619724988937378\n",
            "0.13924884796142578\n",
            "1.108005404472351\n",
            "0.4352618455886841\n",
            "0.5976231098175049\n",
            "1.605566143989563\n",
            "1.4290539026260376\n",
            "-1.352825403213501\n",
            "-0.06656190752983093\n",
            "2.984752655029297\n",
            "-0.6166201233863831\n",
            "0.08590589463710785\n",
            "0.001179429586045444\n",
            "-0.49715447425842285\n",
            "-0.05658990144729614\n",
            "0.33866384625434875\n",
            "0.30503135919570923\n",
            "2.412153720855713\n",
            "0.09724146127700806\n",
            "-1.0488232374191284\n",
            "-0.8128167986869812\n",
            "-0.22023360431194305\n",
            "0.02397467941045761\n",
            "-0.304423063993454\n",
            "-1.4631372690200806\n",
            "-1.3780293464660645\n",
            "-0.5834354758262634\n",
            "0.719691812992096\n",
            "-0.42673519253730774\n",
            "-1.5808199644088745\n",
            "-0.4235641658306122\n",
            "0.6045337915420532\n",
            "0.16582021117210388\n",
            "-0.8061034679412842\n",
            "-1.0617635780363344e-05\n",
            "0.5217661261558533\n",
            "0.9553350806236267\n",
            "1.866494448203746e+37\n",
            "1.4504576921463013\n",
            "0.7139036655426025\n",
            "-0.46774235367774963\n",
            "-1.013526439666748\n",
            "-0.7523808479309082\n",
            "0.08197805285453796\n",
            "-0.6059373021125793\n",
            "0.7413756251335144\n",
            "8.755607268540189e-06\n",
            "0.17395921051502228\n",
            "0.6989824175834656\n",
            "0.6941137909889221\n",
            "0.44646352529525757\n",
            "-0.823075532913208\n",
            "1.2342848777770996\n",
            "-1.3341764211654663\n",
            "-4.798820555151906e-06\n",
            "-1.1192500591278076\n",
            "0.23004880547523499\n",
            "-0.10006017982959747\n",
            "1.8057500123977661\n",
            "1.1436585187911987\n",
            "0.6785757541656494\n",
            "-1.157083511352539\n",
            "0.42411673069000244\n",
            "-1.5986690521240234\n",
            "0.29503950476646423\n",
            "-0.5304545760154724\n",
            "-0.7642516493797302\n",
            "-0.6864187717437744\n",
            "-0.20678886771202087\n",
            "-1.0929069519042969\n",
            "0.23703354597091675\n",
            "1.2361197471618652\n",
            "1.1277662515640259\n",
            "0.9277767539024353\n",
            "-0.7153984904289246\n",
            "0.5229526162147522\n",
            "-0.6468824148178101\n",
            "-0.00015312824689317495\n",
            "-1.2287709712982178\n",
            "0.5956134796142578\n",
            "0.6208051443099976\n",
            "0.6843899488449097\n",
            "0.03158707171678543\n",
            "-0.27276456356048584\n",
            "0.1915295124053955\n",
            "0.4460350573062897\n",
            "1.2931216955184937\n",
            "0.6146524548530579\n",
            "6.937474206214489e-11\n",
            "-2.5666338498986363e-10\n",
            "2.5109286070801318e-05\n",
            "-1.0558099746704102\n",
            "-0.13707175850868225\n",
            "3.2538130651573726e+38\n",
            "-0.7834902405738831\n",
            "1.0941338539123535\n",
            "1.274174690246582\n",
            "3.5889291763305664\n",
            "0.04160020872950554\n",
            "0.19294096529483795\n",
            "-1.688028335571289\n",
            "0.6732358336448669\n",
            "-0.7241448760032654\n",
            "-0.47708597779273987\n",
            "0.004771657753735781\n",
            "-2.520784414539179e-10\n",
            "0.05450300872325897\n",
            "-1.2265111207962036\n",
            "-0.30363619327545166\n",
            "-0.22835871577262878\n",
            "-8.356125556752694e-20\n",
            "-0.5986056327819824\n",
            "-2.2270379066467285\n",
            "0.35901448130607605\n",
            "0.5642114877700806\n",
            "-0.14934857189655304\n",
            "-0.9723511934280396\n",
            "-0.3967423141002655\n",
            "3.720519529584709e+19\n",
            "-5.439304693426474e+19\n",
            "0.00014896976063027978\n",
            "-0.9163310527801514\n",
            "0.014401698485016823\n",
            "-2.945414062303737e-20\n",
            "-0.05024956911802292\n",
            "1.4354662895202637\n",
            "-3.435789153183322e-10\n",
            "-1.0694760084152222\n",
            "-0.6787449717521667\n",
            "-3.697552264370074e-10\n",
            "0.0026493454352021217\n",
            "0.04126764461398125\n",
            "-0.049899082630872726\n",
            "-6.989836947468575e-06\n",
            "2.0541234016418457\n",
            "-4.479230042431226e-10\n",
            "1.9812814208803383e-20\n",
            "-0.5538896918296814\n",
            "0.14511990547180176\n",
            "0.1508617103099823\n",
            "-0.4437028467655182\n",
            "-0.2566363215446472\n",
            "0.11726072430610657\n",
            "1.9966336488723755\n",
            "1.2350127696990967\n",
            "-0.14277943968772888\n",
            "0.9405947327613831\n",
            "-3.902986127493825e-20\n",
            "2.6068133593071252e-05\n",
            "0.2091098129749298\n",
            "-0.4122177064418793\n",
            "0.1523950845003128\n",
            "-0.36033400893211365\n",
            "0.0025329224299639463\n",
            "0.0013309462228789926\n",
            "0.8179567456245422\n",
            "-0.0008241388713940978\n",
            "0.3388943076133728\n",
            "-0.813647985458374\n",
            "1.254373550415039\n",
            "1.820099019354669e+38\n",
            "0.07418734580278397\n",
            "-0.8304651379585266\n",
            "3.536177928253892e-06\n",
            "-0.21645119786262512\n",
            "0.06090555340051651\n",
            "-0.49922648072242737\n",
            "2.3514515521342783e+37\n",
            "0.09586737304925919\n",
            "0.2624558210372925\n",
            "-0.09868364781141281\n",
            "0.7577983140945435\n",
            "0.9624279141426086\n",
            "1.7303810119628906\n",
            "1.3689306797459722e-05\n",
            "8.504930179072155e-20\n",
            "0.0018464750610291958\n",
            "0.5718150734901428\n",
            "-1.7311358451843262\n",
            "1.4572720527648926\n",
            "-4.276883125305176\n",
            "-1.1981327533721924\n",
            "-1.121421217918396\n",
            "-0.20390330255031586\n",
            "-0.07697831839323044\n",
            "-5.5836003411968704e-06\n",
            "-2.0423078536987305\n",
            "-0.8564971685409546\n",
            "0.556735634803772\n",
            "-0.1309584230184555\n",
            "1.197428584098816\n",
            "8.87501960569147e+37\n",
            "0.9690663814544678\n",
            "-0.8777447938919067\n",
            "0.8814632296562195\n",
            "0.6567468047142029\n",
            "0.8576207160949707\n",
            "-1.1507550477981567\n",
            "2.5915655838177097e-39\n",
            "-1.0927600860595703\n",
            "-0.6051408052444458\n",
            "0.8542035818099976\n",
            "2.4771461539785378e-05\n",
            "-1.2956198453903198\n",
            "1.4807615280151367\n",
            "-0.32540467381477356\n",
            "0.5837357044219971\n",
            "-0.18479304015636444\n",
            "0.23104970157146454\n",
            "0.3015943169593811\n",
            "-4.416042694528007e+35\n",
            "-0.9193313121795654\n",
            "0.3054135739803314\n",
            "1.7345755100250244\n",
            "-0.3441874086856842\n",
            "-1.2512834072113037\n",
            "-2.9766526222229004\n",
            "-0.4826831817626953\n",
            "-2.941398035806307e-20\n",
            "-0.28208717703819275\n",
            "0.3745238780975342\n",
            "-0.841736376285553\n",
            "0.6383686661720276\n",
            "-0.0044904956594109535\n",
            "0.052148643881082535\n",
            "-0.8245016932487488\n",
            "-2.113213300704956\n",
            "-1.938225507736206\n",
            "-9.007236258185003e-06\n",
            "0.19884583353996277\n",
            "-0.04949824884533882\n",
            "2.8325015591690317e-05\n",
            "-0.5212679505348206\n",
            "1.7037127017974854\n",
            "0.39692437648773193\n",
            "1.538727045059204\n",
            "0.21734680235385895\n",
            "-0.8691275715827942\n",
            "-0.7372134923934937\n",
            "1.510736346244812\n",
            "1.292918086051941\n",
            "-4.809921847481746e-06\n",
            "3.775254761584357e-11\n",
            "-0.345353364944458\n",
            "0.894366443157196\n",
            "-0.3610810339450836\n",
            "9.637798029871192e-06\n",
            "-0.13114069402217865\n",
            "-1.1860389709472656\n",
            "0.34611842036247253\n",
            "2.162928819656372\n",
            "-0.2217627912759781\n",
            "0.3342995345592499\n",
            "1.8986819982528687\n",
            "1.7320023775100708\n",
            "-5.317123762956824e-20\n",
            "0.6221808195114136\n",
            "1.3490979671478271\n",
            "-1.392260193824768\n",
            "1.39094199766987e-05\n",
            "0.46008285880088806\n",
            "-0.5254020690917969\n",
            "-0.3525041341781616\n",
            "0.10483307391405106\n",
            "0.31398963928222656\n",
            "-5.477864019904057e-20\n",
            "-11.471691131591797\n",
            "0.5571404099464417\n",
            "0.25396546721458435\n",
            "-1.7564227619004669e-06\n",
            "-0.23866869509220123\n",
            "-0.9137297868728638\n",
            "-0.0202841367572546\n",
            "0.001438660197891295\n",
            "1.5269232988357544\n",
            "-0.2267075777053833\n",
            "-0.7292605042457581\n",
            "-0.2133508175611496\n",
            "-0.6365366578102112\n",
            "0.4602125883102417\n",
            "1.089377760887146\n",
            "-0.0028643759433180094\n",
            "0.6518357992172241\n",
            "2.3105561922420748e-05\n",
            "-1.864560900743218e+38\n",
            "-1.2490296363830566\n",
            "0.17866423726081848\n",
            "-0.21709752082824707\n",
            "1.3464468717575073\n",
            "0.49528980255126953\n",
            "-0.6883652210235596\n",
            "-0.4804632365703583\n",
            "-1.0793712139129639\n",
            "0.25200793147087097\n",
            "-1.1542320251464844\n",
            "-0.170230433344841\n",
            "-1.4871819019317627\n",
            "-0.28885242342948914\n",
            "0.9045541882514954\n",
            "2.384474277496338\n",
            "-0.3969730734825134\n",
            "-0.5566980838775635\n",
            "-1.5592695474624634\n",
            "-3.358596040170525e-11\n",
            "-1.4112236499786377\n",
            "0.46948492527008057\n",
            "0.06740567088127136\n",
            "519.4720458984375\n",
            "1.5028682947158813\n",
            "576.7962646484375\n",
            "0.19593530893325806\n",
            "-0.5188895463943481\n",
            "-2.1369757652282715\n",
            "1.867498755455017\n",
            "-3.2237570946058725e-10\n",
            "-0.4325326681137085\n",
            "1.0547806024551392\n",
            "0.2719012498855591\n",
            "-1.8230617046356201\n",
            "1.974534273147583\n",
            "0.39743947982788086\n",
            "-1.1222678422927856\n",
            "-0.6634175181388855\n",
            "-0.2454860806465149\n",
            "-1.5813257694244385\n",
            "1.5094711780548096\n",
            "-1.5485498905181885\n",
            "3.7356662303851007e-20\n",
            "-1.2093946933746338\n",
            "-0.11841999739408493\n",
            "0.11758269369602203\n",
            "-0.018832461908459663\n",
            "1.0175154209136963\n",
            "0.29260388016700745\n",
            "-1.7986392974853516\n",
            "0.554366946220398\n",
            "-0.002559887943789363\n",
            "0.04812592267990112\n",
            "-0.5701106190681458\n",
            "-0.9408108592033386\n",
            "0.05513014271855354\n",
            "0.03276115283370018\n",
            "-0.34073472023010254\n",
            "0.7565807104110718\n",
            "-1.2801921367645264\n",
            "0.441729336977005\n",
            "0.8159937262535095\n",
            "0.384053498506546\n",
            "-1.3503940105438232\n",
            "-1.373281247651903e-05\n",
            "1.1862537860870361\n",
            "-0.7622199654579163\n",
            "1.7702085971832275\n",
            "-3.529351255693314e-10\n",
            "0.1292763352394104\n",
            "1.8321776390075684\n",
            "-6.940336145004003e-20\n",
            "-1.8980739116668701\n",
            "-2.2882273197174072\n",
            "-0.8281863331794739\n",
            "-2.3868298190804747e-20\n",
            "0.45127782225608826\n",
            "0.8151141405105591\n",
            "-0.7581374049186707\n",
            "0.13481679558753967\n",
            "1.7531476020812988\n",
            "-0.01541069708764553\n",
            "1.1322904825210571\n",
            "-0.006064367014914751\n",
            "-3.0940569550885755e-10\n",
            "-1.5378011465072632\n",
            "0.0898783802986145\n",
            "-0.8339090943336487\n",
            "1.6307454109191895\n",
            "0.0942748561501503\n",
            "0.007384166587144136\n",
            "-1.6263623237609863\n",
            "-0.8810842037200928\n",
            "0.7934591174125671\n",
            "-1.4456406831741333\n",
            "0.07184191048145294\n",
            "-2.0983849380318276e-10\n",
            "-0.36316534876823425\n",
            "-0.8851619958877563\n",
            "0.04388061910867691\n",
            "0.2952609956264496\n",
            "-1.4228262901306152\n",
            "7.849343822507992e-21\n",
            "0.5116344094276428\n",
            "4.4960490191980895e-11\n",
            "1.4573296308517456\n",
            "-0.013551865704357624\n",
            "0.8643587827682495\n",
            "Test Loss: nan\n",
            "\n",
            "Test Accuracy of     0: 100% (980/980)\n",
            "Test Accuracy of     1:  0% ( 0/1135)\n",
            "Test Accuracy of     2:  0% ( 0/1032)\n",
            "Test Accuracy of     3:  0% ( 0/1010)\n",
            "Test Accuracy of     4:  0% ( 0/982)\n",
            "Test Accuracy of     5:  0% ( 0/892)\n",
            "Test Accuracy of     6:  0% ( 0/958)\n",
            "Test Accuracy of     7:  0% ( 0/1028)\n",
            "Test Accuracy of     8:  0% ( 0/974)\n",
            "Test Accuracy of     9:  0% ( 0/1009)\n",
            "\n",
            "Test Accuracy (Overall):  9% (980/10000)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "print(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0].item())\r\n",
        "torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0] = 0\r\n",
        "print(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0].item())\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import math\r\n",
        "max = 0\r\n",
        "min = 0 \r\n",
        "for i in range (1474559):\r\n",
        "    if (torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item() > max):\r\n",
        "        max = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()\r\n",
        "\r\n",
        "    if (torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item() < min):\r\n",
        "        min = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()\r\n",
        "\r\n",
        "print(min)\r\n",
        "print(max)\r\n",
        "\r\n",
        "count = 0\r\n",
        "\r\n",
        "for i in range (1474559):\r\n",
        "    if (math.isfinite(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()) == True):\r\n",
        "        count = count + 1\r\n",
        "\r\n",
        "print(count)\r\n",
        "#caps_output, images, reconstructions = test(capsule_net, test_loader)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-c0c994da7e3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1474559\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'digit_capsules.W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'digit_capsules.W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "import math\r\n",
        "if (bin_to_float('01111111100000000000000000000000') == float('inf')):\r\n",
        "    print('yes')\r\n",
        "\r\n",
        "print(math.isfinite(bin_to_float('01111111100000000000000000000000')))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n",
            "False\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(caps_output.size())"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def display_images(images, reconstructions):\r\n",
        "    '''Plot one row of original MNIST images and another row (below) \r\n",
        "       of their reconstructions.'''\r\n",
        "    # convert to numpy images\r\n",
        "    images = images.data.cpu().numpy()\r\n",
        "    reconstructions = reconstructions.view(-1, 1, 28, 28)\r\n",
        "    reconstructions = reconstructions.data.cpu().numpy()\r\n",
        "    \r\n",
        "    # plot the first ten input images and then reconstructed images\r\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(26,5))\r\n",
        "\r\n",
        "    # input images on top row, reconstructions on bottom\r\n",
        "    for images, row in zip([images, reconstructions], axes):\r\n",
        "        for img, ax in zip(images, row):\r\n",
        "            ax.imshow(np.squeeze(img), cmap='gray')\r\n",
        "            ax.get_xaxis().set_visible(False)\r\n",
        "            ax.get_yaxis().set_visible(False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HnjrQyqS1jem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# display original and reconstructed images, in rows\r\n",
        "display_images(images, reconstructions)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "ZTa-sNhX1nf9",
        "outputId": "e168f284-4bb3-441e-b414-6762b81fae86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# convert data to Tensor *and* perform random affine transformation\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.RandomAffine(degrees=30, translate=(0.1,0.1)),\r\n",
        "     transforms.ToTensor()]\r\n",
        "    )\r\n",
        "\r\n",
        "# test dataset\r\n",
        "transformed_test_data = datasets.MNIST(root='data', train=False,\r\n",
        "                                       download=True, transform=transform)\r\n",
        "\r\n",
        "# prepare data loader\r\n",
        "transformed_test_loader = torch.utils.data.DataLoader(transformed_test_data, \r\n",
        "                                                      batch_size=batch_size,\r\n",
        "                                                      num_workers=num_workers)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9vFtJK0R1sHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# obtain one batch of test images\r\n",
        "dataiter = iter(transformed_test_loader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "images = images.numpy()\r\n",
        "\r\n",
        "# plot the images in the batch, along with the corresponding labels\r\n",
        "fig = plt.figure(figsize=(25, 4))\r\n",
        "for idx in np.arange(batch_size):\r\n",
        "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\r\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\r\n",
        "    # print out the correct label for each image\r\n",
        "    # .item() gets the value contained in a Tensor\r\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "KckPo33p1v2S",
        "outputId": "ddf44b2d-93b2-4d56-ad94-ae6dd680b1ba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "# call test function and get reconstructed images\r\n",
        "_, images, reconstructions = test(capsule_net, transformed_test_loader)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd3PdXRe12zL",
        "outputId": "9a600558-8041-4a45-ec1a-960d91fdf2e2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# original input images\r\n",
        "display_images(images, reconstructions)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "XIlrGK7C1-GP",
        "outputId": "d57502ec-1ea2-42c4-8897-8837c94f2044"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from IPython.display import FileLink\r\n",
        "FileLink(r'Q-mnist.pt')"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a344be94937486b3a7f1f0c255bb269d6d9cd5bd89a7c219d69b8756ffbd242d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}