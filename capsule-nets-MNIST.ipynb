{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# import resources\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "\r\n",
        "# random seed (for reproducibility)\r\n",
        "seed = 1\r\n",
        "# set random seed for numpy\r\n",
        "np.random.seed(seed)\r\n",
        "# set random seed for pytorch\r\n",
        "torch.manual_seed(seed)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x160eb673410>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nExVIhReu3IX",
        "outputId": "c077ab39-5192-4b0c-983d-795cbe3c31b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from torchvision import datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "# number of subprocesses to use for data loading\r\n",
        "num_workers = 0\r\n",
        "# how many samples per batch to load\r\n",
        "batch_size = 20\r\n",
        "\r\n",
        "# convert data to Tensors\r\n",
        "transform = transforms.ToTensor()\r\n",
        "\r\n",
        "# choose the training and test datasets\r\n",
        "train_data = datasets.MNIST(root='data', train=True,\r\n",
        "                            download=True, transform=transform)\r\n",
        "\r\n",
        "test_data = datasets.MNIST(root='data', train=False, \r\n",
        "                           download=True, transform=transform)\r\n",
        "\r\n",
        "# prepare data loaders\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           num_workers=num_workers)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          num_workers=num_workers)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Amir\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "metadata": {
        "id": "zAY9BoidvAc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "    \r\n",
        "# obtain one batch of training images\r\n",
        "dataiter = iter(train_loader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "images = images.numpy()\r\n",
        "\r\n",
        "# plot the images in the batch, along with the corresponding labels\r\n",
        "fig = plt.figure(figsize=(25, 4))\r\n",
        "for idx in np.arange(batch_size):\r\n",
        "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\r\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\r\n",
        "    # print out the correct label for each image\r\n",
        "    # .item() gets the value contained in a Tensor\r\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Amir\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"250.458125pt\" version=\"1.1\" viewBox=\"0 0 1393.516025 250.458125\" width=\"1393.516025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-31T17:40:32.171535</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 250.458125 \r\nL 1393.516025 250.458125 \r\nL 1393.516025 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 10.7 121.154489 \r\nL 109.536364 121.154489 \r\nL 109.536364 22.318125 \r\nL 10.7 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pae6a09b459)\">\r\n    <image height=\"99\" id=\"image19f545e73e\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"10.7\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEJUlEQVR4nO2cyyt2URTGt48M3GNAKYkBISm3kkiKEuU6MDA1EiMTpUxIiYEYyED5D8iElMtAidwGShlJGVJukcs3W/Y6dU7e873v8by+5zd6Vqt9ztbT2vvY7947xhjzaQgEf366A+QLmgEEzQCCZgBBM4CgGUDQDCBoBhA0AwiaAUSc34aTk5MqHh4e/la78/NzFa+trYl+e3tTuenpadF3d3ch9jD6YGUAQTOAiDE+V22rq6tVbA9TVVVVKpedne3nFebp6Un07Oysyk1MTIh+fHz09Xw0WBlA0AwgaAYQvucML9LT01W8sLAguqysTOXy8vJ8vWNvb0+0/QlsjDHr6+sqfn5+9vWOoGFlAEEzgIjIMOVFZmamiouKikTPzc2pXGFhoa937O/vq3hqakr0ysqKyn18fPh6RyRgZQBBM4CgGUAEPmd4kZWVpeLe3l7RAwMDKpebm+vrHYeHhyoeHx8Xvbq66uuZ4YKVAQTNAAJqmPKioKBAxfaw1dnZqXLO4c6L9/d30ZubmyrX0tISShf/GVYGEDQDCJoBRNTMGV6UlpaquLu7W8WVlZWim5qaXJ9zdnam4vLyctFBLJuwMoCgGUD8imEqFF5eXlQcF/e1dcy5b6u5uVn09vZ2RPtlDCsDCpoBBM0AwvdeW2TS0tJU3NbWJjo2Nta13e7uroqDmCdsWBlA0AwgfsUwVVJSouKZmRkVNzY2ura193TZPzT9BKwMIGgGEDQDiKidMzo6OkQvLS2pXHJysmu7kZERFS8vL4u+ubkJU+/8wcoAgmYAQTOAiJol9Pz8fBUfHR2Jdh5L3traUrG9cW1+fl7lPj9x/nxWBhA0AwjoT9vExETRi4uLKpeUlCS6p6dH5TY2NiLbsQjBygCCZgBBM4CAnjPGxsZE19fXq9zOzo5o54blaIWVAQTNAOLHh6mUlBTR9/f3Kpeamurazv7URTo+/C+wMoCgGUDQDCACX7Vtb29XcWtrq+jj42OVc96+ZnNyciK6rq5O5Zw3sxUXF4seGhpSuf7+fs/+BgkrAwiaAUQgw5R9GZjzxhu/l3/ZOJ/p/LGpoaFB9Ovrq8p5fT4HDSsDCJoBBM0AIpDlkJycHNEZGRlhf77zwmMv7DN8xhjT19cn+uHhwbWdc4Pb7e2t6IuLi2+/3wtWBhA0A4jA/wO3hyxjjImPjxddU1OjcrW1taKdR8O6urrC0p/r62vRBwcHKmfv53X+V396eip6dHRU5fweP2NlAEEzgKAZQAT+S9/V1ZVr7vLyUsX22QnnkeFQljHsW9sSEhJUzr7hbXBwUOXspRP78kpjjKmoqBDt3CzBOeMXQDOAiJojAf8DrAwgaAYQNAMImgEEzQCCZgBBM4CgGUDQDCBoBhA0AwiaAQTNAIJmAEEzgKAZQNAMIP4C5o/o9XPnuT8AAAAASUVORK5CYII=\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\"/>\r\n   <g id=\"matplotlib.axis_2\"/>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 10.7 121.154489 \r\nL 10.7 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 109.536364 121.154489 \r\nL 109.536364 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 10.7 121.154489 \r\nL 109.536364 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 10.7 22.318125 \r\nL 109.536364 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <!-- 5 -->\r\n    <g transform=\"translate(56.300682 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-35\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path d=\"M 152.564407 121.154489 \r\nL 251.40077 121.154489 \r\nL 251.40077 22.318125 \r\nL 152.564407 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p701c5e40b3)\">\r\n    <image height=\"99\" id=\"image160d41640b\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"152.564407\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEjklEQVR4nO2cSyi9XRTG9/kSSTEwIgMGpi7JJbmUoczkWgyZuORaCiNDhQykZCDlXiQkRcpt4FLGRu6SgUsK4Zut/1r765yO73vf96z//3t+o2f1dM7ePK13v2fv9xyfMebbABX8FeoJgF8gDEUgDEUgDEUgDEUgDEUgDEUgDEUgDEUgDEUgDEUgDEUgDEWEeTFIXFwc6fr6euF1d3eT9vl8wvv+/rWhPDQ0JLyRkRHSZ2dnjswz1KAzFIEwFIEwFOEzLpz0JSQkiHpubo50Zmam/8kEWDNsHh4eSE9PTwuvubk5qHlqA52hCIShCFcuU2VlZaKempoK6nV3d3eifnp6Ip2cnBz0+Pv7+6Le2toi3dvbG/T7eA06QxEIQxEIQxGebIdwPj8/RT06Okp6fHxcePz2NScnR3g1NTWkU1NThZebmytqfqttrz18m+Xg4CDg3N0GnaEIhKEIVy5T9idpXt/e3gqvqakpqPe8uLgQNf9Ub9PS0iLqnp4e0uXl5cL7+PggjcsUIBCGIhCGIlxZM+zdVl4vLi66MaRgYGBA1Hw7pKOjQ3jV1dWko6KihFdaWurC7PyDzlAEwlCE57u29i1qUlKS08MHJCIiQtT8gYiuri7hXV1dka6rqxPe+vq643NDZygCYSgCYSjC811b+5rNH3C7ublxffy3tzdR9/X1kQ4Lk/+Ozs5O0m1tbcLb3d0l/fLy4sjc0BmKQBiKcOXWtqSkRNSzs7Okw8PDhdfe3k56cHDQ6an8J/hBmL2rwJ/1bWxsdGQ8dIYiEIYiEIYiXFkzbPb29khnZ2cLb3t7m3RRUZHbU/kRfJ34+voSHv+b8vPzHRkPnaEIhKEIhKEIT7ZDWltbSe/s7AivoKCAdGFhofD4ehIK+DoR6LsiToHOUATCUIQnl6mTkxPSq6urwisuLia9tLQkvIqKCtKHh4fCi4yMJH15eenIPEMNOkMRCEMRCEMRnqwZ/HSNb5kbY8zz8zPpyspK4U1MTJC2TwH5Cd38/Lwj8/wJ5+fnjr8nOkMRCEMRnuzaBiItLY305uam8KKjo/2+bm1tjXRVVZXw7E/yKSkppMfGxoR3f3/vdwx+0vf6+up3jOPjY7/v8RPQGYpAGIpAGIoI+ZrBycjIEPXGxgbpmJgYv6+zd3eXl5dF3d/fT/r6+lp4/EmWxMRE4fHvkszMzAjPvg13AnSGIhCGIjx/1jYQR0dHol5ZWSFt375y+AGVMf+8teUHQ/zZXmOMSU9PJ81/dcEYHC79r0EYikAYilC1ZtjwHyTmv75jjDGTk5Ok7R+oDIS9dcG/W2GvNZzT09Ogx/i3oDMUgTAUoeoT+E/IysoivbCwILz4+HhR89tSfphljDHv7++kY2NjhZeXl0favrzx1zkFOkMRCEMRCEMRv+2aweGnhcb87MSQ8/j4KGp7DXEbdIYiEIYi/ojLlI19SNXQ0EC6trZWePzZrOHhYeE59aBBsKAzFIEwFIEwFPFHrhm/K+gMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRSAMRfwN+c44Y7Lb2NEAAAAASUVORK5CYII=\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\"/>\r\n   <g id=\"matplotlib.axis_4\"/>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 152.564407 121.154489 \r\nL 152.564407 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 251.40077 121.154489 \r\nL 251.40077 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 152.564407 121.154489 \r\nL 251.40077 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 152.564407 22.318125 \r\nL 251.40077 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <!-- 0 -->\r\n    <g transform=\"translate(198.165089 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-30\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 294.428814 121.154489 \r\nL 393.265177 121.154489 \r\nL 393.265177 22.318125 \r\nL 294.428814 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p2497e45077)\">\r\n    <image height=\"99\" id=\"image19984eb2fd\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"294.428814\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADg0lEQVR4nO2cv0vrYBSGvxbxx1DBSVBHFUHQQRx0VtDRWQcpouLkUHDqv1EEoYPd7OJSN0FdVOygFmrbQUEF6SLaoV1E73bMybWXNk2a95r3mc7hYHLk8XxfmsaEjDFfhkAQ9rsB8g1lAEEZQFAGEJQBBGUAQRlAUAYQlAEEZQDR4XcD7WZ1dVXlyWRS4r29PVXb2NhoR0sCJwMIygAicMvU4uKiykOhkE+d/A0nAwjKAIIygAjcnmHn6wvni05OBhCUAUTglykr5+fnvp6fkwEEZQBBGUAEfs+w3g75/Pz0sRNOBhSUAUTglynrJ/BSqeRjJ5wMKCgDCMoAgjKAoAwgKAOIwF/aWllaWlL5xcVFW8/PyQCCMoCgDCBCxuG/Hu/s7Kh8dna25WYODw9Vfnd3J7Fb6/f6+rrKd3d3Jb6/v1e14eFhV87ZKJwMICgDiKaWqUQiIbH9cfm3tzeJHx8fG25gYmLiuxnbc68fHx8SV6tVVcvn8xJfXl6qWjabVfnp6anE5XJZ1Z6fnyXu6+tTtc7Ozn/27jacDCAoAwjKAKKp2yE9PT0S29f3zc1NidPpdMPHnJycrHvMubk5iYeGhlTNup5Ho1FVW1tbU3mtVpPYvr90d3dLHA7rv82xsTGJC4XCz7+Ai3AygKAMICgDCNduob++vjr6uZubm7q16+vrho6xtbWl8t7eXpUvLCxIvLKyompdXV0S2/eMqakpiblnBAzKAMK1ZWp6elri4+Njtw7riEqlovKDg4MfY2OMSaVSEi8vL6taPB6XOJPJqJr19o9bcDKAoAwgKAOIpvaMYrFYtzY+Pt5yM34Qi8Uktt5+McaY0dFRiSORiKpxz/jlUAYQTS1TR0dHElsv+/5nrN/8PTw8qFp/f7/Eg4ODqvb09OR6L5wMICgDCMoAoqk94/b2VmL7Uxa/gff397q1+fl5lXvxUDQnAwjKAMLxXVu/3ybgBfYHGayXryMjI56fn5MBBGUAQRlAON4z9vf3Vd6ONdVrXl5eVG59N/rMzIyqefGAGycDCMoAwvEydXJyovJcLtdqL75jv1y33sUdGBhQNS/eh8vJAIIygKAMIBzvGWdnZ272AcnV1ZXE29vbnp+PkwEEZQDh+A0JxH04GUBQBhCUAQRlAEEZQFAGEJQBBGUAQRlAUAYQlAEEZQBBGUBQBhCUAQRlAEEZQPwBgPrAQHML2WEAAAAASUVORK5CYII=\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_5\"/>\r\n   <g id=\"matplotlib.axis_6\"/>\r\n   <g id=\"patch_13\">\r\n    <path d=\"M 294.428814 121.154489 \r\nL 294.428814 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path d=\"M 393.265177 121.154489 \r\nL 393.265177 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path d=\"M 294.428814 121.154489 \r\nL 393.265177 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path d=\"M 294.428814 22.318125 \r\nL 393.265177 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_3\">\r\n    <!-- 4 -->\r\n    <g transform=\"translate(340.029495 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-34\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g id=\"patch_17\">\r\n    <path d=\"M 436.29322 121.154489 \r\nL 535.129584 121.154489 \r\nL 535.129584 22.318125 \r\nL 436.29322 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pae2a5dc3f3)\">\r\n    <image height=\"99\" id=\"image6af720219a\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"436.29322\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADQUlEQVR4nO2cv0tyYRTHH+MdBAcRgkRDQhocHJrDRXQR3IzcQsvBP0IQa21zcGhIXNTBwdlBcfJPqCGqrZwUHFyqd3ve59wXo+Le6zf9fqZzOF468Ok8jz+eez1KqQ9FINhZdwPkH5QBBGUAQRlAUAYQlAEEZQBBGUBQBhCUAcQft/9gMBgUebfb1XEikRC1x8dHHR8eHjrbGACcDCAoAwjXl6lYLCby4+Njt1uAhZMBBGUAQRlAUAYQlAEEZQDh+lvb2Wwm8peXFx2HQiFRC4fDOr6+vha1SqWi4+VyaWOH64OTAQRlAEEZQHjUmg+x3d7e6rhQKIja+/v7yuui0aiOn5+fbe9rHXAygKAMINa+TJm8vb2J/LNl6uzsTMftdtuxntyEkwEEZQBBGUBA7RnT6VTkgUBg5Wsnk4mOM5mMqC0WC3sbcwlOBhCUAQTUMnV0dCTyXq+n40gksvK6fr8v8pOTE1v7cgtOBhCUAQRlAAG1Z1hpNBo6LpVKX74uHo+L/P7+3raenISTAQRlAAG9TB0cHOj44eHhy9e1Wi2RF4tFu1pyFE4GEJQBBGUA4fohtu/w9PSk41wuJ2rNZlPHPp9P1MzDCkoptbe3p+PX11f7GrQZTgYQlAEEZQAB/TnjM8rlso7r9bqo7ezI/7HBYKDjfD4vavP53IHufgYnAwjKAOLXLlPmVyXmL4JK/f+LoXkY7urqStQuLy9t7+2ncDKAoAwgKAOIX7tnmOzu7orc+pWHuWdY7yk8PT3V8XA4tL+5b8DJAIIygNiIZcrKzc2NyM/Pz1e+djQa6TiVSjnV0pfgZABBGUBQBhAbuWdYHzxp3vNnfWClycXFhcitp0ychpMBBGUAsZHLlJV0Oq3jTqcjan6/X8d3d3eils1mdWz9VO/Ek3w4GUBQBhCUAcRW7Bkm1WpV5OYT3ayYBxuSyaSojcdjextTnAwoKAMI6LO2TmB9UJj5FtXr9brdjoCTAQRlAEEZQGzdnmHe16GUUvv7+zqu1WqiZr619Xg8jvalFCcDCsoAYus+gSPDyQCCMoCgDCAoAwjKAIIygKAMICgDCMoAgjKAoAwgKAMIygCCMoCgDCAoAwjKAOIvm8meZYdQHtQAAAAASUVORK5CYII=\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_7\"/>\r\n   <g id=\"matplotlib.axis_8\"/>\r\n   <g id=\"patch_18\">\r\n    <path d=\"M 436.29322 121.154489 \r\nL 436.29322 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_19\">\r\n    <path d=\"M 535.129584 121.154489 \r\nL 535.129584 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_20\">\r\n    <path d=\"M 436.29322 121.154489 \r\nL 535.129584 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path d=\"M 436.29322 22.318125 \r\nL 535.129584 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_4\">\r\n    <!-- 1 -->\r\n    <g transform=\"translate(481.893902 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-31\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g id=\"patch_22\">\r\n    <path d=\"M 578.157627 121.154489 \r\nL 676.993991 121.154489 \r\nL 676.993991 22.318125 \r\nL 578.157627 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p7b5f581da0)\">\r\n    <image height=\"99\" id=\"image675ee911da\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"578.157627\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAD70lEQVR4nO2czyu0URTH70hIksTCktggG8qGbMSKJhYoC+zslZJQ2NlIWVlY0JRplMwGG2TBP4CEsmBjp0QK7+64576e18/neb7PvN/P6ns6Y+bo69x75z73ihljXg2BICvsAsgbNAMImgFEdtgF+EFhYaGKZ2dnRQ8PD6tcXV2d6OPjY38L+wB2BhA0A4iMGKbcYWltbU3Fra2totfX11Xu6urKv8K+CDsDCJoBBM0AIiPmjK6uLhXbc4Qxxuzt7YmemppSufv7e9/q+irsDCBoBhAxkwG7tmdnZyquqKhQcVNTk+jDw8NAavoO7AwgaAYQNAOIyC5ta2trRVdVVancy8uLii8uLgKp6aewM4CgGUBEdphqbm4W7Q5Lr6/RXK2zM4CgGUDQDCAiO2dcXl6GXcKvw84AgmYAkRG7ts/Pzyp2l7ZlZWWib29vA6npO7AzgKAZQNAMICK7tG1vbw+7hF+HnQEEzQAissPUw8OD6Kws/Tfl7uL29vaKXlhY8LewH8DOAIJmAEEzgAhkzmhsbBSdTqdVrri4WPT5+bnKbWxsiF5eXlY5++CafZbWGH1ozZi/D7Whws4AgmYA4cuubVFRkYpPTk5El5aW6gJiMdFfOUhwc3Pz7nsYo3dpjdE7tW4OCXYGEDQDCJoBhC9L25ycHBW784RNeXm56MfHR5UbHBwU3dnZqXL2WduCggKVc+eekpIS0R0dHSq3ubnpWVvQsDOAoBlA0AwgAvmecXp6Ktoev43R2yPxePzTn1FZWSl6dXVV5err6z1/LpVKqXhoaEh02NeQ2RlA0AwgAjnENjExIXpyclLlnp6eRG9tbalcX1+faPvJnkteXp6K29raVJxIJDxfOzMz41lb0LAzgKAZQNAMIAI/+Dw9Pa3isbEx0e42xuLioujx8XGVu7u7+/Rn2lv47jVlm+7ubhXbTxqDgJ0BBM0AIvT7GQMDA6KXlpY8X7ezs6Pinp4e0R8NWf39/aLdgw0219fXKm5oaBAdxL0OdgYQNAMImgFE6HNGdvbbw0Z7jDbGmO3tbdH5+fkqt7+/L9pdLh8cHKg4NzdXtPsPiO2tE/eUyejoqOi5ubn3f4FfhJ0BBM0AIvRh6l/Yy9f5+XmVsx9SucPL7u6uiu0DEdXV1Z6f575PMpkUbd/x8At2BhA0AwiaAQT0nGFj3/EwRm9xtLS0qFxNTY3n+4yMjKjYPkDt3utYWVkRfXR09Plivwk7AwiaAURkhqn/AXYGEDQDCJoBBM0AgmYAQTOAoBlA0AwgaAYQNAMImgEEzQCCZgBBM4CgGUDQDCBoBhA0AwiaAQTNAIJmAEEzgKAZQNAMIP4Al6LcAvNfHWQAAAAASUVORK5CYII=\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_9\"/>\r\n   <g id=\"matplotlib.axis_10\"/>\r\n   <g id=\"patch_23\">\r\n    <path d=\"M 578.157627 121.154489 \r\nL 578.157627 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path d=\"M 676.993991 121.154489 \r\nL 676.993991 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_25\">\r\n    <path d=\"M 578.157627 121.154489 \r\nL 676.993991 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_26\">\r\n    <path d=\"M 578.157627 22.318125 \r\nL 676.993991 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_5\">\r\n    <!-- 9 -->\r\n    <g transform=\"translate(623.758309 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 703 97 \r\nL 703 672 \r\nQ 941 559 1184 500 \r\nQ 1428 441 1663 441 \r\nQ 2288 441 2617 861 \r\nQ 2947 1281 2994 2138 \r\nQ 2813 1869 2534 1725 \r\nQ 2256 1581 1919 1581 \r\nQ 1219 1581 811 2004 \r\nQ 403 2428 403 3163 \r\nQ 403 3881 828 4315 \r\nQ 1253 4750 1959 4750 \r\nQ 2769 4750 3195 4129 \r\nQ 3622 3509 3622 2328 \r\nQ 3622 1225 3098 567 \r\nQ 2575 -91 1691 -91 \r\nQ 1453 -91 1209 -44 \r\nQ 966 3 703 97 \r\nz\r\nM 1959 2075 \r\nQ 2384 2075 2632 2365 \r\nQ 2881 2656 2881 3163 \r\nQ 2881 3666 2632 3958 \r\nQ 2384 4250 1959 4250 \r\nQ 1534 4250 1286 3958 \r\nQ 1038 3666 1038 3163 \r\nQ 1038 2656 1286 2365 \r\nQ 1534 2075 1959 2075 \r\nz\r\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-39\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_6\">\r\n   <g id=\"patch_27\">\r\n    <path d=\"M 720.022034 121.154489 \r\nL 818.858398 121.154489 \r\nL 818.858398 22.318125 \r\nL 720.022034 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p9e0eb332be)\">\r\n    <image height=\"99\" id=\"image44ced56824\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"720.022034\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEd0lEQVR4nO2cSyh9XRjGNz7KdaAMGBEDxICUy4hSbuUyEpJMlIkoYqBcSmKgRCbCVMllRCFKLgMDZgwoUeRSlBDh+2bvf72r9un8dRyPr+c3elbPPnuverxrbWvvtQMcx/nXIRAE/nQHyB8YBhAMAwiGAQTDAIJhAMEwgGAYQDAMIBgGEAwDCIYBBMMAgmEAwTCAYBhAMAwg/vHViSIjI0VXVlYqLzMzU/TNzY3ypqenRd/f3yvv7e3NV937FbAygGAYQAQ4Pnoh4eDgQHR6evqXzrG8vKzaW1tbopeWlpR3dnYm+v39/UvXQ4OVAQTDAIJhAOGzOePq6kp0TEyM8l5fX0UfHx8rLzw8XHRSUpLX1+vt7RU9ODiovI+PD6/PgwQrAwiGAYTPhqnm5mbRY2Njynt+fhbd1NSkvNXVVdHZ2dnKa2xsFF1SUqK80NBQ0f39/cqbmZlR7YuLC49994aamhrVrq2tdT22ra1N9MnJidfXYGUAwTCAYBhA+GzOCAoKEj0wMKC89vZ20U9PT8rr6uoSPTs7qzxzFTcrK0t54+Pjrp49Tpvz2ebmpvKioqJE5+XlKa+urk50eXm58sxbchtzjkpISHA9zoaVAQTDAMJnw5RJcHCwapu3nh0dHa6/W1lZUe36+nrRDw8PyjP/y7dXe82HWY6jH1INDw8rLy0tTXRFRYVr39bX11V7aGhItP1QzOTw8NDVs2FlAMEwgGAYQHzLnGETEhIiuri4WHkLCwuuv+vr6xO9sbGhvJ2dHdHR0dHKs48154W/wby1tZ80mivRvoKVAQTDAMIvw5SJfdubkZEhen5+XnmxsbGiX15elGfe6u7t7SnPHgrDwsJc+3N7eyt6ZGREeaOjo6L98Q4XKwMIhgEEwwDC73OGJ+yxPTU1VXRPT4/ySktLXc8TGKj/xj4/P12Pvby8FJ2fn6+809NT1999B6wMIBgGEAwDCKg5429oaWkR7empm01VVZVqm8vtu7u7yisoKBDtjxfjWBlAMAwgfu0w9VWmpqZUu6GhwfVY81Z3e3v7u7oksDKAYBhAMAwgfLb1+KvExcWJ9vRStP1imr2F2Vvs5XZPc4a/YWUAwTCA+PFhanJyUnRRUZHyuru7RZtbjR3Hcfb390V3dnYq7/z83PV619fXX+mmX2BlAMEwgGAYQPz4nDE3NyfanjNM4uPjXdv2i86FhYWqbe6XODo6+kIv/QMrAwiGAcSPD1OLi4uic3JylFddXS3a/LiYTWJiomqvra2ptqfhDwlWBhAMAwiGAQT0k77k5GTRra2tyjP3TpifrnAcxwkICFBt89b28fFReSkpKaLv7u6UZz7ps78G9B2wMoBgGEBAD1OeMP8Dt1dtc3NzVdvbbWQTExOqbb6b5Q9YGUAwDCAYBhC/ds7whL10EhERIbqsrEx55mcv7D1937G92BOsDCAYBhD/y2Hqt8LKAIJhAMEwgGAYQDAMIBgGEAwDCIYBBMMAgmEAwTCAYBhAMAwgGAYQDAMIhgEEwwDiP//NEotZXnhZAAAAAElFTkSuQmCC\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_11\"/>\r\n   <g id=\"matplotlib.axis_12\"/>\r\n   <g id=\"patch_28\">\r\n    <path d=\"M 720.022034 121.154489 \r\nL 720.022034 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_29\">\r\n    <path d=\"M 818.858398 121.154489 \r\nL 818.858398 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_30\">\r\n    <path d=\"M 720.022034 121.154489 \r\nL 818.858398 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_31\">\r\n    <path d=\"M 720.022034 22.318125 \r\nL 818.858398 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_6\">\r\n    <!-- 2 -->\r\n    <g transform=\"translate(765.622716 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-32\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_7\">\r\n   <g id=\"patch_32\">\r\n    <path d=\"M 861.886441 121.154489 \r\nL 960.722804 121.154489 \r\nL 960.722804 22.318125 \r\nL 861.886441 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p7cdddeff3a)\">\r\n    <image height=\"99\" id=\"image120ae03510\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"861.886441\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAACWUlEQVR4nO3cP2oqURhAcZV01jY2ioX4B1yCa7Gy0x0IbsE92FrpCmytBBEbQV2BlZ36unleIXkJb+bNmXnnV91hErhw8s2VIUmxUCg8C0Iopb0B/WYMEGOAGAPEGCDGADEGiDFAjAFiDBBjgBgDxBggH2lvIA61Wi24Xq1WwXW73Y7WxWIxuNdsNqP18XhMYHff52SAGAPEGCC5ODM6nU5w/XpGZImTAWIMkFw8pobDYdpbiIWTAWIMEGOA5OLM6Ha7wfX7K49XpRL354+7s/+QMUAy+5gajUbRutFoBPeez89/fXg2mwXXab+pfeVkgBgDxBggmT0zWq1W2luInZMBYgyQYiGjf0Z2v9+j9VcfZd/1er3ger/fx7anv+VkgBgDxBggmf1o+/r29fF4fPm1i8UiWpPOiHdOBogxQDL7mHp9NP3po+16vU56O7FwMkCMAWIMEGOAGAPEGCDGADEGiDFAjAGS2dchP3lrmxVOBogxQIwBktkz4yev0LPCyQAxBkhmHlOTySTtLSTOyQAxBogxQNBnRrVajdaDweDb3zedToPr5XIZ046S5WSAGAME/Zi63W7R+nK5BPfq9fqn37fZbILr8/kc676S4mSAGAPEGCDoM+N6vUbr7XYb3Ov3+/94N8lzMkCMAYJ+TJXL5Wj9/v/O88jJADEGiDFA0GdGpVKJ1nn8KPvOyQAxBgj6MXU6naL1fD4P7o3H42i92+2Ce4fDIdF9JcXJADEGiDFAMvuf2PLIyQAxBogxQIwBYgwQY4AYA8QYIMYAMQaIMUCMAWIMkF/JSVt5I9R+xwAAAABJRU5ErkJggg==\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_13\"/>\r\n   <g id=\"matplotlib.axis_14\"/>\r\n   <g id=\"patch_33\">\r\n    <path d=\"M 861.886441 121.154489 \r\nL 861.886441 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_34\">\r\n    <path d=\"M 960.722804 121.154489 \r\nL 960.722804 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_35\">\r\n    <path d=\"M 861.886441 121.154489 \r\nL 960.722804 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_36\">\r\n    <path d=\"M 861.886441 22.318125 \r\nL 960.722804 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_7\">\r\n    <!-- 1 -->\r\n    <g transform=\"translate(907.487122 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-31\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_8\">\r\n   <g id=\"patch_37\">\r\n    <path d=\"M 1003.750847 121.154489 \r\nL 1102.587211 121.154489 \r\nL 1102.587211 22.318125 \r\nL 1003.750847 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p9f2def4c7b)\">\r\n    <image height=\"99\" id=\"image59aaaeb243\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1003.750847\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEFElEQVR4nO2dTShtURTHzxX5KAMGiuQjMjKQgYF8TDAwMFMKUTIUQzKTuaQoJSXJRJGQDAwwV0wMjBggUeQ77putt9fu3fvOPXffe/699/+N/qvF3qv+1t7nnrvPEfE8L+oRCDLCLoD8hmYAQTOAoBlA0AwgaAYQNAMImgEEzQCCZgCRmYpBs7OzVTw4OCh6enpa5QoKCkRvbm6q3MHBgeitrS2Vu7m5SbJKPNgZQNAMICKeo7u2dXV1okdGRlRuYGAg6fEvLy9V/Pr6Kvro6EjlFhcXVXx+fp70/OmAnQEEzQCCZgDhbM84PT0VXVtb62JI30QiERXf3t6qeHt7W/To6KjKvb+/p66wBGFnAEEzgEjJJ/B4LCwsqPj5+TnQOO3t7aLr6+tVrqioSMVDQ0Oiq6qqYtazsbERqBZXsDOAoBlA0AwgnF3aNjU1iZ6cnFQ5c32vrKxUuaurq0DzFRYWiu7s7FS5ubk5Fefn58cc5+3tTXRXV5fKHR4eBqotKOwMIGgGEM4ubY+Pj0Xb7d7R0SH6/v7eyXwPDw+iV1dXVS4rK0vFs7OzovPy8lQuNzdXdE5OjpPagsLOAIJmAEEzgEjJ7ZCvry8V7+zspGKamCwvL6v45eVF9NraWlprSQR2BhA0A4i037UNg/39/bBL8AU7AwiaAQTNACL0PaO8vFx0X1+fyplrfTIHB8xv+pBhZwBBM4BI+zJln6kyzzSVlZWp3NTUlK8xMzL039TPz0/A6sKFnQEEzQCCZgAR+qVtNBr9o04Ee49IZBzzjvLe3l6g+V3BzgCCZgBBM4BwdogtKBUVFaL7+/tVrq2tzdcY5gE6z0tsz3h6ehI9Pj6ucru7u6Kvr699jxkUdgYQNAOI0JcpF/T29qrYXm6qq6tF2wfc4mE+Gtfc3Kxy5hldV7AzgKAZQNAMIP6JPeNv9PT0iB4eHla51tZWX2OYz4N4nr4kdgU7AwiaAUTod23Twfr6uujv72+Va2hoEG0+q2Fjf+s4NjbmpjgDdgYQNAMImgFE6HtGZubvEoqLi2P+nP3MR9AXRtqHoB8fH0XH2zNKS0tVbL4U8+PjI1AtNuwMIGgGEKF/AjdfLjkzMxPz5+7u7lS8tLQkOpFDbI2NjSr2+wncxvy9k5OTQGPYsDOAoBlA0AwgQr+0Nd+4Ew/77WoTExOi7RdGBj0MFzbsDCBoBhChL1PmcnNxcaFy3d3dou3L15KSktQWZrGysqLis7Mz53OwM4CgGUDQDCBCvx0Sj5qaGtH24bOWlhbR8/PzKufqmT7zXwuZhxo8z/M+Pz+dzGHCzgCCZgABvUz9b7AzgKAZQNAMIGgGEDQDCJoBBM0AgmYAQTOAoBlA0AwgaAYQNAMImgEEzQCCZgBBM4D4BY7g5liVWepEAAAAAElFTkSuQmCC\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_15\"/>\r\n   <g id=\"matplotlib.axis_16\"/>\r\n   <g id=\"patch_38\">\r\n    <path d=\"M 1003.750847 121.154489 \r\nL 1003.750847 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_39\">\r\n    <path d=\"M 1102.587211 121.154489 \r\nL 1102.587211 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_40\">\r\n    <path d=\"M 1003.750847 121.154489 \r\nL 1102.587211 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_41\">\r\n    <path d=\"M 1003.750847 22.318125 \r\nL 1102.587211 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_8\">\r\n    <!-- 3 -->\r\n    <g transform=\"translate(1049.351529 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-33\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_9\">\r\n   <g id=\"patch_42\">\r\n    <path d=\"M 1145.615254 121.154489 \r\nL 1244.451618 121.154489 \r\nL 1244.451618 22.318125 \r\nL 1145.615254 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pcdc72ac603)\">\r\n    <image height=\"99\" id=\"image1beeb0d792\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1145.615254\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAACO0lEQVR4nO3cMa5pURhAYV5EosIE1AyCxASYh8Iw1EpDEB3jUItGodMoqIjC6zz7JOTdczlnnZ31VXbc4k9W/rMVrnKpVLqXhPAn7wH0jzFAjAFiDBBjgBgDxBggxgAxBogxQCp5D/AJ8/k8OHc6neA8GAwer/f7fSYzpeFmgBgDJIrHVK/XC87NZjM412q1LMdJzc0AMQaIMUCiuDMWi0VwHo/Hwfn5o+52u81kpjTcDBBjgETxmEo6n8/Beblc5jTJz7gZIMYAMQZIlHdGuVwOztVq9fH6crlkPc5/czNAjAFSLkXwXdvNZhOc2+12cJ7NZo/Xo9Eok5nScDNAjAFiDJDCfrQdDoeP18k7IvnxdTqdZjHSr7kZIMYAKexjqlJ5Pfr9Hn5av16v3x7nI9wMEGOAGAOksHdGq9V6+d7tdgvO5O/XPnMzQIwBUtjHVL/fz3uEj3MzQIwBYgyQwt4Z76xWq7xHSMXNADEGiDFAorwzjsdj3iOk4maAGAPEGCDGADEGiDFACvPRttFoBOdut5vPIF/kZoAYA6Qwj6nkl9bq9frLv93tdt8e5yvcDBBjgBgDpDB3xk+s1+u8R0jFzQAxBkgUj6nkLyKQfwXhHTcDxBggxgCJ4s5I/g9fUbkZIMYAieIxdTgc3p6Lws0AMQaIMUAKc2ecTqfg/Pw/fZPJJHjPO0O/ZgyQKH4wMhZuBogxQIwBYgwQY4AYA8QYIMYAMQaIMUCMAWIMEGOAGAPEGCDGADEGyF+FYE/w/+Rl2QAAAABJRU5ErkJggg==\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_17\"/>\r\n   <g id=\"matplotlib.axis_18\"/>\r\n   <g id=\"patch_43\">\r\n    <path d=\"M 1145.615254 121.154489 \r\nL 1145.615254 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_44\">\r\n    <path d=\"M 1244.451618 121.154489 \r\nL 1244.451618 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_45\">\r\n    <path d=\"M 1145.615254 121.154489 \r\nL 1244.451618 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_46\">\r\n    <path d=\"M 1145.615254 22.318125 \r\nL 1244.451618 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_9\">\r\n    <!-- 1 -->\r\n    <g transform=\"translate(1191.215936 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-31\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_10\">\r\n   <g id=\"patch_47\">\r\n    <path d=\"M 1287.479661 121.154489 \r\nL 1386.316025 121.154489 \r\nL 1386.316025 22.318125 \r\nL 1287.479661 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p712fa84b47)\">\r\n    <image height=\"99\" id=\"imagecd3b7b89e4\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1287.479661\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEG0lEQVR4nO2cTSh1URiF90UpkjKTkJSBJAaSEiJlZoRIChMxkDIgAwM/MyZGihiIMvAz9z8iEmVgwEAkJT8ZKeKbvfa7+45O53PuXb7WM1pvK2dvLe/Z++57jogx5tMQCOJiPQHyBcMAgmEAwTCAYBhAMAwgGAYQDAMIhgEEwwCCYQDBMIBgGEAkxHoCNoODg6oeGRkR3dDQoLzV1dWozCmasDOAYBhAMAwgoNaM9vZ2T6++vl7VXDNIqDAMICIG6IGE7OxsVW9tbYnOyspS3vj4uOjh4eFwJxYl2BlAMAwgGAYQUGuGi308Yh+NGGPM/f296JKSEuXd3NyEO7GQYGcAwTCAgL5Npaamih4dHVVed3e36MvLS+Xl5eWFO7GQYGcAwTCAYBhAhLJm9Pb2qnplZUX09fV1oGtWVFSoen19XXRKSoryWlpaVH12duZ5XXsb/PLyEmhuPwU7AwiGAUQotyn7tNUYfRrrblHn5uZ8XTM/P1/V09PTosvKypQXiURU/fnp/SsuLi6Kbmtr8zWXsGBnAMEwgGAYQISyZjQ1Nal6YWFB9Pv7u/Ken59Fu1vSp6cn0RMTE8qrrKz0HP+7NcNdP+7u7kRXVVUpzz1mCRt2BhAMA4ionNq2traKnp+f956Mc3u5uLgQnZub6/lzR0dHqs7IyFB1enq6aPtLKdeLNewMIBgGEAwDiKisGQkJX4/02uuHMcbMzs6KjovTfxsfHx+iDw8PlWef2k5OTiovLS1N1Wtra6KLi4uVZ2+7Ozo6/jr/aMHOAIJhAMEwgIj50yEFBQWi3XcucnJyRE9NTSmvr6/P9xj9/f2ix8bGlBcfHy+6p6dHefYxfTRgZwDBMICI+W3KJjMzU9X2dtZ+oM0YY+rq6kTv7u76HsO99XR2doq+vb1VnvtOSNiwM4BgGEAwDCCg1gwX+52MgYEB5Z2fn4uurq5WnntMbpOcnKzqmZkZ0e6/xDg4OBDtfgv49vbmOUZQ2BlAMAwgoG9TNsfHx6ouLCwUbW9zjTFmY2PD93WLiopE7+3tKc++pbmnzUtLS77H8As7AwiGAQTDAALqv+p8R1JSkqrtJ0leX18DX/fk5ET01dWV8uwT5X8Zwy/sDCAYBhC/ZmvrvkY2NDQkurm5WXmPj4+BxnCvY3+h9fDwoLzGxkbRp6engcZzYWcAwTCAYBhA/Jo1Ixbs7OyILi8vV9729rbo2traHxmPnQEEwwDi13wCjwX7+/uiS0tLlWfX9jbXGGOWl5cDjcfOAIJhAMEwgOCa8Q32QxCJiYnK6+rqEl1TU6M8rhn/AQwDCH4CD8jm5qZo95Vp9zkuv7AzgGAYQDAMILhmAMHOAIJhAMEwgGAYQDAMIBgGEAwDCIYBBMMAgmEAwTCAYBhAMAwg/gB4n/BysY9JNAAAAABJRU5ErkJggg==\" y=\"-22.154489\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_19\"/>\r\n   <g id=\"matplotlib.axis_20\"/>\r\n   <g id=\"patch_48\">\r\n    <path d=\"M 1287.479661 121.154489 \r\nL 1287.479661 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_49\">\r\n    <path d=\"M 1386.316025 121.154489 \r\nL 1386.316025 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_50\">\r\n    <path d=\"M 1287.479661 121.154489 \r\nL 1386.316025 121.154489 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_51\">\r\n    <path d=\"M 1287.479661 22.318125 \r\nL 1386.316025 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_10\">\r\n    <!-- 4 -->\r\n    <g transform=\"translate(1333.080343 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-34\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_11\">\r\n   <g id=\"patch_52\">\r\n    <path d=\"M 10.7 239.758125 \r\nL 109.536364 239.758125 \r\nL 109.536364 140.921761 \r\nL 10.7 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p1b95cecf90)\">\r\n    <image height=\"99\" id=\"imagef57baaaf30\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"10.7\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADwklEQVR4nO2czSt0YRiHn3kRKRIl1j6KCEmxsFEWUzYjEvZYSAgbsrDzbWVrJav5B2z8AcpYyEfJR5GdWCjZsLvfcz+9j5n3zDnHb973d63uu/vMc57p6n7Ox5wzMWPMpyEQ/PrpCZDfUAYQlAEEZQBBGUBQBhCUAQRlAEEZQFAGEJQBBGUAQRlA5Ee9w8LCQpVPTU05t21ra5N4eHjYud3r66vKe3p6VH5ycvI3U/wx2BlAUAYQlAFEzETwS9/m5qbE19fXqra7uxv4/p6fn1VeUVER+D7CgJ0BBGUAEcoy1dnZqfKtrS2Ju7q6nJ+7u7tT+fn5ucTd3d2qVlJS4hzn81N/pcvLS4k7OjpU7e3tzTlO1LAzgKAMICgDiFCOGfv7+yofGRmR+OrqStXGx8clfnx8VDXvaXB7e7uq1dfXS7ywsKBqra2tzrl5T7ONMWZpaUni9/d35+eigJ0BBGUAEcoyZV/x7u3tSXxwcKBqdu6H6upqlXtPZY0xprS01PnZmpoaiW9ubrKeSzawM4CgDCAoA4hI7tpGzfr6usrn5uac287Pz0u8sbER2pwygZ0BBGUA8U8uU/ZDD99dWXtPg3t7e1Xt4eEh2ImlgZ0BBGUAQRlARP4QWxR8fHyofGVlReLl5WVVKygokDgvLy/ciaWBnQEEZQCRM8tUPB5XeVlZmXPb/Hz9taanp53bnp6eSnx/f+9naoHBzgCCMoCgDCCgjxnedzdWV1dVraioKOrphA47AwjKAIIygIA6ZiQSCZWvra1JbN8WD4qnp6dQxvUDOwMIygACapm6uLhQ+e3trcS1tbWqZt/y8Mv29nYg4wQBOwMIygCCMoDImadDRkdHVd7S0iKx/ZBaLBbLeNyZmRmJd3Z2/E0uINgZQFAGEDmzTNlUVVVJfHh4qGrNzc0Zj5NMJiUeGBjIfmJZwM4AgjKAoAwgcuaYYa/ni4uLEn/3qnE6GhoaJLbfBYwadgYQlAFEzixT3ofNjNFX4GdnZ6rW1NSU8bh89Zj8EcoAgjKAgPqlz2ZiYkLiuro653bf/R1FOiYnJyWenZ31PU4QsDOAoAwgoE5ty8vLVe59QKGysjKQfby8vKh8aGhIYvvub9SwM4CgDCAoAwioU9vBwUGVFxcXB76P/v5+lR8dHQW+D7+wM4CgDCCgTm1tGhsbJe7r61O1sbExiY+Pj1UtlUo5x7SfjbL/TeEnYWcAQRlAUAYQ0MeM/w12BhCUAQRlAEEZQFAGEJQBBGUAQRlAUAYQlAEEZQBBGUBQBhBf2bi4lSu6rlcAAAAASUVORK5CYII=\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_21\"/>\r\n   <g id=\"matplotlib.axis_22\"/>\r\n   <g id=\"patch_53\">\r\n    <path d=\"M 10.7 239.758125 \r\nL 10.7 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_54\">\r\n    <path d=\"M 109.536364 239.758125 \r\nL 109.536364 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_55\">\r\n    <path d=\"M 10.7 239.758125 \r\nL 109.536364 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_56\">\r\n    <path d=\"M 10.7 140.921761 \r\nL 109.536364 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_11\">\r\n    <!-- 3 -->\r\n    <g transform=\"translate(56.300682 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-33\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_12\">\r\n   <g id=\"patch_57\">\r\n    <path d=\"M 152.564407 239.758125 \r\nL 251.40077 239.758125 \r\nL 251.40077 140.921761 \r\nL 152.564407 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pd204338496)\">\r\n    <image height=\"99\" id=\"imagee828e6c685\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"152.564407\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADPElEQVR4nO2cP0hqYRjGPy93cSlIFxebGhocwsTJTZrFaGhoiFqEGgQhSjcDHRscGxP3qKE/cxBBLU4liIKIi4MKChHe7b3nlXu858Y9+lDPb3pe3tPnBz/ec+ycgx5jzNgQCH7MewPkN5QBBGUAQRlAUAYQlAEEZQBBGUBQBhCUAQRlAEEZQFAGEJQBBGUAQRlAUAYQlAEEZQBBGUBQBhCUAQRlAEEZQPycxYdkMhnJa2trqhePx23/zuPxSH58fLRds1arqd7Hx8en9jlvOBlAUAYQHuPCu7bHx8eqzuVykr1er+N13t7eJK+srKheo9GQvLm5qXrPz8+OPwMJTgYQlAEEZQDhyjWj3W6remFhQfLR0ZHqlUolR2vm83lVn5ycSL6/v1e9ra0tVfd6PUefMW84GUBQBhCunKYCgYCqr66uJAeDQdVLp9OSLy4ubNf0+/2q7nQ6tsfGYjFVPzw82G8WCE4GEJQBBGUA4cpd28mvtuFwWHI0GlW9l5cX23WWlpYkHxwc2B43GAxU3e12He0TDU4GEJQBhCtfbf8X1gdK6+vrqtdqtSTv7e2p3t3dnbsbcwlOBhCUAQRlAAF9zRiPx3/MxhiTSCQkX15ezmpLrsLJAIIygKAMIGbyEttnKRQKkiefEG5vb0u+vb1VvdFo5O7GXIKTAQRlAAF9mjo9PZX8/v6uejs7O5I3NjZUz/qOrjHG3NzcSEY+hXEygKAMICgDCOjbIU45OztT9eHhoaqtL8pls1nVm3xKOE84GUBQBhBf4jTl8/lUbf3P3Rhj9vf3JU++rFCv1yUXi0XVq1arkofDoeo1m83PbXYKnAwgKAMIygDiS1wz/sb5+bnkUCikepFIxNEa/X5f1eVyWfLT05PqVSoVyf9y+4WTAQRlAPEtTlPTsP5CQzKZVD3rA6zFxUXVm3xBwo7X11dVr66u2h7LyQCCMoCgDCC+/TVjGsvLy5Inf2bDej1JpVK2a1xfX6t6d3fX9lhOBhCUAQRPU0BwMoCgDCAoAwjKAIIygKAMICgDCMoAgjKAoAwgKAMIygCCMoCgDCAoAwjKAIIygKAMICgDCMoAgjKAoAwgKAMIygDiF5EarM5gPxKPAAAAAElFTkSuQmCC\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_23\"/>\r\n   <g id=\"matplotlib.axis_24\"/>\r\n   <g id=\"patch_58\">\r\n    <path d=\"M 152.564407 239.758125 \r\nL 152.564407 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_59\">\r\n    <path d=\"M 251.40077 239.758125 \r\nL 251.40077 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_60\">\r\n    <path d=\"M 152.564407 239.758125 \r\nL 251.40077 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_61\">\r\n    <path d=\"M 152.564407 140.921761 \r\nL 251.40077 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_12\">\r\n    <!-- 5 -->\r\n    <g transform=\"translate(198.165089 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-35\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_13\">\r\n   <g id=\"patch_62\">\r\n    <path d=\"M 294.428814 239.758125 \r\nL 393.265177 239.758125 \r\nL 393.265177 140.921761 \r\nL 294.428814 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pd6c3d72eb3)\">\r\n    <image height=\"99\" id=\"imagedeb30a6180\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"294.428814\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAES0lEQVR4nO2cTyguURjGz3fJnyKUwkaiWEmIpGwoZUGxQSIpWdkIGzsLCyvZyVpKSVgpRLEg5W9CFjZiY6HkP/fujvOezNxvPvON57rPb/W8vTPnnL6nd858Z85MSCn1WxEIfn33AMgHNAMImgEEzQCCZgBBM4CgGUDQDCBoBhA0A4jYoDuMj48XcWNjo9bV1dUid3Z2pnVDQ4NjmycnJ659rq6uOh67t7fnem6QsDKAoBlAhFQAq7Y5OTlaj4yMiFxLS0u0uxe8vr6KeGxsTOvZ2VmR29raCmJIGlYGEDQDCJoBRCBzRnd3t9YTExNhn7e7u6v17e2t43EpKSkiLi4u9jC6D+7u7kRs3navrKxE1KYXWBlA0AwgAvkHXlNTE9ZxJSUlIj49PdX64eHB8bzExEQRDw4Oirivr0/r5ORkx3bs3NzcnNb19fUit76+7thOpLAygKAZQNAMIAK5tc3MzNR6aWlJ5AoLC7VOS0sTObfbWS9kZGRobc4fSik1MDAQVhuHh4ciLioq+vrALFgZQNAMIAK5TJlkZWWJ2Px3bj/4mZmZ8b3/mJgYEZuXTfvhlom92mseu7Gx4cvYWBlA0AwgaAYQgW9IuLq6EvHw8HCg/b+9vYl4f39fa7c5IzZW/lQVFRVac874gdAMIAK/TH039uWmtLQ0onby8/P9GI6AlQEEzQCCZgDxX8wZbW1tWvf29opceXl5RG2en59/aUyfwcoAgmYAEfiqbaRkZ2eLOD09XWvz4ZFSSjU1NYm4q6tL61AoFFH/9gYEc5PF+/t7RG3asDKAoBlA0AwgoG5tKysrRTw0NKR1WVmZyJlzhl/Y137z3Y3R0VHXY/2AlQEEzQCCZgABNWfY/w/q6up872NnZ0fEi4uLWpsbnZVS6ujoyPf+3WBlAEEzgIBaDrFXUDc3N7W2N5+58fz8LGLzdbDl5WWRe3l58TLEqMLKAIJmAEEzgIC6td3e3hZxbW2t1u3t7SLX2dnp2I69TG4uv9tzD+cM8ik0AwioW1s34uLiRDw+Pq51R0eHyCUkJDi2Y7/ezI9/kU+hGUDQDCD+mTnDjdbWVhFPTU05Hvv09CTiqqoqre0V3aBhZQBBM4DwdJnKy8vT2n4/wfwGrc39/b3W9mtkfmB/Dcf+moG9Ac5kcnJS656eHn8H5hFWBhA0AwiaAYSnVVvz0w65ublhn3dzc6P1wcGBly415lfZlFKqoKBA69TUVJFzmyNsFhYWIhpPNGBlAEEzgPB0a2vuN+3v74/GeHzB3gd7fHys9fT0tMiZ8cXFRVTH9TdYGUDQDCBoBhCe5oykpCStm5ubRe7x8VFr+xMQ5nKF+RqwUkqtra1pfXl5Ge5QBNfX1yKen58X8XevxoYLKwMImgHEj3i49FNgZQBBM4CgGUDQDCBoBhA0AwiaAQTNAIJmAEEzgKAZQNAMIGgGEDQDCJoBBM0AgmYA8QeWzPc1OV0SKQAAAABJRU5ErkJggg==\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_25\"/>\r\n   <g id=\"matplotlib.axis_26\"/>\r\n   <g id=\"patch_63\">\r\n    <path d=\"M 294.428814 239.758125 \r\nL 294.428814 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_64\">\r\n    <path d=\"M 393.265177 239.758125 \r\nL 393.265177 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_65\">\r\n    <path d=\"M 294.428814 239.758125 \r\nL 393.265177 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_66\">\r\n    <path d=\"M 294.428814 140.921761 \r\nL 393.265177 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_13\">\r\n    <!-- 3 -->\r\n    <g transform=\"translate(340.029495 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-33\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_14\">\r\n   <g id=\"patch_67\">\r\n    <path d=\"M 436.29322 239.758125 \r\nL 535.129584 239.758125 \r\nL 535.129584 140.921761 \r\nL 436.29322 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p95e1bffbb1)\">\r\n    <image height=\"99\" id=\"image9e10898f73\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"436.29322\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEc0lEQVR4nO2cSyhuXxjGt1shEhMRGTFWBpQSMXApZOBSlIxMDFxKJoiUkpChgTAwUMolZEByyUQKE1IilwkiBkac2TrrXZ21z6HvWx7///MbPW/P/rZVj3ev/e211xfied6HRyAI/e4BkN8wDCAYBhAMAwiGAQTDAIJhAMEwgGAYQDAMIBgGEAwDCIYBBMMAgmEAwTCAYBhAMAwgGAYQDAOIcNd/sKysTNRtbW1K5+fnC+/jw/6uxNTUlNLHx8fCOzw8FPXW1tZnh/ktsDOAYBhAMAwgQjwHL7FlZWUpvbm5Kbzo6OjfgwkJEZ7fnOHH6+urqGdmZpRuaWn50jldwM4AgmEA4eTWNiIiQmn9smSSm5sr6szMTKUHBweFFxMTYz1PbGysqKurq5VeWVkR3urqqvU8rmFnAMEwgGAYQDiZMyoqKqzewsKC0vv7+8J7e3tT+uXlRXj6nDE9PS28oqIiUUdGRird29srvKOjI6Wfn5+FZ94iBxt2BhAMAwjnT23Nb9lmbSM0VP7f6J/TLzWe53lNTU2izsjIUHptbU14V1dXSre3twtvdHT0n8YWKNgZQDAMIBgGEE6e2nZ2dio9MDBgPS483D6F7e7uijo7O9t6bGFhoaj1lb6cnBzh7ezsWM+jzxkdHR3W4wIFOwMIhgGEk8tUSUmJ0ktLS9bj+vr6rHViYqLwJiYmlC4tLRWe3+KSeblJT09Xem5uTnhJSUl/PIfnBWeRip0BBMMAgmEA4WTO0FfeGhsbhTcyMqL03d2d8CYnJ5Xu7u4Wnv6Io6enR3i1tbWivr+/V3p9fV14w8PDSsfFxQlvY2ND6dPTU+Hp8+Dl5aUXCNgZQDAMIBgGEE4eoeurdBcXF9bjkpOTRd3Q0KC0uZp3dnam9NDQkPCioqJEXV5ernRdXZ3w9FXI6+tr69jMVcBgwM4AgmEA4eTWVsd8wWxxcVFpc3/G+/u70uYLbubLCzqtra1Wz3yMkZaWZj1WX11MSUkR3s3NjfVzX4WdAQTDAIJhAOH87ZCwsDBRHxwcKJ2Xlyc8fX+G6fnNGfojFhN9HvI8z0tNTbUe62J1T4edAQTDAML5Zerp6UnU29vbSvvdksbHx4tav9X0++ZsMjY29s/HuoadAQTDAIJhAOH8cYgfe3t7otb39N3e3gqvuLhY6fPz86COyxXsDCAYBhBQlymT/v5+pbu6uoSnbxlubm4WXjCeqLqAnQEEwwCCYQABPWf47cXzW6GrqqoStb69GRl2BhAMAwjoy5TOZ7Z/mduZ6+vrlZ6dnQ3swAIIOwMIhgEEwwDC+UrfV3l8fBS1/otq5p4+E31VsKCgQHjmD1h+J+wMIBgGED/m1tZE34o8Pz8vPPM2WH//6uTkRHj6ryk8PDwEcoifhp0BBMMAgmEA8WPnDD/Gx8dFXVNTo3RCQoLwlpeXla6srAzquP4GOwMIhgHEf/IyZeK3SKVvUfBbsHIBOwMIhgEEwwDifzFn/BTYGUAwDCAYBhAMAwiGAQTDAOIXW7cQc4IAxYkAAAAASUVORK5CYII=\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_27\"/>\r\n   <g id=\"matplotlib.axis_28\"/>\r\n   <g id=\"patch_68\">\r\n    <path d=\"M 436.29322 239.758125 \r\nL 436.29322 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_69\">\r\n    <path d=\"M 535.129584 239.758125 \r\nL 535.129584 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_70\">\r\n    <path d=\"M 436.29322 239.758125 \r\nL 535.129584 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_71\">\r\n    <path d=\"M 436.29322 140.921761 \r\nL 535.129584 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_14\">\r\n    <!-- 6 -->\r\n    <g transform=\"translate(481.893902 134.921761)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 2113 2584 \r\nQ 1688 2584 1439 2293 \r\nQ 1191 2003 1191 1497 \r\nQ 1191 994 1439 701 \r\nQ 1688 409 2113 409 \r\nQ 2538 409 2786 701 \r\nQ 3034 994 3034 1497 \r\nQ 3034 2003 2786 2293 \r\nQ 2538 2584 2113 2584 \r\nz\r\nM 3366 4563 \r\nL 3366 3988 \r\nQ 3128 4100 2886 4159 \r\nQ 2644 4219 2406 4219 \r\nQ 1781 4219 1451 3797 \r\nQ 1122 3375 1075 2522 \r\nQ 1259 2794 1537 2939 \r\nQ 1816 3084 2150 3084 \r\nQ 2853 3084 3261 2657 \r\nQ 3669 2231 3669 1497 \r\nQ 3669 778 3244 343 \r\nQ 2819 -91 2113 -91 \r\nQ 1303 -91 875 529 \r\nQ 447 1150 447 2328 \r\nQ 447 3434 972 4092 \r\nQ 1497 4750 2381 4750 \r\nQ 2619 4750 2861 4703 \r\nQ 3103 4656 3366 4563 \r\nz\r\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-36\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_15\">\r\n   <g id=\"patch_72\">\r\n    <path d=\"M 578.157627 239.758125 \r\nL 676.993991 239.758125 \r\nL 676.993991 140.921761 \r\nL 578.157627 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p75ed6ce94a)\">\r\n    <image height=\"99\" id=\"image94bb778e0f\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"578.157627\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAACIElEQVR4nO3dMariUBhA4WQYRNyArSBWgljpHtyKS3AjtlaCpYUIVhauwQ0IFraCaOPrMt6BDOiY5NxwviohFj8c/tz3XvFMkyR5JkL4VfUA+sMYIMYAMQaIMUCMAWIMEGOAGAPEGCC/qx7gU51OJ7teLpfBs8ViEdzP5/MyRvpvbgaIMUCifU3NZrPsejweB89ut1tw72tKbzMGiDFAoj0zhsNh7rPr9VreIF/kZoAYAySa11Sj0Qjum81m7md3u13R4xTCzQAxBogxQKI5M9rtdnDf7/crmqQ4bgaIMUCieU29Y7PZVD3CR9wMEGOAGAOklmfG/X6veoSPuBkgxgAxBogxQIwBYgyQWv5o2+12g/vT6VTRJO9xM0CMAVLL19RgMAju9/t9RZO8x80AMQaIMUCiPTPSNM2un896/GMgNwPEGCDGAIn2zKjLOfHKzQAxBogxQIwBYgwQY4AYA8QYIMYAifY38H/91fbxeJQ9zle4GSDGADEGSLRnxus58fcZsV6vyx7nK9wMEGOARPOaGo1Guc9Wq1Vwfz6fix6nEG4GiDFAjAESzZkxnU5znx2PxxInKY6bAWIMEPRrqtVqZde9Xi/3c5fLpYxxCudmgBgDxBgg6DPj9XswDodD8GwymWTX2+22tJmK5GaAGAMkTfxydgw3A8QYIMYAMQaIMUCMAWIMEGOAGAPEGCDGADEGiDFAjAFiDBBjgBgD5AeyoEmz+r/rNwAAAABJRU5ErkJggg==\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_29\"/>\r\n   <g id=\"matplotlib.axis_30\"/>\r\n   <g id=\"patch_73\">\r\n    <path d=\"M 578.157627 239.758125 \r\nL 578.157627 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_74\">\r\n    <path d=\"M 676.993991 239.758125 \r\nL 676.993991 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_75\">\r\n    <path d=\"M 578.157627 239.758125 \r\nL 676.993991 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_76\">\r\n    <path d=\"M 578.157627 140.921761 \r\nL 676.993991 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_15\">\r\n    <!-- 1 -->\r\n    <g transform=\"translate(623.758309 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-31\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_16\">\r\n   <g id=\"patch_77\">\r\n    <path d=\"M 720.022034 239.758125 \r\nL 818.858398 239.758125 \r\nL 818.858398 140.921761 \r\nL 720.022034 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pb0a04ea935)\">\r\n    <image height=\"99\" id=\"image6dd5d737c6\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"720.022034\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAD/0lEQVR4nO2dPSwsURTH7z4fhY+IREOIROOzUukkCEtFqHwUGoVEJBRCJxKlhIhNKCQKks02q0OUREGFBCFBIlEo0CnwuvPuue/Ny2Jm/Ff+v+p/cmZnjvxz7p3duXdEjDHvhkDw67sLIH+gGUDQDCAyw75gc3Ozire2tkR3d3erXDKZDKUmFNgZQNAMIEIfplpbWz1zc3NzKj47OxN9fn4eWE0osDOAoBlA0AwgQp8z1tbWVFxTUyO6vb1d5UZHR0XPz8+r3E+cQ9gZQNAMIEIfpk5PT1X8/PzseezQ0JDo4+NjleMwRQKFZgBBM4CImG9+0ldVVSV6fHxc5QYHB0VfXFyonH0bfHNzE1B14cLOAIJmAPHtw5SNPWQZY8zJyYnnsVdXV6IrKysDqylM2BlA0AwgaAYQUHNGfn6+ildWVkT39PR4fm5sbEzFi4uLKn57e/OhuuBhZwBBM4CAGqZccnJyRPf396vc0tKS6EgkonLr6+sqHhkZEf34+Ohjhf7CzgCCZgBBM4CAnjNssrOzVWyvw3UXxr2/6z/JXtgQi8VUDum2l50BBM0AIm2GKZfZ2VnRk5OTKve/ocdep2UM1sIGdgYQNAMImgFE2s4ZNq+vryp2b21thoeHVby8vBxITZ+BnQEEzQAi9LW2QdDZ2anieDyu4qysLNELCwsql5GRIdr9dh427AwgaAYQNAOIQG5t3TcdTE1NiX56elK53t5e0ff3975c3/15ZGZmxvNYe79IW1ubyvlVT6qwM4CgGUDQDCACmTPsN+UY8/ebdGz29/dFT09Pq9zu7u6nrl9YWKjiaDQq2v0ukZeX989a3Ho+W8tHYGcAQTOACGSYchcIJBIJ0fbCNJfb21sVDwwMiN7b2/Olts3NTRV3dHR4Hmu/lcHd4hYE7AwgaAYQNAOIUJ70bW9vi25qakr5cy8vL6InJiZU7uDgQPTh4WHK57QXTBujX4nhcn19LbqhoUHlHh4eUr5mqrAzgKAZQIQyTLW0tIi2t4YZY0xZWdmXz19bW6tidwgpKioSXVJSonKrq6uiS0tLPa+xs7OjYvdFZX7AzgCCZgBBM4AIfRFbcXGxijc2NkRXVFR4fq6goEDFubm5ot09fUdHRyqur6//cJ0ud3d3Ki4vL//yOV3YGUDQDCDSZq1tY2Ojiuvq6jxzXV1dKnaHsVSx93lcXl6qnLvPww/YGUDQDCBoBhBpM2d8BPepnL1tubq6WuX6+vo8z2P//w73J5cgYGcAQTOA+JHDVLrCzgCCZgBBM4CgGUDQDCBoBhA0AwiaAQTNAIJmAEEzgKAZQNAMIGgGEDQDCJoBBM0AgmYAQTOAoBlA0AwgaAYQNAMImgHEb9V85RRBGxGTAAAAAElFTkSuQmCC\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_31\"/>\r\n   <g id=\"matplotlib.axis_32\"/>\r\n   <g id=\"patch_78\">\r\n    <path d=\"M 720.022034 239.758125 \r\nL 720.022034 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_79\">\r\n    <path d=\"M 818.858398 239.758125 \r\nL 818.858398 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_80\">\r\n    <path d=\"M 720.022034 239.758125 \r\nL 818.858398 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_81\">\r\n    <path d=\"M 720.022034 140.921761 \r\nL 818.858398 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_16\">\r\n    <!-- 7 -->\r\n    <g transform=\"translate(765.622716 134.921761)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 525 4666 \r\nL 3525 4666 \r\nL 3525 4397 \r\nL 1831 0 \r\nL 1172 0 \r\nL 2766 4134 \r\nL 525 4134 \r\nL 525 4666 \r\nz\r\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-37\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_17\">\r\n   <g id=\"patch_82\">\r\n    <path d=\"M 861.886441 239.758125 \r\nL 960.722804 239.758125 \r\nL 960.722804 140.921761 \r\nL 861.886441 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p70a4bc85b2)\">\r\n    <image height=\"99\" id=\"imageea84d965a4\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"861.886441\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAEF0lEQVR4nO2cSyh9URTGN5FXJogJJQkxIAMxEYpCJjIwUYYYYywyMjFUKCMTA1GKMjCSvMJIyWNgoiTvKI//bNlr9z/33i7nnC++3+hbrevsU5+19777rnMSjDGfhkCQGPYNkC9oBhA0AwiaAQTNAIJmAEEzgKAZQNAMIGgGEDQDCJoBBM0AgmYAQTOAoBlA0AwgkoIYZGxsTPTg4KDKJSbG9v+wvLys4tnZWdGrq6vfuDscWBlA0AwgEowPDQnHx8cqLikpET03N6dy2dnZog8PD1Xu7OxM9NDQkMqVlpaK3tnZUbn+/n4VHxwcRL9pAFgZQNAMIGgGEL6sGR8fHyq25+yamhqVe3t7i+maqampKl5YWBDd3t6ucq+vrypubW0VvbGxEdN4YcDKAIJmAOHLNPX5qS95fn4uurOzU+Xi3XYmJX0dHoyPj6vcwMCAip+enkS3tbWp3P7+flzj+wErAwiaAQTNAMKXNWNtbU3Fzc3Not1t5/r6umh7bTHGmKWlJc+/u7i4EH15ealykY5j7CMWY4ypqqoS/fj4aMKElQEEzQDCl2kqLS1NxSMjI6I7OjpUrqysLK4x7u/vRT88PKhcXl6eiu1tsMvMzIzoqakplQt628vKAIJmAEEzgPBlzYiEu57k5uaKrq6uVrna2lrRTU1Nntd0T3QrKiriurf393cVu1tmG/sXy5WVFZW7vr4WbW/Bo8HKAIJmABH4NOUHKSkpKs7Pz1dxfX29aLvfyuXo6EjFe3t7ot0pNCsrS3RBQYHK2VvtxcVFlevt7fUcn5UBBM0AgmYAEUivrd+4J7qnp6cqjnQcYtPX16fira0tz8/m5OSIrqysVLm6ujrRduNENFgZQNAMIGgGEL/ie0Y07O8hbjeK3UA9OjqqcvbRfxCwMoCgGUD8iq1tNOyt78vLi+fnMjMzg7gdT1gZQNAMIGgGEH9izUhOThYd69FIGLAygKAZQARes27zgP2GhOfnZ1/GLCoqEh2pWeHk5MSX8WOFlQEEzQCCZgAR+JrR2Nio4snJSdHDw8MqZz+f8R3c7hGbq6sr0fPz8z8yXrywMoCgGUAEPk25b0QoLi4W3d3drXI/NU11dXV55uxTXPuZjzBgZQBBM4CgGUCE3pCwu7srurCwUOWmp6dFT0xMqNzNzY3nNd3nBLe3t0Wnp6ernN2E4DYkBA0rAwiaAUTo05Tds2o/BmyMfkz59vZW5TY3Nz2v2dDQoOKMjAzR7tsTysvLY71V32FlAEEzgKAZQIS+ZkSip6dHdEtLi8rZb8Ox+2X/h/2chfu6jLu7u2/c4c/CygCCZgABPU39NVgZQNAMIGgGEDQDCJoBBM0AgmYAQTOAoBlA0AwgaAYQNAMImgEEzQCCZgBBM4CgGUD8A5eX9brZIbvaAAAAAElFTkSuQmCC\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_33\"/>\r\n   <g id=\"matplotlib.axis_34\"/>\r\n   <g id=\"patch_83\">\r\n    <path d=\"M 861.886441 239.758125 \r\nL 861.886441 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_84\">\r\n    <path d=\"M 960.722804 239.758125 \r\nL 960.722804 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_85\">\r\n    <path d=\"M 861.886441 239.758125 \r\nL 960.722804 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_86\">\r\n    <path d=\"M 861.886441 140.921761 \r\nL 960.722804 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_17\">\r\n    <!-- 2 -->\r\n    <g transform=\"translate(907.487122 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-32\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_18\">\r\n   <g id=\"patch_87\">\r\n    <path d=\"M 1003.750847 239.758125 \r\nL 1102.587211 239.758125 \r\nL 1102.587211 140.921761 \r\nL 1003.750847 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p20609aa621)\">\r\n    <image height=\"99\" id=\"image6c0b11acd5\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1003.750847\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAAETUlEQVR4nO2cSyh1XxjG15GilAgpA2bKrYykhCgTJKGYINeBQpFSrjFgoAwoZigDRZLLQC4pQyIZMSJFuWQgIcl/9lrv7jtyzsf2fP+e3+h5e3Z7rzy9a+2zrb09xph3QyAI+O0BkA8YBhAMAwiGAQTDAIJhAMEwgGAYQDAMIBgGEIFuXCQ8PFx0Q0OD8np6ekTv7+8rb3l5WfTo6OgPjQ4HdgYQDAMIV6ap6upq0UNDQ16Py87OVnVKSorosLAw5Q0PD4t+enr6yxFiwM4AgmEAwTCAcGXNSEhI8OotLCyIjo6OVl5mZqbo7u5u5dm3wSsrK387RAjYGUAwDCBcmaaur6+9elFRUaLz8vKUV1xcLHpubk55U1NTohcXF5XX2NjozzB/HXYGEAwDCIYBhCtrRkDAR+Yej0d5dv36+qq8paUl0a2trcrr7e0VXV9fr7zDw0NVT0xM+DbgX4KdAQTDAMKVaWpjY0N0U1OT8rKyskQXFhYqb3NzU/Tq6qry7GkrIiJCefbt8r8EOwMIhgEEwwDCY1x+P6OyslLV09PTH4Nx3PZ2dXWJHh8fV579qMQ+hzHGzMzMqLq2ttaPkboPOwMIhgGE69NUTEyMqmtqakQPDg4q7/39Y2gHBwfKOzo6+uM5jDFmb29P1enp6f4N1mXYGUAwDCAYBhCurxmfMT8/r+qSkhK/zrO2tqbqoqIiv8fkJuwMIBgGEK48tf0qFRUVqrY3IZSWln75PM5f8v8K7AwgGAYQDAMIqDXj7e1N1bu7u6J9uc0tKChQtb0Xt729XXmnp6e+DPFHYWcAwTCAYBhAQK0ZTuLi4r7lPPn5+aKvrq6UZz+2v7i4+Jbr+Qs7AwiGAQTUNBUUFKTq0NBQr8deXl6Kbm5uVp7zawqxsbGi6+rqlHd8fCx6bGzs64P9AdgZQDAMIBgGEFBrRmpqqqo/29Wxvb0t2t5YbYwxGRkZqp6cnBTtfFTS19cnOjBQ/znc/pIPOwMIhgEE1DRVVlam6qSkJNHn5+fK6+zsFP34+Kg8Z93W1ib6+fnZ6zUHBgaUZx/rxqto7AwgGAYQDAMIqE1s/f39qu7o6BAdHBysPPsdjJubG+WNjIyo2vadt8/r6+uiIyMjlXd7eyva+QTZufZ8B+wMIBgGEFDTlJOWlhbRvvwafnl5UbW9hzc3N1d5zvdFbOzNcFVVVcqbnZ398ni+CjsDCIYBBMMAAnrNSE5OFm2vH8Z8vlkhPj5e1fZ/+pzYHytOTExUnv1689bWlvLKy8tF393deT2/L7AzgGAYQEBPU/7ivF397Cs79/f3onNycpRnf5Ty5OREeWlpaaIfHh78GqcTdgYQDAMIhgHE/3LN8JeQkBBV7+zsiHauQ/amh7Ozs2+5PjsDCIYBBKcpINgZQDAMIBgGEAwDCIYBBMMAgmEAwTCAYBhAMAwgGAYQDAMIhgEEwwCCYQDBMIBgGED8B1ux8bC/8/VcAAAAAElFTkSuQmCC\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_35\"/>\r\n   <g id=\"matplotlib.axis_36\"/>\r\n   <g id=\"patch_88\">\r\n    <path d=\"M 1003.750847 239.758125 \r\nL 1003.750847 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_89\">\r\n    <path d=\"M 1102.587211 239.758125 \r\nL 1102.587211 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_90\">\r\n    <path d=\"M 1003.750847 239.758125 \r\nL 1102.587211 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_91\">\r\n    <path d=\"M 1003.750847 140.921761 \r\nL 1102.587211 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_18\">\r\n    <!-- 8 -->\r\n    <g transform=\"translate(1049.351529 134.921761)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 2034 2216 \r\nQ 1584 2216 1326 1975 \r\nQ 1069 1734 1069 1313 \r\nQ 1069 891 1326 650 \r\nQ 1584 409 2034 409 \r\nQ 2484 409 2743 651 \r\nQ 3003 894 3003 1313 \r\nQ 3003 1734 2745 1975 \r\nQ 2488 2216 2034 2216 \r\nz\r\nM 1403 2484 \r\nQ 997 2584 770 2862 \r\nQ 544 3141 544 3541 \r\nQ 544 4100 942 4425 \r\nQ 1341 4750 2034 4750 \r\nQ 2731 4750 3128 4425 \r\nQ 3525 4100 3525 3541 \r\nQ 3525 3141 3298 2862 \r\nQ 3072 2584 2669 2484 \r\nQ 3125 2378 3379 2068 \r\nQ 3634 1759 3634 1313 \r\nQ 3634 634 3220 271 \r\nQ 2806 -91 2034 -91 \r\nQ 1263 -91 848 271 \r\nQ 434 634 434 1313 \r\nQ 434 1759 690 2068 \r\nQ 947 2378 1403 2484 \r\nz\r\nM 1172 3481 \r\nQ 1172 3119 1398 2916 \r\nQ 1625 2713 2034 2713 \r\nQ 2441 2713 2670 2916 \r\nQ 2900 3119 2900 3481 \r\nQ 2900 3844 2670 4047 \r\nQ 2441 4250 2034 4250 \r\nQ 1625 4250 1398 4047 \r\nQ 1172 3844 1172 3481 \r\nz\r\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-38\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_19\">\r\n   <g id=\"patch_92\">\r\n    <path d=\"M 1145.615254 239.758125 \r\nL 1244.451618 239.758125 \r\nL 1244.451618 140.921761 \r\nL 1145.615254 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pba5d671749)\">\r\n    <image height=\"99\" id=\"image92f2b53e90\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1145.615254\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADxUlEQVR4nO2dTSh8URjG3/nnayNZipUslFDKghSl5GNF9pSVsCILdlIWslFij2wsJisfC4mlxEJZyYJSSBH5yti9//PezDQz7p37DM9v9Zwe13nr6T3nzr1niIhITAgE/8IugPyHYQDBMIBgGEAwDCAYBhAMAwiGAQTDAIJhAMEwgGAYQDAMIBgGEAwDCIYBBMMAIifsAhIxNDSkenZ21nj5+flxr3t8fDTj+fl51dPT08Z7e3v7SYm+ws4AgmEAERGgAwnusiRil6bR0VHjra6uqi4vLzdebW2tGU9MTKh+eXkxXmdnp+qrq6sUK/YXdgYQDAMIhgFE6HtGSUmJ6sPDQ+O5t6GLi4tpz5Gbmxv39zQ0NKhubm423u3tbdpzpgM7AwiGAUToy1Rra6vqnZ0d4xUVFan2fqpOF3fJEhGJRqOqz8/PjTcyMuLLnMnCzgCCYQDBMIAI/altJBL5VgfF+/u7GS8tLaleXl42HveMPwzDACL0ZSoWi32rM8Xe3p7qwsLCjM/vws4AgmEAwTCACH3PSERpaanqs7Mz47nre15envHu7u6SnqOsrCzN6vyHnQEEwwAi9GXq+vo6rldZWanau0xVVVWp7uvrM97g4GDS87s/e3BwkPR1QcDOAIJhAMEwgAh9zzg9PVX98fFhvJyc+OUdHR2pXltbM15vb68Zb21tqXYPrYmIDAwMqO7p6Umi4uBgZwDBMIBgGECEfjrExX3rJiLS2Niour6+3nivr6+q+/v7jTc3N2fGxcXF314nIjI2NqZ6YWEhtYJ9hp0BBMMAAmqZampqMuPd3V3V1dXVxvM+HklES0uL6pubG+O5t9Zhw84AgmEAwTCAgNozvOzv76t+enoyXnt7e6bLCRx2BhAMA4jQn9omYnt7W/X4+Ljx6urqVLtPcLMZdgYQDAMIhgEE9K2t+5dzLi4ujHd8fKy6o6MjQxUFCzsDCIYBBPStrfsiaGVlxXjDw8OqvedlLy8vgy0sINgZQDAMIBgGENC3ti4FBQVmvLm5Gddra2sz44eHh+AK8xF2BhAMA4isWaa8VFRUqD45OTGe+1JKxJ6v/fz8DLawH8DOAIJhAMEwgMjaPcOlq6vLjNfX183YPcM7OTlpvOfn5+AKSxF2BhAMA4hfsUx5cb9KIGI/rXvP2m5sbKiempoy3v39fQDVxYedAQTDAIJhAPEr9wwv7v/XmJmZMV53d7fqmpoa46XyHRA/YGcAwTCA+BPLVLbAzgCCYQDBMIBgGEAwDCAYBhAMAwiGAQTDAIJhAPEFu4jVAF8BmO4AAAAASUVORK5CYII=\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_37\"/>\r\n   <g id=\"matplotlib.axis_38\"/>\r\n   <g id=\"patch_93\">\r\n    <path d=\"M 1145.615254 239.758125 \r\nL 1145.615254 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_94\">\r\n    <path d=\"M 1244.451618 239.758125 \r\nL 1244.451618 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_95\">\r\n    <path d=\"M 1145.615254 239.758125 \r\nL 1244.451618 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_96\">\r\n    <path d=\"M 1145.615254 140.921761 \r\nL 1244.451618 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_19\">\r\n    <!-- 6 -->\r\n    <g transform=\"translate(1191.215936 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-36\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_20\">\r\n   <g id=\"patch_97\">\r\n    <path d=\"M 1287.479661 239.758125 \r\nL 1386.316025 239.758125 \r\nL 1386.316025 140.921761 \r\nL 1287.479661 140.921761 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p7369e10eea)\">\r\n    <image height=\"99\" id=\"image11a181503b\" transform=\"scale(1 -1)translate(0 -99)\" width=\"99\" x=\"1287.479661\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAGMAAABjCAYAAACPO76VAAADnklEQVR4nO2cPSyrYRTHT0V8DcRHlzJIaiiLQYjRYK9FRFJCTBKrSBq7hEgXi0gsBguhNoPoxKKLr6WLgc0sZai7nfucJ27itn1f//fe/2/6PznUSX7O87xebxsTkU8hEDT8dAPkN5QBBGUA0RjGDxkbG9N8fHxsavv7+5r39vZM7fn5OdjGwOBkAEEZQMQk5Evb5eVls97Z2dF8dXVlapOTk5rf39+DbQwATgYQlAEEZQAR+pnR2tpq1pubm5r988S9DJ6ZmQm2MQA4GUBQBhChb1M+/f39movFoqm1tLRozmQypnZychJoXz8BJwMIygCCMoD48TPDxb39ISKSz+c1VyoVU3PPEPfrogwnAwjKAAJqm/LZ3d3VvLS0ZGqHh4ea5+bmQuspSDgZQFAGEJQBBPSZ0dHRofn29tbUent7Na+trZna9vZ2sI0FBCcDCMoAAnqbckmlUma9tbWleXR01NRWVlbM+ujoKLjG6ggnAwjKAIIygIjMmeEzNTWl2X9+t1AomLV7K+Xp6SnArmqDkwEEZQARylsCgsB9/qqhwf5OTUxMmHVTU1MYLdUMJwMIygCCMoCI7Jlxd3en2X9Y4fMzklfrnAwkKAOIyGxT4+PjZt3X1/ft781ms5oXFhbq1VLd4WQAQRlAUAYQ0HdtHx4eNLvv4xARaW5u1hyLxUzNv7R9e3vT7J89j4+PtbZZNzgZQFAGEJQBBPTfGd3d3ZrdM0JE5ObmRrN/ZoyMjJh1W1ub5qGhIVPjmUG+hDKAgL60vbi40Oz/9252dlbz2dmZqSWTSbN2b4H4W1g8Hv/yNUVE7u/v/6rfWuFkAEEZQFAGENCXtu5tDf8WR2dnp+ZyuWxq7m0UEZHV1VXNAwMDpnZ9fa35/Pzc1NwPunx5eflu21XDyQCCMoCA3qb8DwpzSafTmt23KNdCe3u7Wff09GjmNvWfQRlAUAYQ0LdD3D378vLS1AYHBzW/vr6a2unpqVm7n7ozPz9vatPT05pLpZKpDQ8Pa/74+Phm19XDyQCCMoCA3qZc/AcJcrmcZvcvZZHqn7U9ODgw68XFxapep1o4GUBQBhCUAURkzgyfrq4uzf7npLsPOouIJBKJP77O+vq65o2NjTp1Vx2cDCAoA4jIblP/IpwMICgDCMoAgjKAoAwgKAMIygCCMoCgDCAoAwjKAIIygKAMICgDCMoAgjKAoAwgKAMIygCCMoCgDCAoAwjKAIIygPgFW7m5KM23BFEAAAAASUVORK5CYII=\" y=\"-140.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_39\"/>\r\n   <g id=\"matplotlib.axis_40\"/>\r\n   <g id=\"patch_98\">\r\n    <path d=\"M 1287.479661 239.758125 \r\nL 1287.479661 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_99\">\r\n    <path d=\"M 1386.316025 239.758125 \r\nL 1386.316025 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_100\">\r\n    <path d=\"M 1287.479661 239.758125 \r\nL 1386.316025 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_101\">\r\n    <path d=\"M 1287.479661 140.921761 \r\nL 1386.316025 140.921761 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_20\">\r\n    <!-- 9 -->\r\n    <g transform=\"translate(1333.080343 134.921761)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-39\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pae6a09b459\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"10.7\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p701c5e40b3\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"152.564407\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p2497e45077\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"294.428814\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pae2a5dc3f3\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"436.29322\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p7b5f581da0\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"578.157627\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p9e0eb332be\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"720.022034\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p7cdddeff3a\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"861.886441\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p9f2def4c7b\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1003.750847\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pcdc72ac603\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1145.615254\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p712fa84b47\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1287.479661\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p1b95cecf90\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"10.7\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd204338496\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"152.564407\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd6c3d72eb3\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"294.428814\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p95e1bffbb1\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"436.29322\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p75ed6ce94a\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"578.157627\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pb0a04ea935\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"720.022034\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p70a4bc85b2\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"861.886441\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p20609aa621\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1003.750847\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pba5d671749\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1145.615254\" y=\"140.921761\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p7369e10eea\">\r\n   <rect height=\"98.836364\" width=\"98.836364\" x=\"1287.479661\" y=\"140.921761\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "P3XDuBTOwZA3",
        "outputId": "af9ff40a-5951-4965-ee91-665806e1eee5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "metadata": {
        "id": "BXtqPAnVwc8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class ConvLayer(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, in_channels=1, out_channels=256):\r\n",
        "        '''Constructs the ConvLayer with a specified input and output size.\r\n",
        "           param in_channels: input depth of an image, default value = 1\r\n",
        "           param out_channels: output depth of the convolutional layer, default value = 256\r\n",
        "           '''\r\n",
        "        super(ConvLayer, self).__init__()\r\n",
        "\r\n",
        "        # defining a convolutional layer of the specified size\r\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, \r\n",
        "                              kernel_size=9, stride=1, padding=0)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input to the layer; an input image\r\n",
        "           return: a relu-activated, convolutional layer\r\n",
        "           '''\r\n",
        "        # applying a ReLu activation to the outputs of the conv layer\r\n",
        "        features = F.relu(self.conv(x)) # will have dimensions (batch_size, 20, 20, 256)\r\n",
        "        return features"
      ],
      "outputs": [],
      "metadata": {
        "id": "f7y0uI3ywf5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class PrimaryCaps(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32):\r\n",
        "        '''Constructs a list of convolutional layers to be used in \r\n",
        "           creating capsule output vectors.\r\n",
        "           param num_capsules: number of capsules to create\r\n",
        "           param in_channels: input depth of features, default value = 256\r\n",
        "           param out_channels: output depth of the convolutional layers, default value = 32\r\n",
        "           '''\r\n",
        "        super(PrimaryCaps, self).__init__()\r\n",
        "\r\n",
        "        # creating a list of convolutional layers for each capsule I want to create\r\n",
        "        # all capsules have a conv layer with the same parameters\r\n",
        "        self.capsules = nn.ModuleList([\r\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \r\n",
        "                      kernel_size=9, stride=2, padding=0)\r\n",
        "            for _ in range(num_capsules)])\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input; features from a convolutional layer\r\n",
        "           return: a set of normalized, capsule output vectors\r\n",
        "           '''\r\n",
        "        # get batch size of inputs\r\n",
        "        batch_size = x.size(0)\r\n",
        "        # reshape convolutional layer outputs to be (batch_size, vector_dim=1152, 1)\r\n",
        "        u = [capsule(x).view(batch_size, 32 * 6 * 6, 1) for capsule in self.capsules]\r\n",
        "        # stack up output vectors, u, one for each capsule\r\n",
        "        u = torch.cat(u, dim=-1)\r\n",
        "        # squashing the stack of vectors\r\n",
        "        u_squash = self.squash(u)\r\n",
        "        return u_squash\r\n",
        "    \r\n",
        "    def squash(self, input_tensor):\r\n",
        "        '''Squashes an input Tensor so it has a magnitude between 0-1.\r\n",
        "           param input_tensor: a stack of capsule inputs, s_j\r\n",
        "           return: a stack of normalized, capsule output vectors, v_j\r\n",
        "           '''\r\n",
        "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\r\n",
        "        scale = squared_norm / (1 + squared_norm) # normalization coeff\r\n",
        "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \r\n",
        "        return output_tensor"
      ],
      "outputs": [],
      "metadata": {
        "id": "FsvxVCgDwjat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "def softmax(input_tensor, dim=1):\r\n",
        "    # transpose input\r\n",
        "    transposed_input = input_tensor.transpose(dim, len(input_tensor.size()) - 1)\r\n",
        "    # calculate softmax\r\n",
        "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\r\n",
        "    # un-transpose result\r\n",
        "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input_tensor.size()) - 1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vYhvYM6szTHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "#import helpers # to get transpose softmax function\r\n",
        "\r\n",
        "# dynamic routing\r\n",
        "def dynamic_routing(b_ij, u_hat, squash, routing_iterations=3):\r\n",
        "    '''Performs dynamic routing between two capsule layers.\r\n",
        "       param b_ij: initial log probabilities that capsule i should be coupled to capsule j\r\n",
        "       param u_hat: input, weighted capsule vectors, W u\r\n",
        "       param squash: given, normalizing squash function\r\n",
        "       param routing_iterations: number of times to update coupling coefficients\r\n",
        "       return: v_j, output capsule vectors\r\n",
        "       '''    \r\n",
        "    # update b_ij, c_ij for number of routing iterations\r\n",
        "    for iteration in range(routing_iterations):\r\n",
        "        # softmax calculation of coupling coefficients, c_ij\r\n",
        "        c_ij = softmax(b_ij, dim=2)\r\n",
        "         #helpers.\r\n",
        "        \r\n",
        "\r\n",
        "        # calculating total capsule inputs, s_j = sum(c_ij*u_hat)\r\n",
        "        s_j = (c_ij * u_hat).sum(dim=2, keepdim=True)\r\n",
        "\r\n",
        "        # squashing to get a normalized vector output, v_j\r\n",
        "        v_j = squash(s_j)\r\n",
        "\r\n",
        "        # if not on the last iteration, calculate agreement and new b_ij\r\n",
        "        if iteration < routing_iterations - 1:\r\n",
        "            # agreement\r\n",
        "            a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\r\n",
        "            \r\n",
        "            # new b_ij\r\n",
        "            b_ij = b_ij + a_ij\r\n",
        "    \r\n",
        "    return v_j # return latest v_j"
      ],
      "outputs": [],
      "metadata": {
        "id": "skUSggXGwm0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# it will also be relevant, in this model, to see if I can train on gpu\r\n",
        "TRAIN_ON_GPU = False#torch.cuda.is_available()\r\n",
        "\r\n",
        "if(TRAIN_ON_GPU):\r\n",
        "    print('Training on GPU!')\r\n",
        "else:\r\n",
        "    print('Only CPU available')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only CPU available\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaDbIgfCxER-",
        "outputId": "c421a444-2aa3-4c5a-84f8-a993a958dca9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "class DigitCaps(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, num_capsules=10, previous_layer_nodes=32*6*6, \r\n",
        "                 in_channels=8, out_channels=16):\r\n",
        "        '''Constructs an initial weight matrix, W, and sets class variables.\r\n",
        "           param num_capsules: number of capsules to create\r\n",
        "           param previous_layer_nodes: dimension of input capsule vector, default value = 1152\r\n",
        "           param in_channels: number of capsules in previous layer, default value = 8\r\n",
        "           param out_channels: dimensions of output capsule vector, default value = 16\r\n",
        "           '''\r\n",
        "        super(DigitCaps, self).__init__()\r\n",
        "\r\n",
        "        # setting class variables\r\n",
        "        self.num_capsules = num_capsules\r\n",
        "        self.previous_layer_nodes = previous_layer_nodes # vector input (dim=1152)\r\n",
        "        self.in_channels = in_channels # previous layer's number of capsules\r\n",
        "\r\n",
        "        # starting out with a randomly initialized weight matrix, W\r\n",
        "        # these will be the weights connecting the PrimaryCaps and DigitCaps layers\r\n",
        "        self.W = nn.Parameter(torch.randn(num_capsules, previous_layer_nodes, \r\n",
        "                                          in_channels, out_channels))\r\n",
        "\r\n",
        "    def forward(self, u):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param u: the input; vectors from the previous PrimaryCaps layer\r\n",
        "           return: a set of normalized, capsule output vectors\r\n",
        "           '''\r\n",
        "        \r\n",
        "        # adding batch_size dims and stacking all u vectors\r\n",
        "        u = u[None, :, :, None, :]\r\n",
        "        # 4D weight matrix\r\n",
        "        W = self.W[:, None, :, :, :]\r\n",
        "        \r\n",
        "        # calculating u_hat = W*u\r\n",
        "        u_hat = torch.matmul(u, W)\r\n",
        "\r\n",
        "        # getting the correct size of b_ij\r\n",
        "        # setting them all to 0, initially\r\n",
        "        b_ij = torch.zeros(*u_hat.size())\r\n",
        "        \r\n",
        "        # moving b_ij to GPU, if available\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            b_ij = b_ij.cuda()\r\n",
        "\r\n",
        "        # update coupling coefficients and calculate v_j\r\n",
        "        v_j = dynamic_routing(b_ij, u_hat, self.squash, routing_iterations=3)\r\n",
        "\r\n",
        "        return v_j # return final vector outputs\r\n",
        "    \r\n",
        "    \r\n",
        "    def squash(self, input_tensor):\r\n",
        "        '''Squashes an input Tensor so it has a magnitude between 0-1.\r\n",
        "           param input_tensor: a stack of capsule inputs, s_j\r\n",
        "           return: a stack of normalized, capsule output vectors, v_j\r\n",
        "           '''\r\n",
        "        # same squash function as before\r\n",
        "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\r\n",
        "        scale = squared_norm / (1 + squared_norm) # normalization coeff\r\n",
        "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \r\n",
        "        return output_tensor"
      ],
      "outputs": [],
      "metadata": {
        "id": "xGZfUiimxIgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, input_vector_length=16, input_capsules=10, hidden_dim=512):\r\n",
        "        '''Constructs an series of linear layers + activations.\r\n",
        "           param input_vector_length: dimension of input capsule vector, default value = 16\r\n",
        "           param input_capsules: number of capsules in previous layer, default value = 10\r\n",
        "           param hidden_dim: dimensions of hidden layers, default value = 512\r\n",
        "           '''\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        \r\n",
        "        # calculate input_dim\r\n",
        "        input_dim = input_vector_length * input_capsules\r\n",
        "        \r\n",
        "        # define linear layers + activations\r\n",
        "        self.linear_layers = nn.Sequential(\r\n",
        "            nn.Linear(input_dim, hidden_dim), # first hidden layer\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(hidden_dim, hidden_dim*2), # second, twice as deep\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(hidden_dim*2, 28*28), # can be reshaped into 28*28 image\r\n",
        "            nn.Sigmoid() # sigmoid activation to get output pixel values in a range from 0-1\r\n",
        "            )\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param x: the input; vectors from the previous DigitCaps layer\r\n",
        "           return: two things, reconstructed images and the class scores, y\r\n",
        "           '''\r\n",
        "        classes = (x ** 2).sum(dim=-1) ** 0.5\r\n",
        "        classes = F.softmax(classes, dim=-1)\r\n",
        "        \r\n",
        "        # find the capsule with the maximum vector length\r\n",
        "        # here, vector length indicates the probability of a class' existence\r\n",
        "        _, max_length_indices = classes.max(dim=1)\r\n",
        "        \r\n",
        "        # create a sparse class matrix\r\n",
        "        sparse_matrix = torch.eye(10) # 10 is the number of classes\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            sparse_matrix = sparse_matrix.cuda()\r\n",
        "        # get the class scores from the \"correct\" capsule\r\n",
        "        y = sparse_matrix.index_select(dim=0, index=max_length_indices.data)\r\n",
        "        \r\n",
        "        # create reconstructed pixels\r\n",
        "        x = x * y[:, :, None]\r\n",
        "        # flatten image into a vector shape (batch_size, vector_dim)\r\n",
        "        flattened_x = x.contiguous().view(x.size(0), -1)\r\n",
        "        # create reconstructed image vectors\r\n",
        "        reconstructions = self.linear_layers(flattened_x)\r\n",
        "        \r\n",
        "        # return reconstructions and the class scores, y\r\n",
        "        return reconstructions, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gu8R_RG0xN3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "class CapsuleNetwork(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self):\r\n",
        "        '''Constructs a complete Capsule Network.'''\r\n",
        "        super(CapsuleNetwork, self).__init__()\r\n",
        "        self.conv_layer = ConvLayer()\r\n",
        "        self.primary_capsules = PrimaryCaps()\r\n",
        "        self.digit_capsules = DigitCaps()\r\n",
        "        self.decoder = Decoder()\r\n",
        "                \r\n",
        "    def forward(self, images):\r\n",
        "        '''Defines the feedforward behavior.\r\n",
        "           param images: the original MNIST image input data\r\n",
        "           return: output of DigitCaps layer, reconstructed images, class scores\r\n",
        "           '''\r\n",
        "        primary_caps_output = self.primary_capsules(self.conv_layer(images))\r\n",
        "        caps_output = self.digit_capsules(primary_caps_output).squeeze().transpose(0,1)\r\n",
        "        #print(caps_output.type(), caps_output.size())\r\n",
        "        reconstructions, y = self.decoder(caps_output)\r\n",
        "        return caps_output, reconstructions, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "LKr1_RcwxRuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# instantiate and print net\r\n",
        "#import torch, gc\r\n",
        "#gc.collect()\r\n",
        "#torch.cuda.empty_cache()\r\n",
        "\r\n",
        "capsule_net = CapsuleNetwork()\r\n",
        "\r\n",
        "print(capsule_net)\r\n",
        "\r\n",
        "\r\n",
        "# move model to GPU, if available \r\n",
        "if TRAIN_ON_GPU:\r\n",
        "    capsule_net = capsule_net.cuda()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CapsuleNetwork(\n",
            "  (conv_layer): ConvLayer(\n",
            "    (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
            "  )\n",
            "  (primary_capsules): PrimaryCaps(\n",
            "    (capsules): ModuleList(\n",
            "      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (digit_capsules): DigitCaps()\n",
            "  (decoder): Decoder(\n",
            "    (linear_layers): Sequential(\n",
            "      (0): Linear(in_features=160, out_features=512, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=1024, out_features=784, bias=True)\n",
            "      (5): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHzjE51KxWe3",
        "outputId": "de39ddb8-e603-434a-ce0b-f20854be0d4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "class CapsuleLoss(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self):\r\n",
        "        '''Constructs a CapsuleLoss module.'''\r\n",
        "        super(CapsuleLoss, self).__init__()\r\n",
        "        self.reconstruction_loss = nn.MSELoss(reduction='sum') # cumulative loss, equiv to size_average=False\r\n",
        "\r\n",
        "    def forward(self, x, labels, images, reconstructions):\r\n",
        "        '''Defines how the loss compares inputs.\r\n",
        "           param x: digit capsule outputs\r\n",
        "           param labels: \r\n",
        "           param images: the original MNIST image input data\r\n",
        "           param reconstructions: reconstructed MNIST image data\r\n",
        "           return: weighted margin and reconstruction loss, averaged over a batch\r\n",
        "           '''\r\n",
        "        batch_size = x.size(0)\r\n",
        "\r\n",
        "        ##  calculate the margin loss   ##\r\n",
        "        \r\n",
        "        # get magnitude of digit capsule vectors, v_c\r\n",
        "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\r\n",
        "\r\n",
        "        # calculate \"correct\" and incorrect loss\r\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\r\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\r\n",
        "        \r\n",
        "        # sum the losses, with a lambda = 0.5\r\n",
        "        margin_loss = labels * left + 0.5 * (1. - labels) * right\r\n",
        "        margin_loss = margin_loss.sum()\r\n",
        "\r\n",
        "        ##  calculate the reconstruction loss   ##\r\n",
        "        images = images.view(reconstructions.size()[0], -1)\r\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\r\n",
        "\r\n",
        "        # return a weighted, summed loss, averaged over a batch size\r\n",
        "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lf7jUp2exZQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "# custom loss\r\n",
        "criterion = CapsuleLoss()\r\n",
        "\r\n",
        "# Adam optimizer with default params\r\n",
        "optimizer = optim.Adam(capsule_net.parameters())"
      ],
      "outputs": [],
      "metadata": {
        "id": "GYecVY8Jxdtt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "def train(capsule_net, criterion, optimizer, \r\n",
        "          n_epochs, print_every=300):\r\n",
        "    '''Trains a capsule network and prints out training batch loss statistics.\r\n",
        "       Saves model parameters if *validation* loss has decreased.\r\n",
        "       param capsule_net: trained capsule network\r\n",
        "       param criterion: capsule loss function\r\n",
        "       param optimizer: optimizer for updating network weights\r\n",
        "       param n_epochs: number of epochs to train for\r\n",
        "       param print_every: batches to print and save training loss, default = 100\r\n",
        "       return: list of recorded training losses\r\n",
        "       '''\r\n",
        "\r\n",
        "    # track training loss over time\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    # one epoch = one pass over all training data \r\n",
        "    for epoch in range(1, n_epochs+1):\r\n",
        "\r\n",
        "        # initialize training loss\r\n",
        "        train_loss = 0.0\r\n",
        "        \r\n",
        "        capsule_net.train() # set to train mode\r\n",
        "    \r\n",
        "        # get batches of training image data and targets\r\n",
        "        for batch_i, (images, target) in enumerate(train_loader):\r\n",
        "\r\n",
        "            # reshape and get target class\r\n",
        "            target = torch.eye(10).index_select(dim=0, index=target)\r\n",
        "\r\n",
        "            if TRAIN_ON_GPU:\r\n",
        "                images, target = images.cuda(), target.cuda()\r\n",
        "\r\n",
        "            # zero out gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "            # get model outputs\r\n",
        "            caps_output, reconstructions, y = capsule_net(images)\r\n",
        "            # calculate loss\r\n",
        "            loss = criterion(caps_output, target, images, reconstructions)\r\n",
        "            # perform backpropagation and optimization\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            train_loss += loss.item() # accumulated training loss\r\n",
        "            \r\n",
        "            # print and record training stats\r\n",
        "            if batch_i != 0 and batch_i % print_every == 0:\r\n",
        "                avg_train_loss = train_loss/print_every\r\n",
        "                losses.append(avg_train_loss)\r\n",
        "                print('Epoch: {} \\tTraining Loss: {:.8f}'.format(epoch, avg_train_loss))\r\n",
        "                train_loss = 0 # reset accumulated training loss\r\n",
        "        \r\n",
        "    return losses"
      ],
      "outputs": [],
      "metadata": {
        "id": "V0rVHcOnxjE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# training for 3 epochs\r\n",
        "n_epochs = 3\r\n",
        "losses = train(capsule_net, criterion, optimizer, n_epochs=n_epochs)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQs6bM2gxoCT",
        "outputId": "5b77a345-825f-4929-afac-2807074b2e59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def test(capsule_net, test_loader):\r\n",
        "    '''Prints out test statistics for a given capsule net.\r\n",
        "       param capsule_net: trained capsule network\r\n",
        "       param test_loader: test dataloader\r\n",
        "       return: returns last batch of test image data and corresponding reconstructions\r\n",
        "       '''\r\n",
        "    class_correct = list(0. for i in range(10))\r\n",
        "    class_total = list(0. for i in range(10))\r\n",
        "    \r\n",
        "    test_loss = 0 # loss tracking\r\n",
        "\r\n",
        "    capsule_net.eval() # eval mode\r\n",
        "\r\n",
        "    for batch_i, (images, target) in enumerate(test_loader):\r\n",
        "        target = torch.eye(10).index_select(dim=0, index=target)\r\n",
        "\r\n",
        "        batch_size = images.size(0)\r\n",
        "\r\n",
        "        if TRAIN_ON_GPU:\r\n",
        "            images, target = images.cuda(), target.cuda()\r\n",
        "\r\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\r\n",
        "        caps_output, reconstructions, y = capsule_net(images)\r\n",
        "        # calculate the loss\r\n",
        "        loss = criterion(caps_output, target, images, reconstructions)\r\n",
        "        # update average test loss \r\n",
        "        test_loss += loss.item()\r\n",
        "        # convert output probabilities to predicted class\r\n",
        "        _, pred = torch.max(y.data.cpu(), 1)\r\n",
        "        _, target_shape = torch.max(target.data.cpu(), 1)\r\n",
        "\r\n",
        "        # compare predictions to true label\r\n",
        "        correct = np.squeeze(pred.eq(target_shape.data.view_as(pred)))\r\n",
        "        # calculate test accuracy for each object class\r\n",
        "        for i in range(batch_size):\r\n",
        "            label = target_shape.data[i]\r\n",
        "            class_correct[label] += correct[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "\r\n",
        "    # avg test loss\r\n",
        "    avg_test_loss = test_loss/len(test_loader)\r\n",
        "    print('Test Loss: {:.8f}\\n'.format(avg_test_loss))\r\n",
        "\r\n",
        "    for i in range(10):\r\n",
        "        if class_total[i] > 0:\r\n",
        "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\r\n",
        "                str(i), 100 * class_correct[i] / class_total[i],\r\n",
        "                np.sum(class_correct[i]), np.sum(class_total[i])))\r\n",
        "        else:\r\n",
        "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\r\n",
        "\r\n",
        "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\r\n",
        "        100. * np.sum(class_correct) / np.sum(class_total),\r\n",
        "        np.sum(class_correct), np.sum(class_total)))\r\n",
        "    \r\n",
        "    # return last batch of capsule vectors, images, reconstructions\r\n",
        "    return caps_output, images, reconstructions"
      ],
      "outputs": [],
      "metadata": {
        "id": "oR6Gu9yQyE_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "#load the model\r\n",
        "\r\n",
        "\r\n",
        "from torchsummary import summary\r\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device = torch.device('cpu')\r\n",
        "\r\n",
        "capsule_net = CapsuleNetwork().to(device)\r\n",
        "capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "\r\n",
        "\r\n",
        "pre_trained_dict = capsule_net.state_dict()\r\n",
        "weight_tensor = pre_trained_dict['digit_capsules.W']\r\n",
        "print(weight_tensor.size())\r\n",
        "#print(weight_tensor)\r\n",
        "\r\n",
        "print('none zero weights count: ', torch.count_nonzero(weight_tensor))\r\n",
        "print('number of all tensor cells: ', torch.numel(weight_tensor))\r\n",
        "\r\n",
        "#pre_trained_dict['primary_capsules.capsules.1.weight'] = torch.zeros(32, 256, 9, 9, dtype=torch.float)\r\n",
        "\r\n",
        "#conv_weights = a\r\n",
        "#print(a.size())\r\n",
        "#print(a)\r\n",
        "#print(pre_trained_dict['digit_capsules.W'])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#PRINTING NETWORK PARAMETERS\r\n",
        "#for name, param in capsule_net.named_parameters():\r\n",
        "#    if param.requires_grad:\r\n",
        "#        print(name, param.type())\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "capsule_net.eval()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1152, 8, 16])\n",
            "none zero weights count:  tensor(1474560)\n",
            "number of all tensor cells:  1474560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsuleNetwork(\n",
              "  (conv_layer): ConvLayer(\n",
              "    (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "  )\n",
              "  (primary_capsules): PrimaryCaps(\n",
              "    (capsules): ModuleList(\n",
              "      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
              "    )\n",
              "  )\n",
              "  (digit_capsules): DigitCaps()\n",
              "  (decoder): Decoder(\n",
              "    (linear_layers): Sequential(\n",
              "      (0): Linear(in_features=160, out_features=512, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Linear(in_features=1024, out_features=784, bias=True)\n",
              "      (5): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# call test function and get reconstructed images\r\n",
        "capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "capsule_net.eval()\r\n",
        "caps_output, images, reconstructions = test(capsule_net, test_loader)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.03458104\n",
            "\n",
            "Test Accuracy of     0: 99% (975/980)\n",
            "Test Accuracy of     1: 99% (1130/1135)\n",
            "Test Accuracy of     2: 99% (1024/1032)\n",
            "Test Accuracy of     3: 98% (998/1010)\n",
            "Test Accuracy of     4: 99% (976/982)\n",
            "Test Accuracy of     5: 99% (888/892)\n",
            "Test Accuracy of     6: 99% (951/958)\n",
            "Test Accuracy of     7: 99% (1019/1028)\n",
            "Test Accuracy of     8: 98% (964/974)\n",
            "Test Accuracy of     9: 96% (977/1009)\n",
            "\n",
            "Test Accuracy (Overall): 99% (9902/10000)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clQUkYe81d3Q",
        "outputId": "2c167fd7-1ca2-4096-9349-ae86ff972989"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "import struct\r\n",
        "def float_to_bin(num):\r\n",
        "    return format(struct.unpack('!I', struct.pack('!f', num))[0], '032b')\r\n",
        "\r\n",
        "def bin_to_float(binary):\r\n",
        "    return struct.unpack('!f',struct.pack('!I', int(binary, 2)))[0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "from utils import float2bit\r\n",
        "from utils import bit2float\r\n",
        "import math\r\n",
        "\r\n",
        "#capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "\r\n",
        "#capsule_net.eval()\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "#state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "\r\n",
        "#print(state_dict['digit_capsules.W'][0, 0, 0, 0], '\\n')\r\n",
        "\r\n",
        "\r\n",
        "#binary_tensor = float2bit(state_dict['digit_capsules.W'], num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,)).size(), '\\n')\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,))[0].item(), '\\n')\r\n",
        "\r\n",
        "#torch.reshape(binary_tensor, (-1,))[0] = float(0)\r\n",
        "\r\n",
        "#print(torch.reshape(binary_tensor, (-1,))[0].item(), '\\n')\r\n",
        "\r\n",
        "#print(type(torch.reshape(binary_tensor, (-1,))[47185919].item()), '\\n')\r\n",
        "\r\n",
        "\r\n",
        "# validity test  ###############################################\r\n",
        "\r\n",
        "#for i in range (1, 9):\r\n",
        "    #torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index].item()\r\n",
        " #   binary_tensor[0, 0, 0, 0][i] = float(1)\r\n",
        "\r\n",
        "#for i in range (9, 32):\r\n",
        "#    binary_tensor[0, 0, 0, 0][i] = float(0)\r\n",
        "\r\n",
        "\r\n",
        "#print((binary_tensor[0, 0, 0, 0]), '\\n')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#float_tensor = bit2float(binary_tensor, num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "#print(math.isfinite(float_tensor[0, 0, 0, 0]))\r\n",
        "\r\n",
        "\r\n",
        "#print(float_tensor[0, 0, 0, 0])\r\n",
        "\r\n",
        "##################################################################\r\n",
        "\r\n",
        "\r\n",
        "## Fault injection ###############################################\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "number_of_bit_flips = 1000000\r\n",
        "\r\n",
        "exponential_fault_growth = 1\r\n",
        "\r\n",
        "while exponential_fault_growth < 47185919:\r\n",
        "\r\n",
        "    capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "\r\n",
        "    capsule_net.eval()\r\n",
        "\r\n",
        "    state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "    binary_tensor = float2bit(state_dict['digit_capsules.W'], num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "\r\n",
        "    for i in range (exponential_fault_growth):\r\n",
        "\r\n",
        "        random_bit_number = random.randint(0, 47185919)  \r\n",
        "\r\n",
        "        if( torch.reshape(binary_tensor, (-1,))[random_bit_number] == float(0) ):\r\n",
        "\r\n",
        "            torch.reshape(binary_tensor, (-1,))[random_bit_number] = float(1)\r\n",
        "\r\n",
        "        if( torch.reshape(binary_tensor, (-1,))[random_bit_number] == float(1) ):\r\n",
        "\r\n",
        "         torch.reshape(binary_tensor, (-1,))[random_bit_number] = float(0)\r\n",
        "\r\n",
        "    print(\"Number of Faults Injected: \", exponential_fault_growth, '\\n')\r\n",
        "\r\n",
        "    exponential_fault_growth *= 2\r\n",
        "\r\n",
        "    float_tensor = bit2float(binary_tensor, num_e_bits=8, num_m_bits=23, bias=127.)\r\n",
        "\r\n",
        "    for i in range (1474560):\r\n",
        "        if (math.isfinite(torch.reshape(float_tensor, (-1,))[i]) == False):\r\n",
        "         print(\"EROOOOOOOOOOOOOOOOOR\")\r\n",
        "\r\n",
        "    state_dict['digit_capsules.W'] = float_tensor\r\n",
        "    capsule_net.load_state_dict(state_dict)\r\n",
        "    capsule_net.eval()\r\n",
        "    caps_output, images, reconstructions = test(capsule_net, test_loader)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    print(\"*************************************************************************\", '\\n')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Faults Injected:  1 \n",
            "\n",
            "Test Loss: 0.03458070\n",
            "\n",
            "Test Accuracy of     0: 99% (975/980)\n",
            "Test Accuracy of     1: 99% (1130/1135)\n",
            "Test Accuracy of     2: 99% (1024/1032)\n",
            "Test Accuracy of     3: 98% (998/1010)\n",
            "Test Accuracy of     4: 99% (976/982)\n",
            "Test Accuracy of     5: 99% (888/892)\n",
            "Test Accuracy of     6: 99% (951/958)\n",
            "Test Accuracy of     7: 99% (1019/1028)\n",
            "Test Accuracy of     8: 98% (964/974)\n",
            "Test Accuracy of     9: 96% (977/1009)\n",
            "\n",
            "Test Accuracy (Overall): 99% (9902/10000)\n",
            "************************************************************************* \n",
            "\n",
            "Number of Faults Injected:  2 \n",
            "\n",
            "Test Loss: 0.03458104\n",
            "\n",
            "Test Accuracy of     0: 99% (975/980)\n",
            "Test Accuracy of     1: 99% (1130/1135)\n",
            "Test Accuracy of     2: 99% (1024/1032)\n",
            "Test Accuracy of     3: 98% (998/1010)\n",
            "Test Accuracy of     4: 99% (976/982)\n",
            "Test Accuracy of     5: 99% (888/892)\n",
            "Test Accuracy of     6: 99% (951/958)\n",
            "Test Accuracy of     7: 99% (1019/1028)\n",
            "Test Accuracy of     8: 98% (964/974)\n",
            "Test Accuracy of     9: 96% (977/1009)\n",
            "\n",
            "Test Accuracy (Overall): 99% (9902/10000)\n",
            "************************************************************************* \n",
            "\n",
            "Number of Faults Injected:  4 \n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "a = np.zeros((3, 3))\r\n",
        "print (a)\r\n",
        "\r\n",
        "iterator = 47185919\r\n",
        "i = 1\r\n",
        "while i < iterator:\r\n",
        "    print(i)\r\n",
        "    i *= 2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "1\n",
            "2\n",
            "4\n",
            "8\n",
            "16\n",
            "32\n",
            "64\n",
            "128\n",
            "256\n",
            "512\n",
            "1024\n",
            "2048\n",
            "4096\n",
            "8192\n",
            "16384\n",
            "32768\n",
            "65536\n",
            "131072\n",
            "262144\n",
            "524288\n",
            "1048576\n",
            "2097152\n",
            "4194304\n",
            "8388608\n",
            "16777216\n",
            "33554432\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "# Firstly, we get the model stats and parameters: \r\n",
        "\r\n",
        "#from torchsummary import summary\r\n",
        "#from time import sleep\r\n",
        "\r\n",
        "capsule_net.load_state_dict(torch.load('./model-parameters.pt'))\r\n",
        "capsule_net.eval()\r\n",
        "\r\n",
        "#summary(capsule_net, input_size=(1, 28, 28))\r\n",
        "\r\n",
        "state_dict = capsule_net.state_dict()\r\n",
        "\r\n",
        "original_parameters = capsule_net.state_dict()\r\n",
        "\r\n",
        "#print('The weight tensor size is:', state_dict['digit_capsules.W'].size(), state_dict['digit_capsules.W'].dtype, '\\n')\r\n",
        "\r\n",
        "#print('Number zero weights count: ', torch.count_nonzero(weight_tensor), '\\n')\r\n",
        "\r\n",
        "#print('Number of all tensor cells: ', torch.numel(weight_tensor), '\\n')\r\n",
        "\r\n",
        "#print('Number of total bits in the weight tensor: ', f\"{torch.numel(weight_tensor)*32:,}\", 'bits', '\\n' )\r\n",
        "\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "\r\n",
        "count = 0\r\n",
        "for i in range (1000):\r\n",
        "    #w_index = random.randint(0,9)\r\n",
        "    #x_index = random.randint(0,1151)\r\n",
        "    #y_index = random.randint(0,7)\r\n",
        "    #z_index = random.randint(0,15)\r\n",
        "    random_tensor_index = random.randint(0,1474559)\r\n",
        "    \r\n",
        "    tensor_cell = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index].item()\r\n",
        "\r\n",
        "    #tensor_cell = state_dict['digit_capsules.W'][w_index, x_index, y_index, z_index].item()\r\n",
        "\r\n",
        "    #print('The random selected weight at:', random_tensor_index, ' value:', type(tensor_cell), tensor_cell, '\\n')\r\n",
        "\r\n",
        "    temp = float_to_bin(tensor_cell)\r\n",
        "\r\n",
        "    #print('The random selected weight value in bits:', temp, type(temp), '\\n')\r\n",
        "\r\n",
        "    #print('Reversion check: ', bin_to_float(temp), type(bin_to_float(temp)), '\\n')\r\n",
        "\r\n",
        "    #for j in range (32):\r\n",
        "    random_bit_location = random.randint(0, 31)\r\n",
        "\r\n",
        "    #print('The selected bit is located at bit:', random_bit_location, '-  Value is:', temp[random_bit_location], '\\n')\r\n",
        "\r\n",
        "    editable_string = list(temp)\r\n",
        "        \r\n",
        "    if ( temp[random_bit_location] == '0' ):\r\n",
        "        editable_string[random_bit_location] = '1'\r\n",
        "    if ( temp[random_bit_location] == '1' ):\r\n",
        "        editable_string[random_bit_location] = '0'\r\n",
        "\r\n",
        "    final_bit_string = ''.join(editable_string)\r\n",
        "    \r\n",
        "    #print('The random selected weight value after bit flip: ', final_bit_string, '\\n')\r\n",
        "\r\n",
        "    final_tensor_value = float(bin_to_float(final_bit_string))\r\n",
        "    if (math.isfinite(final_tensor_value) == True):\r\n",
        "        print(final_tensor_value)\r\n",
        "        torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index] = final_tensor_value\r\n",
        "    #print('The random selected weight value after bit flip in float format', final_tensor_value, '\\n')\r\n",
        "    #print(final_tensor_value)\r\n",
        "    #torch.reshape(state_dict['digit_capsules.W'] , (-1,))[random_tensor_index] = tensor_cell\r\n",
        "\r\n",
        "    #state_dict['digit_capsules.W'][w_index, x_index, y_index, z_index] = final_tensor_value\r\n",
        "    #sleep(0.5) # Time in seconds\r\n",
        "    #Loading updated faulty cell back into the model's tensor\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "capsule_net.load_state_dict(state_dict)\r\n",
        "\r\n",
        "capsule_net.eval()\r\n",
        "caps_output, images, reconstructions = test(capsule_net, test_loader)\r\n",
        "\r\n",
        "  #capsule_net.load_state_dict(original_parameters)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4686159233168183e-10\n",
            "0.834665060043335\n",
            "0.5738019347190857\n",
            "-1.693809151649475\n",
            "-0.41687431931495667\n",
            "0.2846231460571289\n",
            "2.9128847122192383\n",
            "-1.701809287071228\n",
            "-1.883732795715332\n",
            "-1.882802963256836\n",
            "-1.242649793624878\n",
            "0.4774663746356964\n",
            "-2.2517949673783733e-06\n",
            "-0.6633909940719604\n",
            "-2.206758213663118e-11\n",
            "0.8108271360397339\n",
            "-1.0668209791183472\n",
            "1.2507662773132324\n",
            "1.216475248336792\n",
            "-1.3265883922576904\n",
            "0.6387655138969421\n",
            "-0.5887660980224609\n",
            "-1.749934434890747\n",
            "-0.9858512878417969\n",
            "2.1767120361328125\n",
            "0.15294647216796875\n",
            "0.917176365852356\n",
            "-0.02032366581261158\n",
            "-2.719259023666382\n",
            "1.879441499710083\n",
            "-0.4128277003765106\n",
            "-0.005330312997102737\n",
            "-1.2635740041732788\n",
            "0.5676394104957581\n",
            "0.507246732711792\n",
            "-1.6011048555374146\n",
            "-0.6115731000900269\n",
            "2.5539393424987793\n",
            "-2.1078776977811712e-20\n",
            "-0.253911554813385\n",
            "-1.4313610792160034\n",
            "1.2210946083068848\n",
            "0.017640158534049988\n",
            "0.4377450942993164\n",
            "-133244.515625\n",
            "-1.9117329120635986\n",
            "0.9317785501480103\n",
            "-0.9319571852684021\n",
            "1.1800907850265503\n",
            "0.8817236423492432\n",
            "-0.7435846328735352\n",
            "1.5438811779022217\n",
            "2.6254636395606212e-05\n",
            "3.484430105560321e-11\n",
            "0.9726134538650513\n",
            "1.3914414644241333\n",
            "1.3324943780899048\n",
            "0.5213566422462463\n",
            "0.719071090221405\n",
            "1.0101265907287598\n",
            "-1.0810775756835938\n",
            "-1.4372932011230688e-10\n",
            "-0.26918286085128784\n",
            "0.7731052041053772\n",
            "-1.9157376289367676\n",
            "-0.9160729050636292\n",
            "0.010866982862353325\n",
            "0.2903173565864563\n",
            "0.6743772625923157\n",
            "-1.7510709688110774e-39\n",
            "0.042918626219034195\n",
            "-1.7962607145309448\n",
            "0.0848298966884613\n",
            "-0.19825361669063568\n",
            "0.468648225069046\n",
            "0.16354069113731384\n",
            "1.2804242032871116e-05\n",
            "-0.9761194586753845\n",
            "1.0701396465301514\n",
            "0.8084775805473328\n",
            "0.8811667561531067\n",
            "-0.45346084237098694\n",
            "-1.683354377746582\n",
            "-0.3289971947669983\n",
            "-0.9947959184646606\n",
            "-1.6774089336395264\n",
            "-0.954123318195343\n",
            "0.14042404294013977\n",
            "-1.030930519104004\n",
            "0.22646357119083405\n",
            "1.7541496753692627\n",
            "1.2858377695083618\n",
            "-0.49207374453544617\n",
            "0.31067970395088196\n",
            "-0.03361629322171211\n",
            "6.105540251155617e-06\n",
            "-1.8566800874530998e-10\n",
            "0.25930678844451904\n",
            "-1.0197993516921997\n",
            "1.0448977947235107\n",
            "0.4139902889728546\n",
            "-0.6922740936279297\n",
            "0.4368283748626709\n",
            "3.750113364731078e-06\n",
            "0.02513423189520836\n",
            "2.4119374752044678\n",
            "-1.0643584728240967\n",
            "1.584800362586975\n",
            "2.144094228744507\n",
            "1.9139890670776367\n",
            "0.5221424102783203\n",
            "0.30638715624809265\n",
            "-2.589099168777466\n",
            "-1.2892496585845947\n",
            "-0.5917124152183533\n",
            "-0.5547288656234741\n",
            "3.8909684210396513e-20\n",
            "2.1184511184692383\n",
            "-5.94352536545896e+37\n",
            "-1.2110670804977417\n",
            "0.9669520258903503\n",
            "-0.36522147059440613\n",
            "0.12066303193569183\n",
            "0.3031651973724365\n",
            "0.8337497115135193\n",
            "-0.41293731331825256\n",
            "0.4754016697406769\n",
            "-1.0155391693115234\n",
            "0.14479902386665344\n",
            "-0.35455045104026794\n",
            "2.0424253940582275\n",
            "0.3577902913093567\n",
            "4.645964923567783e-21\n",
            "1.3377056121826172\n",
            "-0.5917028188705444\n",
            "1.6250352452562566e-10\n",
            "-35.354061126708984\n",
            "-2.2217113971710205\n",
            "0.6193358898162842\n",
            "0.38018760085105896\n",
            "1.0587612390518188\n",
            "0.002884871792048216\n",
            "-0.9264162182807922\n",
            "0.8693826198577881\n",
            "-0.8401562571525574\n",
            "0.974292516708374\n",
            "1.9042168855667114\n",
            "-0.18528519570827484\n",
            "-1.6972236633300781\n",
            "-0.8633507490158081\n",
            "0.5551627278327942\n",
            "-0.28858089447021484\n",
            "-0.8277394771575928\n",
            "-0.10224851965904236\n",
            "1.3878391981124878\n",
            "0.5821751356124878\n",
            "-1.8155256509780884\n",
            "-1.323249340057373\n",
            "0.04172810539603233\n",
            "-0.8932791948318481\n",
            "0.004499554634094238\n",
            "-0.6000108122825623\n",
            "-1.7044416666030884\n",
            "-0.807467520236969\n",
            "-1.703308214473509e-07\n",
            "-0.3322228491306305\n",
            "-1.6511976718902588\n",
            "-0.390096515417099\n",
            "2.7056651106249774e-06\n",
            "-0.6989789605140686\n",
            "-0.43739205598831177\n",
            "-1.015499234199524\n",
            "1.3189797401428223\n",
            "-0.6223021745681763\n",
            "-8.131742652039975e-05\n",
            "-2.346341371536255\n",
            "0.24938789010047913\n",
            "-0.08127807825803757\n",
            "-0.23928411304950714\n",
            "-0.7919719815254211\n",
            "-1.70927095413208\n",
            "0.2541791796684265\n",
            "0.003381691174581647\n",
            "-0.1702393889427185\n",
            "-0.6089335680007935\n",
            "0.017799226567149162\n",
            "1.4989367374235773e-39\n",
            "0.3643868565559387\n",
            "-0.9066692590713501\n",
            "-0.11716707050800323\n",
            "-0.8353261351585388\n",
            "1.3855124711990356\n",
            "-1.0747963190078735\n",
            "1.1854987144470215\n",
            "-1.117087960243225\n",
            "0.4451195001602173\n",
            "-2.245396137237549\n",
            "1.1885100603103638\n",
            "-6.868445748720049e-20\n",
            "-0.9508264064788818\n",
            "0.20551452040672302\n",
            "-0.5114886164665222\n",
            "-0.9773648977279663\n",
            "-0.7437756657600403\n",
            "-0.4415357708930969\n",
            "2.6816757148218073e-10\n",
            "1.2035717964172363\n",
            "0.34657609462738037\n",
            "-3.086637889726518e-10\n",
            "-1.037224776041028e-19\n",
            "-0.29698389768600464\n",
            "4.9541003646188695e-20\n",
            "-3.2060634702624213e-10\n",
            "0.6154928207397461\n",
            "1.5642354488372803\n",
            "2.5235355774694765e+38\n",
            "-0.019330495968461037\n",
            "-0.43982136249542236\n",
            "-0.9775928854942322\n",
            "0.005636771209537983\n",
            "1.3564692380896304e-05\n",
            "1.0744022130966187\n",
            "-0.001954694977030158\n",
            "-1.4317342042922974\n",
            "0.7443146705627441\n",
            "-0.17749656736850739\n",
            "1.4200375080108643\n",
            "1.006862759590149\n",
            "-0.7138078808784485\n",
            "9.73116343983265e+37\n",
            "0.21308274567127228\n",
            "-0.513723611831665\n",
            "0.6493567228317261\n",
            "2.833781838113158e-20\n",
            "-0.3460668921470642\n",
            "-0.043447233736515045\n",
            "-0.009000963531434536\n",
            "-1.0063111782073975\n",
            "0.8107517957687378\n",
            "-592.738525390625\n",
            "-0.006930537987500429\n",
            "-0.1471812129020691\n",
            "-0.8619325757026672\n",
            "-3.902050139004132e-06\n",
            "8.167274245352019e-06\n",
            "-0.39815548062324524\n",
            "0.5186880826950073\n",
            "-1.0326660871505737\n",
            "1.1221884489059448\n",
            "-4.07658576965332\n",
            "-0.4092337489128113\n",
            "-0.3957515060901642\n",
            "-1.0969721415676759e-06\n",
            "0.7875362038612366\n",
            "0.03198273479938507\n",
            "0.0027293344028294086\n",
            "7.943792661942489e-21\n",
            "0.48204657435417175\n",
            "-1.9688763618469238\n",
            "0.497273325920105\n",
            "-0.0005487538292072713\n",
            "0.10751055926084518\n",
            "0.10715384781360626\n",
            "-0.9353960156440735\n",
            "1.0466349124908447\n",
            "0.4314919114112854\n",
            "-1.0884590148925781\n",
            "-0.47465312480926514\n",
            "-0.8180596232414246\n",
            "-0.0006938294973224401\n",
            "-0.4980018734931946\n",
            "-4.102548597072748e+37\n",
            "-0.750801146030426\n",
            "-0.887513279914856\n",
            "-1.806392788887024\n",
            "1.7067537307739258\n",
            "0.7952156066894531\n",
            "0.5720251798629761\n",
            "523.5570678710938\n",
            "1.0899735689163208\n",
            "1.2187950611114502\n",
            "0.5194019675254822\n",
            "0.6346311569213867\n",
            "2.269906520843506\n",
            "-0.1865512728691101\n",
            "0.5720552206039429\n",
            "0.03758171200752258\n",
            "-0.7427316904067993\n",
            "0.182453915476799\n",
            "-0.6905132532119751\n",
            "-1.0971142053604126\n",
            "1.8531630039215088\n",
            "1.047745943069458\n",
            "-0.3470299541950226\n",
            "0.4806642234325409\n",
            "-1.0420526266098022\n",
            "-1.0086259841918945\n",
            "-1.1107890605926514\n",
            "0.06474687904119492\n",
            "-1.3264482021331787\n",
            "-0.006133189424872398\n",
            "-0.5502089858055115\n",
            "0.888293445110321\n",
            "0.0808291882276535\n",
            "0.7305206656455994\n",
            "-1.65194571018219\n",
            "0.7792297005653381\n",
            "1.0637773275375366\n",
            "-0.0018108469666913152\n",
            "-1.1227507591247559\n",
            "0.7242144346237183\n",
            "-0.6674734354019165\n",
            "-0.6106880307197571\n",
            "0.18990759551525116\n",
            "-2.499363493946305e-10\n",
            "-0.28255632519721985\n",
            "0.6111130714416504\n",
            "-0.48703500628471375\n",
            "-0.4023268520832062\n",
            "0.879883885383606\n",
            "0.5233659744262695\n",
            "-0.3123834431171417\n",
            "-0.15791383385658264\n",
            "-0.007590364199131727\n",
            "-0.03641992062330246\n",
            "-1.2340123653411865\n",
            "0.9836534261703491\n",
            "0.5093742609024048\n",
            "-0.32582521438598633\n",
            "0.2640095353126526\n",
            "2.384028434753418\n",
            "0.3597756028175354\n",
            "1.3102110624313354\n",
            "0.8300571441650391\n",
            "-0.5111739635467529\n",
            "0.09892674535512924\n",
            "0.2511114180088043\n",
            "0.0035737226717174053\n",
            "0.09933114051818848\n",
            "1.4217075109481812\n",
            "32.45317459106445\n",
            "0.07750067859888077\n",
            "0.45106980204582214\n",
            "-0.673812210559845\n",
            "0.3424679934978485\n",
            "1.3140971660614014\n",
            "-0.17615137994289398\n",
            "0.3571084141731262\n",
            "-0.8477128148078918\n",
            "-2.0890533924102783\n",
            "-0.3236824572086334\n",
            "1.073792815208435\n",
            "0.6458468437194824\n",
            "-0.32888278365135193\n",
            "0.551957905292511\n",
            "7.717693733866327e-06\n",
            "-0.18730714917182922\n",
            "-1.1357406377792358\n",
            "0.23045960068702698\n",
            "0.05761972814798355\n",
            "-0.2589874863624573\n",
            "0.3227309286594391\n",
            "1.846287869459e+38\n",
            "-0.2557549476623535\n",
            "0.8896061182022095\n",
            "0.0015280661173164845\n",
            "0.6238054633140564\n",
            "0.7120837569236755\n",
            "1.1949108738917857e-05\n",
            "0.3589235842227936\n",
            "-0.5516353249549866\n",
            "-0.3487367331981659\n",
            "-0.467319518327713\n",
            "0.2789309322834015\n",
            "4.186532978601919e-20\n",
            "2.977892210456381e-20\n",
            "1.3103525638580322\n",
            "0.4055556058883667\n",
            "-0.06377390027046204\n",
            "-2.3072397708892822\n",
            "0.7534986734390259\n",
            "1.4566410779953003\n",
            "-1.2018382549285889\n",
            "1.2813533544540405\n",
            "-0.22969911992549896\n",
            "-2.5340094137888022e+38\n",
            "0.3291414678096771\n",
            "1.4347666501998901\n",
            "-1.2394353689160198e-05\n",
            "-1.4316707849502563\n",
            "-0.34850791096687317\n",
            "1.4631770849227905\n",
            "1.1299564838409424\n",
            "-0.9751867651939392\n",
            "0.15634489059448242\n",
            "1.705539584159851\n",
            "1.5543040037155151\n",
            "1.6595269441604614\n",
            "-1.420946478843689\n",
            "-0.00278459582477808\n",
            "-0.7337605953216553\n",
            "0.14911463856697083\n",
            "0.16162453591823578\n",
            "0.1351391226053238\n",
            "1.4047417640686035\n",
            "0.823900043964386\n",
            "-0.6420522928237915\n",
            "0.0014377619372680783\n",
            "0.5357489585876465\n",
            "-0.9343762397766113\n",
            "-0.6101953983306885\n",
            "-1.8552977975121701e+37\n",
            "-0.5794407725334167\n",
            "0.45263782143592834\n",
            "-0.9088109731674194\n",
            "0.18357881903648376\n",
            "2.1656248569488525\n",
            "-0.35395532846450806\n",
            "-3.1066055283801575e-10\n",
            "0.6366688013076782\n",
            "0.00032535468926653266\n",
            "-0.23251159489154816\n",
            "-0.170311838388443\n",
            "-2.398122787475586\n",
            "1.2521320581436157\n",
            "-0.9433920383453369\n",
            "-7.80575465375577e-11\n",
            "0.6343982219696045\n",
            "-0.03749839961528778\n",
            "0.5665416121482849\n",
            "1.7668406569210162e+38\n",
            "-3.600482623191488e-20\n",
            "-1.0296374559402466\n",
            "-0.1282142996788025\n",
            "-0.3514537811279297\n",
            "-1.0839943885803223\n",
            "0.6714889407157898\n",
            "1.4619544744491577\n",
            "0.9856173396110535\n",
            "-0.0020594955421984196\n",
            "-0.6993867754936218\n",
            "0.49895989894866943\n",
            "-2.945445294102906e-39\n",
            "0.12068038433790207\n",
            "-3.971023510022159e-21\n",
            "1.0535287857055664\n",
            "-2.3106384861026896e-10\n",
            "-0.8497896194458008\n",
            "3.627569557078332e-20\n",
            "-0.5639558434486389\n",
            "1.2601047274074517e-05\n",
            "0.6274288296699524\n",
            "0.05515814200043678\n",
            "1.1060129404067993\n",
            "1.930490493774414\n",
            "-0.08636806905269623\n",
            "-0.6281771659851074\n",
            "-0.15138721466064453\n",
            "-0.039213698357343674\n",
            "0.12484728544950485\n",
            "-0.6797389388084412\n",
            "1.0556626319885254\n",
            "-1.8623811548505163e-20\n",
            "0.5564934015274048\n",
            "1.07753586769104\n",
            "0.7976519465446472\n",
            "-1.8585687939776108e-05\n",
            "-2.269204742333386e-06\n",
            "0.2711344063282013\n",
            "1.1560770273208618\n",
            "1.238933801651001\n",
            "-0.29206615686416626\n",
            "0.9431819319725037\n",
            "0.2252240628004074\n",
            "0.25060850381851196\n",
            "-0.33885738253593445\n",
            "-0.019633175805211067\n",
            "-1.3946985006332397\n",
            "1.3989288806915283\n",
            "-6.691893038508497e+37\n",
            "-0.44161105155944824\n",
            "-0.32244688272476196\n",
            "-0.9377541542053223\n",
            "-0.2565048933029175\n",
            "-0.33461764454841614\n",
            "0.0034492090344429016\n",
            "-0.16779348254203796\n",
            "-0.049682844430208206\n",
            "0.329950749874115\n",
            "-0.08140018582344055\n",
            "1.8334239682005204e-10\n",
            "0.6568456292152405\n",
            "0.990310549736023\n",
            "0.14270880818367004\n",
            "-5.7576830840844195e-06\n",
            "1.3865727186203003\n",
            "-0.2856159508228302\n",
            "-7.963981200326324e-20\n",
            "0.6528197526931763\n",
            "-1.4221971035003662\n",
            "-0.3249015510082245\n",
            "-1.5716572999954224\n",
            "-0.012014125473797321\n",
            "0.5979969501495361\n",
            "-0.31162670254707336\n",
            "-1.0083268880844116\n",
            "-1.6128671169281006\n",
            "-1.6972471475601196\n",
            "0.22317686676979065\n",
            "0.5088365077972412\n",
            "-6.234598571070831e-20\n",
            "0.5108502507209778\n",
            "1.014656901359558\n",
            "1.0329625606536865\n",
            "-1.5109323263168335\n",
            "-0.2116556316614151\n",
            "-0.34061938524246216\n",
            "0.19499894976615906\n",
            "-0.10180419683456421\n",
            "-0.0049613844603300095\n",
            "-0.7475864887237549\n",
            "2.3208162784576416\n",
            "-0.10954815149307251\n",
            "2.734876871109009\n",
            "-3.3220516903015785e-20\n",
            "0.17798109352588654\n",
            "0.7156996130943298\n",
            "1.5942625999450684\n",
            "0.49280980229377747\n",
            "0.4551524221897125\n",
            "0.1241781935095787\n",
            "0.8736764192581177\n",
            "-0.5282785892486572\n",
            "-0.8075979948043823\n",
            "-2.026723363312763e-20\n",
            "0.1809314638376236\n",
            "-1.8700782220548717e-06\n",
            "-1.351939082145691\n",
            "-1.180260005639866e-05\n",
            "0.013191615231335163\n",
            "-0.19408418238162994\n",
            "-0.9651568531990051\n",
            "0.0033272849395871162\n",
            "0.8010114431381226\n",
            "0.6042752861976624\n",
            "0.2801760137081146\n",
            "0.37987619638442993\n",
            "-0.8532294034957886\n",
            "0.3067111670970917\n",
            "0.42748403549194336\n",
            "0.860537052154541\n",
            "-1.3080674592574741e+38\n",
            "0.3862946331501007\n",
            "0.10668989270925522\n",
            "0.4866192638874054\n",
            "144484.5\n",
            "-0.0011386588448658586\n",
            "0.4921724200248718\n",
            "-0.5549749135971069\n",
            "0.09223780035972595\n",
            "6.693629529763712e-06\n",
            "-0.6446689367294312\n",
            "1.4593141078948975\n",
            "-0.002095063216984272\n",
            "-1.2410534620285034\n",
            "0.6367480754852295\n",
            "0.055417392402887344\n",
            "-1.1198161840438843\n",
            "0.00018453208031132817\n",
            "-1.1885204315185547\n",
            "-0.47937145829200745\n",
            "0.05586840584874153\n",
            "0.3535597324371338\n",
            "0.009097538888454437\n",
            "1.8032618761062622\n",
            "0.03188895061612129\n",
            "0.6719167232513428\n",
            "0.9146711230278015\n",
            "-1.3555139303207397\n",
            "1.7558001279830933\n",
            "2.1822545022587292e-05\n",
            "-0.9426141381263733\n",
            "0.15998093783855438\n",
            "1.6841042041778564\n",
            "-3.809186107852299e-21\n",
            "-2.5386719341084897e+38\n",
            "0.5577998161315918\n",
            "-0.8475815057754517\n",
            "0.12098240107297897\n",
            "1.1281707286834717\n",
            "1.8919851779937744\n",
            "0.34900760650634766\n",
            "1.8560596704483032\n",
            "0.3549371659755707\n",
            "1.1208232641220093\n",
            "-0.5830531716346741\n",
            "-6.040238430543432e-21\n",
            "-9.065136835628707e-11\n",
            "-1.213671088218689\n",
            "0.4044022262096405\n",
            "0.5619724988937378\n",
            "0.13924884796142578\n",
            "1.108005404472351\n",
            "0.4352618455886841\n",
            "0.5976231098175049\n",
            "1.605566143989563\n",
            "1.4290539026260376\n",
            "-1.352825403213501\n",
            "-0.06656190752983093\n",
            "2.984752655029297\n",
            "-0.6166201233863831\n",
            "0.08590589463710785\n",
            "0.001179429586045444\n",
            "-0.49715447425842285\n",
            "-0.05658990144729614\n",
            "0.33866384625434875\n",
            "0.30503135919570923\n",
            "2.412153720855713\n",
            "0.09724146127700806\n",
            "-1.0488232374191284\n",
            "-0.8128167986869812\n",
            "-0.22023360431194305\n",
            "0.02397467941045761\n",
            "-0.304423063993454\n",
            "-1.4631372690200806\n",
            "-1.3780293464660645\n",
            "-0.5834354758262634\n",
            "0.719691812992096\n",
            "-0.42673519253730774\n",
            "-1.5808199644088745\n",
            "-0.4235641658306122\n",
            "0.6045337915420532\n",
            "0.16582021117210388\n",
            "-0.8061034679412842\n",
            "-1.0617635780363344e-05\n",
            "0.5217661261558533\n",
            "0.9553350806236267\n",
            "1.866494448203746e+37\n",
            "1.4504576921463013\n",
            "0.7139036655426025\n",
            "-0.46774235367774963\n",
            "-1.013526439666748\n",
            "-0.7523808479309082\n",
            "0.08197805285453796\n",
            "-0.6059373021125793\n",
            "0.7413756251335144\n",
            "8.755607268540189e-06\n",
            "0.17395921051502228\n",
            "0.6989824175834656\n",
            "0.6941137909889221\n",
            "0.44646352529525757\n",
            "-0.823075532913208\n",
            "1.2342848777770996\n",
            "-1.3341764211654663\n",
            "-4.798820555151906e-06\n",
            "-1.1192500591278076\n",
            "0.23004880547523499\n",
            "-0.10006017982959747\n",
            "1.8057500123977661\n",
            "1.1436585187911987\n",
            "0.6785757541656494\n",
            "-1.157083511352539\n",
            "0.42411673069000244\n",
            "-1.5986690521240234\n",
            "0.29503950476646423\n",
            "-0.5304545760154724\n",
            "-0.7642516493797302\n",
            "-0.6864187717437744\n",
            "-0.20678886771202087\n",
            "-1.0929069519042969\n",
            "0.23703354597091675\n",
            "1.2361197471618652\n",
            "1.1277662515640259\n",
            "0.9277767539024353\n",
            "-0.7153984904289246\n",
            "0.5229526162147522\n",
            "-0.6468824148178101\n",
            "-0.00015312824689317495\n",
            "-1.2287709712982178\n",
            "0.5956134796142578\n",
            "0.6208051443099976\n",
            "0.6843899488449097\n",
            "0.03158707171678543\n",
            "-0.27276456356048584\n",
            "0.1915295124053955\n",
            "0.4460350573062897\n",
            "1.2931216955184937\n",
            "0.6146524548530579\n",
            "6.937474206214489e-11\n",
            "-2.5666338498986363e-10\n",
            "2.5109286070801318e-05\n",
            "-1.0558099746704102\n",
            "-0.13707175850868225\n",
            "3.2538130651573726e+38\n",
            "-0.7834902405738831\n",
            "1.0941338539123535\n",
            "1.274174690246582\n",
            "3.5889291763305664\n",
            "0.04160020872950554\n",
            "0.19294096529483795\n",
            "-1.688028335571289\n",
            "0.6732358336448669\n",
            "-0.7241448760032654\n",
            "-0.47708597779273987\n",
            "0.004771657753735781\n",
            "-2.520784414539179e-10\n",
            "0.05450300872325897\n",
            "-1.2265111207962036\n",
            "-0.30363619327545166\n",
            "-0.22835871577262878\n",
            "-8.356125556752694e-20\n",
            "-0.5986056327819824\n",
            "-2.2270379066467285\n",
            "0.35901448130607605\n",
            "0.5642114877700806\n",
            "-0.14934857189655304\n",
            "-0.9723511934280396\n",
            "-0.3967423141002655\n",
            "3.720519529584709e+19\n",
            "-5.439304693426474e+19\n",
            "0.00014896976063027978\n",
            "-0.9163310527801514\n",
            "0.014401698485016823\n",
            "-2.945414062303737e-20\n",
            "-0.05024956911802292\n",
            "1.4354662895202637\n",
            "-3.435789153183322e-10\n",
            "-1.0694760084152222\n",
            "-0.6787449717521667\n",
            "-3.697552264370074e-10\n",
            "0.0026493454352021217\n",
            "0.04126764461398125\n",
            "-0.049899082630872726\n",
            "-6.989836947468575e-06\n",
            "2.0541234016418457\n",
            "-4.479230042431226e-10\n",
            "1.9812814208803383e-20\n",
            "-0.5538896918296814\n",
            "0.14511990547180176\n",
            "0.1508617103099823\n",
            "-0.4437028467655182\n",
            "-0.2566363215446472\n",
            "0.11726072430610657\n",
            "1.9966336488723755\n",
            "1.2350127696990967\n",
            "-0.14277943968772888\n",
            "0.9405947327613831\n",
            "-3.902986127493825e-20\n",
            "2.6068133593071252e-05\n",
            "0.2091098129749298\n",
            "-0.4122177064418793\n",
            "0.1523950845003128\n",
            "-0.36033400893211365\n",
            "0.0025329224299639463\n",
            "0.0013309462228789926\n",
            "0.8179567456245422\n",
            "-0.0008241388713940978\n",
            "0.3388943076133728\n",
            "-0.813647985458374\n",
            "1.254373550415039\n",
            "1.820099019354669e+38\n",
            "0.07418734580278397\n",
            "-0.8304651379585266\n",
            "3.536177928253892e-06\n",
            "-0.21645119786262512\n",
            "0.06090555340051651\n",
            "-0.49922648072242737\n",
            "2.3514515521342783e+37\n",
            "0.09586737304925919\n",
            "0.2624558210372925\n",
            "-0.09868364781141281\n",
            "0.7577983140945435\n",
            "0.9624279141426086\n",
            "1.7303810119628906\n",
            "1.3689306797459722e-05\n",
            "8.504930179072155e-20\n",
            "0.0018464750610291958\n",
            "0.5718150734901428\n",
            "-1.7311358451843262\n",
            "1.4572720527648926\n",
            "-4.276883125305176\n",
            "-1.1981327533721924\n",
            "-1.121421217918396\n",
            "-0.20390330255031586\n",
            "-0.07697831839323044\n",
            "-5.5836003411968704e-06\n",
            "-2.0423078536987305\n",
            "-0.8564971685409546\n",
            "0.556735634803772\n",
            "-0.1309584230184555\n",
            "1.197428584098816\n",
            "8.87501960569147e+37\n",
            "0.9690663814544678\n",
            "-0.8777447938919067\n",
            "0.8814632296562195\n",
            "0.6567468047142029\n",
            "0.8576207160949707\n",
            "-1.1507550477981567\n",
            "2.5915655838177097e-39\n",
            "-1.0927600860595703\n",
            "-0.6051408052444458\n",
            "0.8542035818099976\n",
            "2.4771461539785378e-05\n",
            "-1.2956198453903198\n",
            "1.4807615280151367\n",
            "-0.32540467381477356\n",
            "0.5837357044219971\n",
            "-0.18479304015636444\n",
            "0.23104970157146454\n",
            "0.3015943169593811\n",
            "-4.416042694528007e+35\n",
            "-0.9193313121795654\n",
            "0.3054135739803314\n",
            "1.7345755100250244\n",
            "-0.3441874086856842\n",
            "-1.2512834072113037\n",
            "-2.9766526222229004\n",
            "-0.4826831817626953\n",
            "-2.941398035806307e-20\n",
            "-0.28208717703819275\n",
            "0.3745238780975342\n",
            "-0.841736376285553\n",
            "0.6383686661720276\n",
            "-0.0044904956594109535\n",
            "0.052148643881082535\n",
            "-0.8245016932487488\n",
            "-2.113213300704956\n",
            "-1.938225507736206\n",
            "-9.007236258185003e-06\n",
            "0.19884583353996277\n",
            "-0.04949824884533882\n",
            "2.8325015591690317e-05\n",
            "-0.5212679505348206\n",
            "1.7037127017974854\n",
            "0.39692437648773193\n",
            "1.538727045059204\n",
            "0.21734680235385895\n",
            "-0.8691275715827942\n",
            "-0.7372134923934937\n",
            "1.510736346244812\n",
            "1.292918086051941\n",
            "-4.809921847481746e-06\n",
            "3.775254761584357e-11\n",
            "-0.345353364944458\n",
            "0.894366443157196\n",
            "-0.3610810339450836\n",
            "9.637798029871192e-06\n",
            "-0.13114069402217865\n",
            "-1.1860389709472656\n",
            "0.34611842036247253\n",
            "2.162928819656372\n",
            "-0.2217627912759781\n",
            "0.3342995345592499\n",
            "1.8986819982528687\n",
            "1.7320023775100708\n",
            "-5.317123762956824e-20\n",
            "0.6221808195114136\n",
            "1.3490979671478271\n",
            "-1.392260193824768\n",
            "1.39094199766987e-05\n",
            "0.46008285880088806\n",
            "-0.5254020690917969\n",
            "-0.3525041341781616\n",
            "0.10483307391405106\n",
            "0.31398963928222656\n",
            "-5.477864019904057e-20\n",
            "-11.471691131591797\n",
            "0.5571404099464417\n",
            "0.25396546721458435\n",
            "-1.7564227619004669e-06\n",
            "-0.23866869509220123\n",
            "-0.9137297868728638\n",
            "-0.0202841367572546\n",
            "0.001438660197891295\n",
            "1.5269232988357544\n",
            "-0.2267075777053833\n",
            "-0.7292605042457581\n",
            "-0.2133508175611496\n",
            "-0.6365366578102112\n",
            "0.4602125883102417\n",
            "1.089377760887146\n",
            "-0.0028643759433180094\n",
            "0.6518357992172241\n",
            "2.3105561922420748e-05\n",
            "-1.864560900743218e+38\n",
            "-1.2490296363830566\n",
            "0.17866423726081848\n",
            "-0.21709752082824707\n",
            "1.3464468717575073\n",
            "0.49528980255126953\n",
            "-0.6883652210235596\n",
            "-0.4804632365703583\n",
            "-1.0793712139129639\n",
            "0.25200793147087097\n",
            "-1.1542320251464844\n",
            "-0.170230433344841\n",
            "-1.4871819019317627\n",
            "-0.28885242342948914\n",
            "0.9045541882514954\n",
            "2.384474277496338\n",
            "-0.3969730734825134\n",
            "-0.5566980838775635\n",
            "-1.5592695474624634\n",
            "-3.358596040170525e-11\n",
            "-1.4112236499786377\n",
            "0.46948492527008057\n",
            "0.06740567088127136\n",
            "519.4720458984375\n",
            "1.5028682947158813\n",
            "576.7962646484375\n",
            "0.19593530893325806\n",
            "-0.5188895463943481\n",
            "-2.1369757652282715\n",
            "1.867498755455017\n",
            "-3.2237570946058725e-10\n",
            "-0.4325326681137085\n",
            "1.0547806024551392\n",
            "0.2719012498855591\n",
            "-1.8230617046356201\n",
            "1.974534273147583\n",
            "0.39743947982788086\n",
            "-1.1222678422927856\n",
            "-0.6634175181388855\n",
            "-0.2454860806465149\n",
            "-1.5813257694244385\n",
            "1.5094711780548096\n",
            "-1.5485498905181885\n",
            "3.7356662303851007e-20\n",
            "-1.2093946933746338\n",
            "-0.11841999739408493\n",
            "0.11758269369602203\n",
            "-0.018832461908459663\n",
            "1.0175154209136963\n",
            "0.29260388016700745\n",
            "-1.7986392974853516\n",
            "0.554366946220398\n",
            "-0.002559887943789363\n",
            "0.04812592267990112\n",
            "-0.5701106190681458\n",
            "-0.9408108592033386\n",
            "0.05513014271855354\n",
            "0.03276115283370018\n",
            "-0.34073472023010254\n",
            "0.7565807104110718\n",
            "-1.2801921367645264\n",
            "0.441729336977005\n",
            "0.8159937262535095\n",
            "0.384053498506546\n",
            "-1.3503940105438232\n",
            "-1.373281247651903e-05\n",
            "1.1862537860870361\n",
            "-0.7622199654579163\n",
            "1.7702085971832275\n",
            "-3.529351255693314e-10\n",
            "0.1292763352394104\n",
            "1.8321776390075684\n",
            "-6.940336145004003e-20\n",
            "-1.8980739116668701\n",
            "-2.2882273197174072\n",
            "-0.8281863331794739\n",
            "-2.3868298190804747e-20\n",
            "0.45127782225608826\n",
            "0.8151141405105591\n",
            "-0.7581374049186707\n",
            "0.13481679558753967\n",
            "1.7531476020812988\n",
            "-0.01541069708764553\n",
            "1.1322904825210571\n",
            "-0.006064367014914751\n",
            "-3.0940569550885755e-10\n",
            "-1.5378011465072632\n",
            "0.0898783802986145\n",
            "-0.8339090943336487\n",
            "1.6307454109191895\n",
            "0.0942748561501503\n",
            "0.007384166587144136\n",
            "-1.6263623237609863\n",
            "-0.8810842037200928\n",
            "0.7934591174125671\n",
            "-1.4456406831741333\n",
            "0.07184191048145294\n",
            "-2.0983849380318276e-10\n",
            "-0.36316534876823425\n",
            "-0.8851619958877563\n",
            "0.04388061910867691\n",
            "0.2952609956264496\n",
            "-1.4228262901306152\n",
            "7.849343822507992e-21\n",
            "0.5116344094276428\n",
            "4.4960490191980895e-11\n",
            "1.4573296308517456\n",
            "-0.013551865704357624\n",
            "0.8643587827682495\n",
            "Test Loss: nan\n",
            "\n",
            "Test Accuracy of     0: 100% (980/980)\n",
            "Test Accuracy of     1:  0% ( 0/1135)\n",
            "Test Accuracy of     2:  0% ( 0/1032)\n",
            "Test Accuracy of     3:  0% ( 0/1010)\n",
            "Test Accuracy of     4:  0% ( 0/982)\n",
            "Test Accuracy of     5:  0% ( 0/892)\n",
            "Test Accuracy of     6:  0% ( 0/958)\n",
            "Test Accuracy of     7:  0% ( 0/1028)\n",
            "Test Accuracy of     8:  0% ( 0/974)\n",
            "Test Accuracy of     9:  0% ( 0/1009)\n",
            "\n",
            "Test Accuracy (Overall):  9% (980/10000)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "print(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0].item())\r\n",
        "torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0] = 0\r\n",
        "print(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[0].item())\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import math\r\n",
        "max = 0\r\n",
        "min = 0 \r\n",
        "for i in range (1474559):\r\n",
        "    if (torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item() > max):\r\n",
        "        max = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()\r\n",
        "\r\n",
        "    if (torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item() < min):\r\n",
        "        min = torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()\r\n",
        "\r\n",
        "print(min)\r\n",
        "print(max)\r\n",
        "\r\n",
        "count = 0\r\n",
        "\r\n",
        "for i in range (1474559):\r\n",
        "    if (math.isfinite(torch.reshape(state_dict['digit_capsules.W'] , (-1,))[i].item()) == True):\r\n",
        "        count = count + 1\r\n",
        "\r\n",
        "print(count)\r\n",
        "#caps_output, images, reconstructions = test(capsule_net, test_loader)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-c0c994da7e3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1474559\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'digit_capsules.W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'digit_capsules.W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "import math\r\n",
        "if (bin_to_float('01111111100000000000000000000000') == float('inf')):\r\n",
        "    print('yes')\r\n",
        "\r\n",
        "print(math.isfinite(bin_to_float('01111111100000000000000000000000')))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n",
            "False\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(caps_output.size())"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def display_images(images, reconstructions):\r\n",
        "    '''Plot one row of original MNIST images and another row (below) \r\n",
        "       of their reconstructions.'''\r\n",
        "    # convert to numpy images\r\n",
        "    images = images.data.cpu().numpy()\r\n",
        "    reconstructions = reconstructions.view(-1, 1, 28, 28)\r\n",
        "    reconstructions = reconstructions.data.cpu().numpy()\r\n",
        "    \r\n",
        "    # plot the first ten input images and then reconstructed images\r\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(26,5))\r\n",
        "\r\n",
        "    # input images on top row, reconstructions on bottom\r\n",
        "    for images, row in zip([images, reconstructions], axes):\r\n",
        "        for img, ax in zip(images, row):\r\n",
        "            ax.imshow(np.squeeze(img), cmap='gray')\r\n",
        "            ax.get_xaxis().set_visible(False)\r\n",
        "            ax.get_yaxis().set_visible(False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HnjrQyqS1jem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# display original and reconstructed images, in rows\r\n",
        "display_images(images, reconstructions)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "ZTa-sNhX1nf9",
        "outputId": "e168f284-4bb3-441e-b414-6762b81fae86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# convert data to Tensor *and* perform random affine transformation\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.RandomAffine(degrees=30, translate=(0.1,0.1)),\r\n",
        "     transforms.ToTensor()]\r\n",
        "    )\r\n",
        "\r\n",
        "# test dataset\r\n",
        "transformed_test_data = datasets.MNIST(root='data', train=False,\r\n",
        "                                       download=True, transform=transform)\r\n",
        "\r\n",
        "# prepare data loader\r\n",
        "transformed_test_loader = torch.utils.data.DataLoader(transformed_test_data, \r\n",
        "                                                      batch_size=batch_size,\r\n",
        "                                                      num_workers=num_workers)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9vFtJK0R1sHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# obtain one batch of test images\r\n",
        "dataiter = iter(transformed_test_loader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "images = images.numpy()\r\n",
        "\r\n",
        "# plot the images in the batch, along with the corresponding labels\r\n",
        "fig = plt.figure(figsize=(25, 4))\r\n",
        "for idx in np.arange(batch_size):\r\n",
        "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\r\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\r\n",
        "    # print out the correct label for each image\r\n",
        "    # .item() gets the value contained in a Tensor\r\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "KckPo33p1v2S",
        "outputId": "ddf44b2d-93b2-4d56-ad94-ae6dd680b1ba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "# call test function and get reconstructed images\r\n",
        "_, images, reconstructions = test(capsule_net, transformed_test_loader)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd3PdXRe12zL",
        "outputId": "9a600558-8041-4a45-ec1a-960d91fdf2e2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# original input images\r\n",
        "display_images(images, reconstructions)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "XIlrGK7C1-GP",
        "outputId": "d57502ec-1ea2-42c4-8897-8837c94f2044"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ea9a38d010ffc381d1d172948c04e6ee4e06772ab79ba1dede86e3c983e76032"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}